{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta as rd\n",
    "import time\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks data csv read\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df.set_index('Date')\n",
    "\n",
    "# s&p data csv read\n",
    "df_sp = pd.read_csv('sp500.csv')\n",
    "df_sp = df_sp.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks data csv read for daily change\n",
    "df_change = pd.read_csv('data.csv')\n",
    "df_change = df_change.set_index('Date')\n",
    "\n",
    "# s&p data csv read for daily change\n",
    "df_sp_change = pd.read_csv('sp500.csv')\n",
    "df_sp_change = df_sp_change.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_slicer(df, start, duration, rebalancing_period=0):\n",
    "    start = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=rebalancing_period))\n",
    "    end = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=duration) - rd(days=1))\n",
    "    return df.loc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(df):\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    df = df.cumprod()\n",
    "    df = df - 1\n",
    "    df = df.iloc[-1,:]\n",
    "    df = df.to_numpy()\n",
    "    df = torch.from_numpy(df).type(torch.Tensor)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_change(df):\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_return(df):\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf biuld\n",
    "class shallow_NNF(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_classes):\n",
    "        super(shallow_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.softmax(self.fc2(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf build\n",
    "class deep_NNF(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size1, hidden_size2, hidden_size3,\n",
    "                 hidden_size4, hidden_size5, num_classes, dropout_p = 0.2):\n",
    "        super(deep_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.fc5 = nn.Linear(hidden_size4, hidden_size5)\n",
    "        self.fc6 = nn.Linear(hidden_size5, num_classes)\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        self.fc3.reset_parameters()\n",
    "        self.fc4.reset_parameters()\n",
    "        self.fc5.reset_parameters()\n",
    "        self.fc6.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc4(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc5(out))\n",
    "        out = self.softmax(self.fc6(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/N model build\n",
    "class equal_w_model():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.performance()\n",
    "        \n",
    "    def performance(self):\n",
    "        self.df = np.array(self.df)\n",
    "        weights = np.ones((len(self.df), 1)) * (1/len(self.df))\n",
    "        cumulative_change = sum(np.multiply(weights, self.df.reshape(-1,1)))\n",
    "        return cumulative_change, weights.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# shallow_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size = 471\n",
    "num_classes = 471\n",
    "lr = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf tune\n",
    "shallow_NNF = shallow_NNF(input_dim=input_dim, hidden_size=hidden_size, num_classes=num_classes)\n",
    "shallow_NNF_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "shallow_NNF_optimizer = torch.optim.Adam(shallow_NNF.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# deep_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size1 = 471\n",
    "hidden_size2 = 471\n",
    "hidden_size3 = 471\n",
    "hidden_size4 = 471\n",
    "hidden_size5 = 471\n",
    "num_classes = 471\n",
    "lr = 0.001\n",
    "dropout_p = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf tune\n",
    "deep_NNF = deep_NNF(input_dim=input_dim, hidden_size1=hidden_size1, hidden_size2=hidden_size2, \n",
    "                    hidden_size3=hidden_size3, hidden_size4=hidden_size4, hidden_size5=hidden_size5,\n",
    "                    num_classes=num_classes)\n",
    "deep_NNF_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "deep_NNF_optimizer = torch.optim.Adam(deep_NNF.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "def RMSE(x, y, weights):\n",
    "    temp = 0\n",
    "    for i in range(len(x)):\n",
    "        temp += (sum(x.iloc[i] * weights) - y.iloc[i]) ** 2\n",
    "    return math.sqrt(temp/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MEAN(x, weights):\n",
    "    temp = []\n",
    "    for i in range(len(x)):\n",
    "        temp.append(sum(x.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf validation function\n",
    "def valid_fun(x_valid, y_valid, i, model):\n",
    "    x = daily_change(date_slicer(df_change, '2017-07-01', 6, i))\n",
    "    y = daily_change(date_slicer(df_sp_change, '2017-07-01', 6, i))\n",
    "    weights = np.array(model(x_valid)[1].detach())\n",
    "    valid_rmse = RMSE(x, y, weights)\n",
    "    return print(f'Validation RMSE: {valid_rmse}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Shallow NNF Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf training function\n",
    "def train_shallow_nnf(x_train, y_train, i):\n",
    "    start_time_shallow_nnf = time.time()\n",
    "    print(f'\\nShallow NNF Training & Results for model {i+1}:')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = shallow_NNF(x_train)[0]\n",
    "        loss_shallow_nnf = shallow_NNF_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_shallow_nnf.item()}')\n",
    "        shallow_NNF_optimizer.zero_grad()\n",
    "        loss_shallow_nnf.backward()\n",
    "        shallow_NNF_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_shallow_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shallow NNF Training & Results for model 1:\n",
      "Epoch 1 of 100 | MSE: 0.04402278736233711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamidrezarahimzadeh/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 of 100 | MSE: 9.129153113462962e-06\n",
      "Training time: 0.80\n",
      "Validation RMSE: 0.007996386268122522\n",
      "\n",
      "Shallow NNF Training & Results for model 2:\n",
      "Epoch 1 of 100 | MSE: 0.052078526467084885\n",
      "Epoch 100 of 100 | MSE: 0.048756424337625504\n",
      "Training time: 0.58\n",
      "Validation RMSE: 0.013179129351876089\n",
      "\n",
      "Shallow NNF Training & Results for model 3:\n",
      "Epoch 1 of 100 | MSE: 0.045497145503759384\n",
      "Epoch 100 of 100 | MSE: 0.0010102405212819576\n",
      "Training time: 0.58\n",
      "Validation RMSE: 0.013498313076115005\n",
      "\n",
      "Shallow NNF Training & Results for model 4:\n",
      "Epoch 1 of 100 | MSE: 0.05976375937461853\n",
      "Epoch 100 of 100 | MSE: 0.00021922565065324306\n",
      "Training time: 0.57\n",
      "Validation RMSE: 0.009269164690021297\n",
      "\n",
      "Shallow NNF Training & Results for model 5:\n",
      "Epoch 1 of 100 | MSE: 0.043018873780965805\n",
      "Epoch 100 of 100 | MSE: 0.0026629024650901556\n",
      "Training time: 0.58\n",
      "Validation RMSE: 0.011181171995261398\n",
      "\n",
      "Shallow NNF Training & Results for model 6:\n",
      "Epoch 1 of 100 | MSE: 0.047487594187259674\n",
      "Epoch 100 of 100 | MSE: 0.0018421834101900458\n",
      "Training time: 0.61\n",
      "Validation RMSE: 0.01532038005743992\n",
      "\n",
      "Shallow NNF Training & Results for model 7:\n",
      "Epoch 1 of 100 | MSE: 0.04097576066851616\n",
      "Epoch 100 of 100 | MSE: 0.06094931811094284\n",
      "Training time: 0.57\n",
      "Validation RMSE: 0.014320852957084969\n",
      "\n",
      "Shallow NNF Training & Results for model 8:\n",
      "Epoch 1 of 100 | MSE: 0.041364848613739014\n",
      "Epoch 100 of 100 | MSE: 0.0349324531853199\n",
      "Training time: 0.60\n",
      "Validation RMSE: 0.010206880934537766\n",
      "\n",
      "Shallow NNF Training & Results for model 9:\n",
      "Epoch 1 of 100 | MSE: 0.02661452256143093\n",
      "Epoch 100 of 100 | MSE: 0.018304649740457535\n",
      "Training time: 0.61\n",
      "Validation RMSE: 0.009297410882343649\n",
      "\n",
      "Shallow NNF Training & Results for model 10:\n",
      "Epoch 1 of 100 | MSE: 0.030174031853675842\n",
      "Epoch 100 of 100 | MSE: 7.757371349725872e-06\n",
      "Training time: 0.58\n",
      "Validation RMSE: 0.009859569551215683\n",
      "\n",
      "Shallow NNF Training & Results for model 11:\n",
      "Epoch 1 of 100 | MSE: 0.034820716828107834\n",
      "Epoch 100 of 100 | MSE: 0.019544359296560287\n",
      "Training time: 0.59\n",
      "Validation RMSE: 0.014378661878670469\n",
      "\n",
      "Shallow NNF Training & Results for model 12:\n",
      "Epoch 1 of 100 | MSE: 0.037240151315927505\n",
      "Epoch 100 of 100 | MSE: 0.0323115810751915\n",
      "Training time: 0.56\n",
      "Validation RMSE: 0.018783939945234234\n",
      "\n",
      "Shallow NNF Training & Results for model 13:\n",
      "Epoch 1 of 100 | MSE: 0.03400393947958946\n",
      "Epoch 100 of 100 | MSE: 0.04241694509983063\n",
      "Training time: 0.58\n",
      "Validation RMSE: 0.023556984692288743\n",
      "\n",
      "Shallow NNF Training & Results for model 14:\n",
      "Epoch 1 of 100 | MSE: 0.03221547231078148\n",
      "Epoch 100 of 100 | MSE: 0.00048803340177983046\n",
      "Training time: 0.60\n",
      "Validation RMSE: 0.024515642340880064\n",
      "\n",
      "Shallow NNF Training & Results for model 15:\n",
      "Epoch 1 of 100 | MSE: 0.038578856736421585\n",
      "Epoch 100 of 100 | MSE: 0.10870157182216644\n",
      "Training time: 0.59\n",
      "Validation RMSE: 0.016042303050822805\n",
      "\n",
      "Shallow NNF Training & Results for model 16:\n",
      "Epoch 1 of 100 | MSE: 0.04116625338792801\n",
      "Epoch 100 of 100 | MSE: 0.04850398749113083\n",
      "Training time: 0.59\n",
      "Validation RMSE: 0.015911921322041975\n",
      "\n",
      "Shallow NNF Training & Results for model 17:\n",
      "Epoch 1 of 100 | MSE: 0.026059376075863838\n",
      "Epoch 100 of 100 | MSE: 0.0043588546104729176\n",
      "Training time: 0.60\n",
      "Validation RMSE: 0.012570841217857955\n",
      "\n",
      "Shallow NNF Training & Results for model 18:\n",
      "Epoch 1 of 100 | MSE: 0.025859663262963295\n",
      "Epoch 100 of 100 | MSE: 0.010333050042390823\n",
      "Training time: 0.63\n",
      "Validation RMSE: 0.012127101306875693\n",
      "\n",
      "Shallow NNF Training & Results for model 19:\n",
      "Epoch 1 of 100 | MSE: 0.021480906754732132\n",
      "Epoch 100 of 100 | MSE: 0.007886937819421291\n",
      "Training time: 0.59\n",
      "Validation RMSE: 0.013125992144649259\n",
      "\n",
      "Shallow NNF Training & Results for model 20:\n",
      "Epoch 1 of 100 | MSE: 0.037237148731946945\n",
      "Epoch 100 of 100 | MSE: 0.00019980590150225908\n",
      "Training time: 0.60\n",
      "Validation RMSE: 0.013640982778316246\n",
      "\n",
      "Shallow NNF Training & Results for model 21:\n",
      "Epoch 1 of 100 | MSE: 0.0457335002720356\n",
      "Epoch 100 of 100 | MSE: 0.008262485265731812\n",
      "Training time: 0.78\n",
      "Validation RMSE: 0.013509970262904942\n",
      "\n",
      "Shallow NNF Training & Results for model 22:\n",
      "Epoch 1 of 100 | MSE: 0.02765597775578499\n",
      "Epoch 100 of 100 | MSE: 0.017993172630667686\n",
      "Training time: 0.83\n",
      "Validation RMSE: 0.01577367246080972\n",
      "\n",
      "Shallow NNF Training & Results for model 23:\n",
      "Epoch 1 of 100 | MSE: 0.026807501912117004\n",
      "Epoch 100 of 100 | MSE: 0.034376513212919235\n",
      "Training time: 0.84\n",
      "Validation RMSE: 0.013718612617895245\n",
      "\n",
      "Shallow NNF Training & Results for model 24:\n",
      "Epoch 1 of 100 | MSE: 0.017079971730709076\n",
      "Epoch 100 of 100 | MSE: 0.0065803141333162785\n",
      "Training time: 0.83\n",
      "Validation RMSE: 0.013402328698647966\n"
     ]
    }
   ],
   "source": [
    "#shallow nnf\n",
    "for i in range(24):\n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    # x_test = data_process(date_slicer(df, '2014-07-01', 30, i))\n",
    "    # y_test = data_process(date_slicer(df_sp, '2014-07-01', 30, i))\n",
    "    train_shallow_nnf(x_train, y_train, i)\n",
    "    valid_fun(x_valid, y_valid, i, shallow_NNF)\n",
    "    # test computation\n",
    "    shallow_NNF.reset_parameters()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deep NNF Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf training function\n",
    "def train_deep_nnf(x_train, y_train, i):\n",
    "    start_time_deep_nnf = time.time()\n",
    "    print(f'\\nDeep NNF Training & Results for model {i+1}:')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = deep_NNF(x_train)[0]\n",
    "        loss_deep_nnf = deep_NNF_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_deep_nnf.item()}')\n",
    "        deep_NNF_optimizer.zero_grad()\n",
    "        loss_deep_nnf.backward()\n",
    "        deep_NNF_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_deep_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep nnf\n",
    "for i in range(24):\n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    # x_test = data_process(date_slicer(df, '2014-07-01', 30, i))\n",
    "    # y_test = data_process(date_slicer(df_sp, '2014-07-01', 30, i))\n",
    "    train_deep_nnf(x_train, y_train, i)\n",
    "    valid_fun(x_valid, y_valid, i, deep_NNF)\n",
    "    # test computation\n",
    "    deep_NNF.reset_parameters()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1/N Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fun_equal_w_model(x_valid, y_valid, i):\n",
    "    x = daily_change(date_slicer(df_change, '2017-07-01', 6, i))\n",
    "    y = daily_change(date_slicer(df_sp_change, '2017-07-01', 6, i))\n",
    "    weights = equal_w_model(x_valid).performance()[1]\n",
    "    valid_rmse = RMSE(x, y, weights)\n",
    "    return print(f'Validation RMSE: {valid_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sag(x_valid, i):\n",
    "    x = daily_return(date_slicer(df_change, '2017-07-01', 6, i))\n",
    "    y = daily_return(date_slicer(df_sp_change, '2017-07-01', 6, i))\n",
    "    weights = equal_w_model(x_valid).performance()[1]\n",
    "    valid_x_mean = MEAN(x, weights)\n",
    "    print(f'Validation x Mean: {valid_x_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.0013752466607634818\n",
      "Validation x Mean: 1.0008795683923595\n",
      "Validation RMSE: 0.0014103582761839522\n",
      "Validation x Mean: 1.0011205179773053\n",
      "Validation RMSE: 0.00161101492926301\n",
      "Validation x Mean: 1.0008484149042147\n",
      "Validation RMSE: 0.00178815568268382\n",
      "Validation x Mean: 1.0005543154597492\n",
      "Validation RMSE: 0.0017533218637125797\n",
      "Validation x Mean: 1.0004703068568601\n",
      "Validation RMSE: 0.0017002638599400465\n",
      "Validation x Mean: 1.0003007440577854\n",
      "Validation RMSE: 0.0016838896697022906\n",
      "Validation x Mean: 1.000223979363228\n",
      "Validation RMSE: 0.0019078407523448037\n",
      "Validation x Mean: 1.0001866853162422\n",
      "Validation RMSE: 0.0017918743187162148\n",
      "Validation x Mean: 1.0007247171178195\n",
      "Validation RMSE: 0.0017472761704575702\n",
      "Validation x Mean: 1.0008824136684178\n",
      "Validation RMSE: 0.002080505442953261\n",
      "Validation x Mean: 1.0001083627465603\n",
      "Validation RMSE: 0.00228250529001297\n",
      "Validation x Mean: 1.0001620095538837\n",
      "Validation RMSE: 0.002378854806423318\n",
      "Validation x Mean: 0.9993495431539628\n",
      "Validation RMSE: 0.0023376364047417086\n",
      "Validation x Mean: 0.9999067253622472\n",
      "Validation RMSE: 0.002388129123328023\n",
      "Validation x Mean: 1.0000040026106212\n",
      "Validation RMSE: 0.0023085543362458107\n",
      "Validation x Mean: 1.0000718893313152\n",
      "Validation RMSE: 0.002032437718144319\n",
      "Validation x Mean: 1.000830591240973\n",
      "Validation RMSE: 0.0018717109499381298\n",
      "Validation x Mean: 1.0000411226733432\n",
      "Validation RMSE: 0.0019686564797122682\n",
      "Validation x Mean: 1.001545688626488\n",
      "Validation RMSE: 0.0018238046048378409\n",
      "Validation x Mean: 1.0008391489528465\n",
      "Validation RMSE: 0.0018329033576296974\n",
      "Validation x Mean: 1.0002709492409667\n",
      "Validation RMSE: 0.0019462210070632896\n",
      "Validation x Mean: 1.0003969000958595\n",
      "Validation RMSE: 0.0019529162145969603\n",
      "Validation x Mean: 1.000392883753487\n",
      "Validation RMSE: 0.0017551968016899662\n",
      "Validation x Mean: 1.0010811798288035\n"
     ]
    }
   ],
   "source": [
    "for i in range(24):\n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    # x_test = data_process(date_slicer(df, '2014-07-01', 30, i))\n",
    "    # y_test = data_process(date_slicer(df_sp, '2014-07-01', 30, i))\n",
    "    valid_fun_equal_w_model(x_valid, y_valid, i)\n",
    "    sag(x_valid, i)\n",
    "    # test computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_plot(hist_model):   \n",
    "#     plt.plot(hist_model, color='r')\n",
    "#     plt.title(f'Loss Plot')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Loss')\n",
    "#     return plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72a5606bcafec1593511b6d198bb0982fb8ea54acb1913d581966686ae52246b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
