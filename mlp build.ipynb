{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta as rd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks data csv read\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s&p data csv read\n",
    "df_sp = pd.read_csv('sp500.csv')\n",
    "df_sp = df_sp.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(df):\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    df = df.cumprod()\n",
    "    df = df - 1\n",
    "    df = df.iloc[-1,:]\n",
    "    df = df.to_numpy()\n",
    "    df = torch.from_numpy(df).type(torch.Tensor)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf biuld\n",
    "class shallow_NNF(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_classes):\n",
    "        super(shallow_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.softmax(self.fc2(out))\n",
    "        out = sum(out * x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf build\n",
    "class deep_NNF(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size1, hidden_size2, hidden_size3,\n",
    "                 hidden_size4, hidden_size5, num_classes, dropout_p = 0.2):\n",
    "        super(deep_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.fc5 = nn.Linear(hidden_size4, hidden_size5)\n",
    "        self.fc6 = nn.Linear(hidden_size5, num_classes)\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc4(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc5(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.softmax(self.fc6(out))\n",
    "        out = sum(out * x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/N model build\n",
    "class equal_w_model():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.performance()\n",
    "        \n",
    "    def performance(self):\n",
    "        self.df = np.array(self.df)\n",
    "        weights = np.ones((len(self.df), 1)) * (1/len(self.df))\n",
    "        out = sum(np.multiply(weights, self.df.reshape(-1,1)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# shallow_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size = 471\n",
    "num_classes = 471\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf tune\n",
    "shallow_NNF = shallow_NNF(input_dim=input_dim, hidden_size=hidden_size, num_classes=num_classes)\n",
    "loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(shallow_NNF.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# deep_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size1 = 471\n",
    "hidden_size2 = 471\n",
    "hidden_size3 = 471\n",
    "hidden_size4 = 471\n",
    "hidden_size5 = 471\n",
    "num_classes = 471\n",
    "lr = 0.001\n",
    "dropout_p = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_NNF = deep_NNF(input_dim=input_dim, hidden_size1=hidden_size1, hidden_size2=hidden_size1,\n",
    "#                     hidden_size3=hidden_size3, hidden_size4=hidden_size4, hidden_size5=hidden_size5,\n",
    "#                     dropout_p=dropout_p, num_classes=num_classes)\n",
    "# loss_fun = torch.nn.L1Loss()\n",
    "# optimizer = torch.optim.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test run models\n",
    "# hist_shallow_nnf = np.zeros(num_epochs)\n",
    "# start_time_shallow_nnf = time.time()\n",
    "\n",
    "# print(f'Shallow NNF Training & Results:')\n",
    "# for epoch in range(num_epochs):\n",
    "#     y_train_pred = shallow_NNF(x_train)\n",
    "#     loss_shallow_nnf = loss_fun(y_train_pred, y_train)\n",
    "#     print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_shallow_nnf.item()}')\n",
    "#     hist_shallow_nnf[epoch] = loss_shallow_nnf.item()\n",
    "#     optimizer.zero_grad()\n",
    "#     loss_shallow_nnf.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# training_time = format(time.time()-start_time_shallow_nnf, '0.2f')\n",
    "# print(f'Sallow NNF Training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_shallow_nnf(x_train, y_train, i):\n",
    "    start_time_shallow_nnf = time.time()\n",
    "    print(f'\\nShallow NNF Training & Results for model {i+1}:')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = shallow_NNF(x_train)\n",
    "        loss_shallow_nnf = loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_shallow_nnf.item()}')\n",
    "        optimizer.zero_grad()\n",
    "        loss_shallow_nnf.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_shallow_nnf, '0.2f')\n",
    "    print(f'Sallow NNF Training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_slicer(df, start, duration, rebalancing_period=0):\n",
    "    start = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=rebalancing_period))\n",
    "    end = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=duration) - rd(days=1))\n",
    "    return df.loc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shallow NNF Training & Results for model 1:\n",
      "Epoch 1 of 100 | MSE: 0.022616053000092506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamidrezarahimzadeh/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 of 100 | MSE: 1.0097603109215925e-07\n",
      "Sallow NNF Training time: 0.89\n",
      "\n",
      "Shallow NNF Training & Results for model 2:\n",
      "Epoch 1 of 100 | MSE: 0.002051469637081027\n",
      "Epoch 100 of 100 | MSE: 3.1492044527681173e-09\n",
      "Sallow NNF Training time: 0.69\n",
      "\n",
      "Shallow NNF Training & Results for model 3:\n",
      "Epoch 1 of 100 | MSE: 9.728913710205234e-07\n",
      "Epoch 100 of 100 | MSE: 9.606537787476555e-12\n",
      "Sallow NNF Training time: 1.12\n",
      "\n",
      "Shallow NNF Training & Results for model 4:\n",
      "Epoch 1 of 100 | MSE: 0.0004058948252350092\n",
      "Epoch 100 of 100 | MSE: 6.630216375924647e-10\n",
      "Sallow NNF Training time: 0.76\n",
      "\n",
      "Shallow NNF Training & Results for model 5:\n",
      "Epoch 1 of 100 | MSE: 0.0010928709525614977\n",
      "Epoch 100 of 100 | MSE: 1.1026781265854879e-08\n",
      "Sallow NNF Training time: 0.96\n",
      "\n",
      "Shallow NNF Training & Results for model 6:\n",
      "Epoch 1 of 100 | MSE: 0.003810642287135124\n",
      "Epoch 100 of 100 | MSE: 1.8738399720774623e-09\n",
      "Sallow NNF Training time: 0.93\n",
      "\n",
      "Shallow NNF Training & Results for model 7:\n",
      "Epoch 1 of 100 | MSE: 1.0063633453682996e-05\n",
      "Epoch 100 of 100 | MSE: 2.765467854715098e-10\n",
      "Sallow NNF Training time: 0.83\n",
      "\n",
      "Shallow NNF Training & Results for model 8:\n",
      "Epoch 1 of 100 | MSE: 0.00014316958549898118\n",
      "Epoch 100 of 100 | MSE: 3.688999328232967e-09\n",
      "Sallow NNF Training time: 0.77\n",
      "\n",
      "Shallow NNF Training & Results for model 9:\n",
      "Epoch 1 of 100 | MSE: 3.918695074389689e-05\n",
      "Epoch 100 of 100 | MSE: 2.6623703242023566e-10\n",
      "Sallow NNF Training time: 0.68\n",
      "\n",
      "Shallow NNF Training & Results for model 10:\n",
      "Epoch 1 of 100 | MSE: 9.306368883699179e-05\n",
      "Epoch 100 of 100 | MSE: 7.202241025794365e-10\n",
      "Sallow NNF Training time: 0.66\n",
      "\n",
      "Shallow NNF Training & Results for model 11:\n",
      "Epoch 1 of 100 | MSE: 1.389255794492783e-05\n",
      "Epoch 100 of 100 | MSE: 2.9672619916709664e-10\n",
      "Sallow NNF Training time: 0.65\n",
      "\n",
      "Shallow NNF Training & Results for model 12:\n",
      "Epoch 1 of 100 | MSE: 9.235089964931831e-05\n",
      "Epoch 100 of 100 | MSE: 3.3921665476555063e-10\n",
      "Sallow NNF Training time: 0.69\n",
      "\n",
      "Shallow NNF Training & Results for model 13:\n",
      "Epoch 1 of 100 | MSE: 6.774321082048118e-05\n",
      "Epoch 100 of 100 | MSE: 4.070779269227387e-10\n",
      "Sallow NNF Training time: 1.01\n",
      "\n",
      "Shallow NNF Training & Results for model 14:\n",
      "Epoch 1 of 100 | MSE: 0.0002422861725790426\n",
      "Epoch 100 of 100 | MSE: 2.339576532506271e-09\n",
      "Sallow NNF Training time: 0.86\n",
      "\n",
      "Shallow NNF Training & Results for model 15:\n",
      "Epoch 1 of 100 | MSE: 0.0016450876137241721\n",
      "Epoch 100 of 100 | MSE: 1.1101555230652593e-09\n",
      "Sallow NNF Training time: 0.68\n",
      "\n",
      "Shallow NNF Training & Results for model 16:\n",
      "Epoch 1 of 100 | MSE: 0.0051764920353889465\n",
      "Epoch 100 of 100 | MSE: 7.993605777301127e-11\n",
      "Sallow NNF Training time: 0.66\n",
      "\n",
      "Shallow NNF Training & Results for model 17:\n",
      "Epoch 1 of 100 | MSE: 0.001122708315961063\n",
      "Epoch 100 of 100 | MSE: 8.546411578436164e-09\n",
      "Sallow NNF Training time: 0.67\n",
      "\n",
      "Shallow NNF Training & Results for model 18:\n",
      "Epoch 1 of 100 | MSE: 0.0003443273017182946\n",
      "Epoch 100 of 100 | MSE: 8.952980579124414e-10\n",
      "Sallow NNF Training time: 0.67\n",
      "\n",
      "Shallow NNF Training & Results for model 19:\n",
      "Epoch 1 of 100 | MSE: 0.002219853922724724\n",
      "Epoch 100 of 100 | MSE: 5.671666691853261e-09\n",
      "Sallow NNF Training time: 0.67\n",
      "\n",
      "Shallow NNF Training & Results for model 20:\n",
      "Epoch 1 of 100 | MSE: 0.04941708967089653\n",
      "Epoch 100 of 100 | MSE: 1.2811094407538803e-09\n",
      "Sallow NNF Training time: 0.68\n",
      "\n",
      "Shallow NNF Training & Results for model 21:\n",
      "Epoch 1 of 100 | MSE: 0.00030658015748485923\n",
      "Epoch 100 of 100 | MSE: 3.3427483003833913e-09\n",
      "Sallow NNF Training time: 0.68\n",
      "\n",
      "Shallow NNF Training & Results for model 22:\n",
      "Epoch 1 of 100 | MSE: 8.732558853807859e-07\n",
      "Epoch 100 of 100 | MSE: 5.2660098504020425e-12\n",
      "Sallow NNF Training time: 0.68\n",
      "\n",
      "Shallow NNF Training & Results for model 23:\n",
      "Epoch 1 of 100 | MSE: 2.1817197193740867e-05\n",
      "Epoch 100 of 100 | MSE: 3.525180147789797e-12\n",
      "Sallow NNF Training time: 0.71\n",
      "\n",
      "Shallow NNF Training & Results for model 24:\n",
      "Epoch 1 of 100 | MSE: 5.7253451814176515e-05\n",
      "Epoch 100 of 100 | MSE: 1.0880185641326534e-12\n",
      "Sallow NNF Training time: 0.71\n"
     ]
    }
   ],
   "source": [
    "#shallow nnf\n",
    "for i in range(24):\n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 30, i))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 30, i))\n",
    "    x_valid = data_process(date_slicer(df, '2017-01-01', 12, i))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-01-01', 12, i))\n",
    "    # x_test = data_process(date_slicer(df, '2014-07-01', 30, i))\n",
    "    # y_test = data_process(date_slicer(df_sp, '2014-07-01', 30, i))\n",
    "    train_shallow_nnf(x_train, y_train, i)\n",
    "    # validation computation\n",
    "    # test computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_plot(hist_model):   \n",
    "#     plt.plot(hist_model, color='r')\n",
    "#     plt.title(f'Loss Plot')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Loss')\n",
    "#     return plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72a5606bcafec1593511b6d198bb0982fb8ea54acb1913d581966686ae52246b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
