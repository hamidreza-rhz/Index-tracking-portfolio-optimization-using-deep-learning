{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta as rd\n",
    "import time\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks data csv read\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df.set_index('Date')\n",
    "\n",
    "# s&p data csv read\n",
    "df_sp = pd.read_csv('sp500.csv')\n",
    "df_sp = df_sp.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_slicer(df, start, duration, rebalancing_period=0):\n",
    "    '''\n",
    "    this function is used to slice out specific section of the data\n",
    "    '''\n",
    "    start = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=rebalancing_period))\n",
    "    end = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=duration) - rd(days=1))\n",
    "    return df.loc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(df):\n",
    "    '''\n",
    "    this function gets the dataframe as input, processes it, and ouputs the cumulative change of the stocks\n",
    "    that is used as input for training the model.\n",
    "    '''\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    df = df.cumprod()\n",
    "    df = df - 1\n",
    "    df = df.iloc[-1,:]\n",
    "    df = df.to_numpy()\n",
    "    df = torch.from_numpy(df).type(torch.Tensor)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_change(df):\n",
    "    '''\n",
    "    this function calculate the daily change of stocks included in the dataframe.\n",
    "    '''\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_return(df):\n",
    "    '''\n",
    "    this function calculate the daily return of stocks included in the dataframe, note that \n",
    "    daily return is equal to daily change + 1\n",
    "    '''\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf biuld\n",
    "class shallow_NNF(nn.Module):\n",
    "    '''\n",
    "    this class is used to train the data with Shallow NNF model, consisted of 2 fully connected layers, \n",
    "    a relU activation function in between and a softmax layer output that is translated into stock weights in portfolio.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_size, num_classes):\n",
    "        super(shallow_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size) # fully connected layer\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # fully connected layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.softmax(self.fc2(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf build\n",
    "class deep_NNF(nn.Module):\n",
    "    '''\n",
    "    this class is used to train the data with Deep NNF model, consisted of 6 fully connected layers, \n",
    "    relU activation functions in between and a softmax layer output that is translated into stock weights in portfolio.\n",
    "    dropout is also included in deep NNF model.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_size1, hidden_size2, hidden_size3,\n",
    "                 hidden_size4, hidden_size5, num_classes, dropout_p = 0.2):\n",
    "        super(deep_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size1) # fully connected layer\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2) # fully connected layer\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3) # fully connected layer\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4) # fully connected layer\n",
    "        self.fc5 = nn.Linear(hidden_size4, hidden_size5) # fully connected layer\n",
    "        self.fc6 = nn.Linear(hidden_size5, num_classes) # fully connected layer\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        self.fc3.reset_parameters()\n",
    "        self.fc4.reset_parameters()\n",
    "        self.fc5.reset_parameters()\n",
    "        self.fc6.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc4(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc5(out))\n",
    "        out = self.softmax(self.fc6(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/N model build\n",
    "class equal_w_model():\n",
    "    '''\n",
    "    this class is used to construct a portfolio with equal weights.\n",
    "    '''\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.performance()\n",
    "        \n",
    "    def performance(self):\n",
    "        self.df = np.array(self.df)\n",
    "        weights = np.ones((len(self.df), 1)) * (1/len(self.df))\n",
    "        cumulative_change = sum(np.multiply(weights, self.df.reshape(-1,1)))\n",
    "        return cumulative_change, weights.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebalancing period = one or three months\n",
    "rbp = 1\n",
    "\n",
    "# epochs\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size = 471\n",
    "num_classes = 471\n",
    "lr = 1e-3 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf tune\n",
    "'''\n",
    "loss function is set to MSE and Adam optimizer is used in this model.\n",
    "'''\n",
    "shallow_NNF = shallow_NNF(input_dim=input_dim, hidden_size=hidden_size, num_classes=num_classes)\n",
    "shallow_NNF_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "shallow_NNF_optimizer = torch.optim.Adam(shallow_NNF.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size1 = 471\n",
    "hidden_size2 = 471\n",
    "hidden_size3 = 471\n",
    "hidden_size4 = 471\n",
    "hidden_size5 = 471\n",
    "num_classes = 471\n",
    "lr = 1e-3 # learning rate\n",
    "# probability of a neuron being shutdown that shuffles every epoch minimizing the overfit phenomenon\n",
    "dropout_p = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf tune\n",
    "'''\n",
    "like in shallow NNF, loss function is set to MSE and Adam optimizer is used.\n",
    "'''\n",
    "deep_NNF = deep_NNF(input_dim=input_dim, hidden_size1=hidden_size1, hidden_size2=hidden_size2, \n",
    "                    hidden_size3=hidden_size3, hidden_size4=hidden_size4, hidden_size5=hidden_size5,\n",
    "                    num_classes=num_classes)\n",
    "deep_NNF_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "deep_NNF_optimizer = torch.optim.Adam(deep_NNF.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "def RMSE(x, y, weights):\n",
    "    '''\n",
    "    this function calculates the root mean squere error of constructed portfollio and benchmark index \n",
    "    that is used for evaluating trained models.\n",
    "    '''\n",
    "    temp = 0\n",
    "    for i in range(len(x)):\n",
    "        temp += (sum(x.iloc[i] * weights) - y.iloc[i]) ** 2\n",
    "    return math.sqrt(temp/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEAN\n",
    "def MEAN(x, weights):\n",
    "    '''\n",
    "    this function calculates the mean return of the constructed portfolio during the given period.\n",
    "    '''\n",
    "    temp = []\n",
    "    for i in range(len(x)):\n",
    "        temp.append(sum(x.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility\n",
    "def VOL(x, weights):\n",
    "    '''\n",
    "    this function calculates the volatility of the constructed portfolio during the given period.\n",
    "    '''\n",
    "    temp = []\n",
    "    for i in range(len(x)):\n",
    "        temp.append(sum(x.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_return(df, x_test, model, i, temp):   \n",
    "    '''\n",
    "    this function outputs the cumulative return of the portfolio test dataset of the given dataframe\n",
    "    ''' \n",
    "    x_return = date_slicer(df, '2018-01-01', 1, i)\n",
    "    x_return =  x_return.pct_change()\n",
    "    x_return =  x_return.tail(-1)\n",
    "    x_return =  x_return + 1\n",
    "    x_return =  x_return.cumprod()\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_test).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_test)[1].detach())\n",
    "    \n",
    "    for i in range(len(x_return)):\n",
    "        temp.append(sum(x_return.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_return(df_sp, i, temp):\n",
    "    '''\n",
    "    this function outputs the cumulative return of the benchmark index test dataset of the given dataframe\n",
    "    '''\n",
    "    y_return = date_slicer(df_sp, '2018-01-01', 1, i)\n",
    "    y_return = y_return.pct_change()\n",
    "    y_return = y_return.tail(-1)\n",
    "    y_return = y_return + 1\n",
    "    y_return = y_return.cumprod()\n",
    "    \n",
    "    for i in range(len(y_return)):\n",
    "        temp.append(sum(y_return.iloc[i]))\n",
    "    temp = np.array(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fun(x_valid, i, model):\n",
    "    '''\n",
    "    this function gets validation dataset, model and rebalaning period as input, then outputs the RMSE of given dataset.\n",
    "    '''\n",
    "    x_change = daily_change(date_slicer(df, '2017-07-01', 6, i))\n",
    "    y_change = daily_change(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    # x_return = daily_return(date_slicer(df, '2017-07-01', 6, i))\n",
    "    # y_return = daily_return(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_valid).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_valid)[1].detach())\n",
    "    \n",
    "    valid_rmse = RMSE(x_change, y_change, weights)\n",
    "    # valid_mean = MEAN(x_return, weights)\n",
    "    # valid_vol  = VOL(x_return, weights)\n",
    "    \n",
    "    print(f'Validation RMSE: {valid_rmse}')\n",
    "    # print(f'Validation MEAN: {valid_mean}')\n",
    "    # print(f'Validation VOL: {valid_vol}')\n",
    "    \n",
    "    return valid_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fun(x_test, i, model):\n",
    "    '''\n",
    "    this function gets test dataset, model and rebalaning period as input, then outputs the RMSE, Mean and volatility \n",
    "    of the given dataset.\n",
    "    '''\n",
    "    x_change = daily_change(date_slicer(df, '2018-01-01', 1, i))\n",
    "    y_change = daily_change(date_slicer(df_sp, '2018-01-01', 1, i))\n",
    "    x_return = daily_return(date_slicer(df, '2018-01-01', 1, i))\n",
    "    y_return = daily_return(date_slicer(df_sp, '2018-01-01', 1, i))\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_test).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_test)[1].detach())\n",
    "    \n",
    "    test_rmse = RMSE(x_change, y_change, weights)\n",
    "    test_mean = MEAN(x_return, weights)\n",
    "    test_vol  = VOL(x_return, weights)\n",
    "    test_dic = {'RMSE': test_rmse, 'MEAN': test_mean, 'VOL': test_vol} # a dictionary for storing the results\n",
    "    \n",
    "    print(f'Test RMSE: {test_rmse}')\n",
    "    print(f'Test MEAN: {test_mean}')\n",
    "    print(f'Test VOL: {test_vol}')\n",
    "    \n",
    "    return test_dic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deep NNF Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf training function\n",
    "'''\n",
    "this function is used to train the model using x_train & y_train given to it, printing MSE of trained model in first and last\n",
    " epich and also printing train time of the model\n",
    "'''\n",
    "def train_deep_nnf(x_train, y_train, i):\n",
    "    start_time_deep_nnf = time.time()\n",
    "    print(f'\\nDeep NNF Training & Results for model {(i/rbp)+1}:')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = deep_NNF(x_train)[0]\n",
    "        loss_deep_nnf = deep_NNF_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_deep_nnf.item()}')\n",
    "        deep_NNF_optimizer.zero_grad()\n",
    "        loss_deep_nnf.backward()\n",
    "        deep_NNF_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_deep_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deep NNF Training & Results for model 1.0:\n",
      "Epoch 1 of 10 | MSE: 0.04568424075841904\n",
      "Epoch 10 of 10 | MSE: 0.0004861154593527317\n",
      "Training time: 0.19\n",
      "Validation RMSE: 0.0014704474061788399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamidrezarahimzadeh/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning:\n",
      "\n",
      "Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.0014339130477000297\n",
      "Test MEAN: 1.001897959974057\n",
      "Test VOL: 0.005360620568554472\n",
      "\n",
      "Deep NNF Training & Results for model 2.0:\n",
      "Epoch 1 of 10 | MSE: 0.05325326323509216\n",
      "Epoch 10 of 10 | MSE: 0.0009558473248034716\n",
      "Training time: 0.09\n",
      "Validation RMSE: 0.001614403839352181\n",
      "Test RMSE: 0.0022678555532461286\n",
      "Test MEAN: 0.9979034756115183\n",
      "Test VOL: 0.015437859250082588\n",
      "\n",
      "Deep NNF Training & Results for model 3.0:\n",
      "Epoch 1 of 10 | MSE: 0.04559122398495674\n",
      "Epoch 10 of 10 | MSE: 0.012366250157356262\n",
      "Training time: 0.10\n",
      "Validation RMSE: 0.001753891656552477\n",
      "Test RMSE: 0.002210022824702207\n",
      "Test MEAN: 1.0002369551915147\n",
      "Test VOL: 0.010991512476734753\n",
      "\n",
      "Deep NNF Training & Results for model 4.0:\n",
      "Epoch 1 of 10 | MSE: 0.05981092154979706\n",
      "Epoch 10 of 10 | MSE: 0.0026019408833235502\n",
      "Training time: 0.13\n",
      "Validation RMSE: 0.0019469596327262688\n",
      "Test RMSE: 0.0017350709258675348\n",
      "Test MEAN: 1.001311298252053\n",
      "Test VOL: 0.008721380514640905\n",
      "\n",
      "Deep NNF Training & Results for model 5.0:\n",
      "Epoch 1 of 10 | MSE: 0.047414302825927734\n",
      "Epoch 10 of 10 | MSE: 0.012151496484875679\n",
      "Training time: 0.14\n",
      "Validation RMSE: 0.0019317554693184544\n",
      "Test RMSE: 0.0013067331929953218\n",
      "Test MEAN: 1.0007232244282542\n",
      "Test VOL: 0.006336228840401733\n",
      "\n",
      "Deep NNF Training & Results for model 6.0:\n",
      "Epoch 1 of 10 | MSE: 0.04966364800930023\n",
      "Epoch 10 of 10 | MSE: 0.00861411727964878\n",
      "Training time: 0.11\n",
      "Validation RMSE: 0.0018603799831452923\n",
      "Test RMSE: 0.001292487992232784\n",
      "Test MEAN: 1.0001699385456964\n",
      "Test VOL: 0.0046940208290342745\n",
      "\n",
      "Deep NNF Training & Results for model 7.0:\n",
      "Epoch 1 of 10 | MSE: 0.03862863779067993\n",
      "Epoch 10 of 10 | MSE: 0.01204619463533163\n",
      "Training time: 0.10\n",
      "Validation RMSE: 0.0018370169767997473\n",
      "Test RMSE: 0.002707892081375866\n",
      "Test MEAN: 1.0016258317167455\n",
      "Test VOL: 0.004890869385893525\n",
      "\n",
      "Deep NNF Training & Results for model 8.0:\n",
      "Epoch 1 of 10 | MSE: 0.03760434687137604\n",
      "Epoch 10 of 10 | MSE: 0.011093810200691223\n",
      "Training time: 0.10\n",
      "Validation RMSE: 0.002016736173839679\n",
      "Test RMSE: 0.0012740038009504539\n",
      "Test MEAN: 1.0012682778247333\n",
      "Test VOL: 0.004681435389172241\n",
      "\n",
      "Deep NNF Training & Results for model 9.0:\n",
      "Epoch 1 of 10 | MSE: 0.027175728231668472\n",
      "Epoch 10 of 10 | MSE: 0.0035067666321992874\n",
      "Training time: 0.11\n",
      "Validation RMSE: 0.0019136488175085817\n",
      "Test RMSE: 0.0019546440992579068\n",
      "Test MEAN: 1.0001829132339024\n",
      "Test VOL: 0.003522742146021295\n",
      "\n",
      "Deep NNF Training & Results for model 10.0:\n",
      "Epoch 1 of 10 | MSE: 0.03157148137688637\n",
      "Epoch 10 of 10 | MSE: 0.008728315122425556\n",
      "Training time: 0.11\n",
      "Validation RMSE: 0.001891998013233252\n",
      "Test RMSE: 0.003247041169039016\n",
      "Test MEAN: 0.9968497920686462\n",
      "Test VOL: 0.012548175033091928\n",
      "\n",
      "Deep NNF Training & Results for model 11.0:\n",
      "Epoch 1 of 10 | MSE: 0.035534851253032684\n",
      "Epoch 10 of 10 | MSE: 0.022669970989227295\n",
      "Training time: 0.11\n",
      "Validation RMSE: 0.002120105152443795\n",
      "Test RMSE: 0.0025562258490840575\n",
      "Test MEAN: 1.0008388752586819\n",
      "Test VOL: 0.009735161449448563\n",
      "\n",
      "Deep NNF Training & Results for model 12.0:\n",
      "Epoch 1 of 10 | MSE: 0.03479762002825737\n",
      "Epoch 10 of 10 | MSE: 0.009942753240466118\n",
      "Training time: 0.11\n",
      "Validation RMSE: 0.002397202049988691\n",
      "Test RMSE: 0.0021844720395353756\n",
      "Test MEAN: 0.9939199302384307\n",
      "Test VOL: 0.01702771406340498\n",
      "\n",
      "Deep NNF Training & Results for model 13.0:\n",
      "Epoch 1 of 10 | MSE: 0.03623449429869652\n",
      "Epoch 10 of 10 | MSE: 0.018073754385113716\n",
      "Training time: 0.11\n",
      "Validation RMSE: 0.002455983141331185\n",
      "Test RMSE: 0.002688634592678351\n",
      "Test MEAN: 1.00476735747362\n",
      "Test VOL: 0.010318205579448908\n",
      "\n",
      "Deep NNF Training & Results for model 14.0:\n",
      "Epoch 1 of 10 | MSE: 0.03350094333291054\n",
      "Epoch 10 of 10 | MSE: 0.0011869664303958416\n",
      "Training time: 0.11\n",
      "Validation RMSE: 0.002433075666628974\n",
      "Test RMSE: 0.001434234955342607\n",
      "Test MEAN: 1.0020012250486694\n",
      "Test VOL: 0.004519648126068022\n",
      "\n",
      "Deep NNF Training & Results for model 15.0:\n",
      "Epoch 1 of 10 | MSE: 0.036006879061460495\n",
      "Epoch 10 of 10 | MSE: 0.0014055120991542935\n",
      "Training time: 0.10\n",
      "Validation RMSE: 0.0024791503311546214\n",
      "Test RMSE: 0.0014359840780332452\n",
      "Test MEAN: 1.000257930213891\n",
      "Test VOL: 0.00758566067192739\n",
      "\n",
      "Deep NNF Training & Results for model 16.0:\n",
      "Epoch 1 of 10 | MSE: 0.03966609761118889\n",
      "Epoch 10 of 10 | MSE: 0.0005591204972006381\n",
      "Training time: 0.11\n",
      "Validation RMSE: 0.0023834570489086084\n",
      "Test RMSE: 0.001985319186290912\n",
      "Test MEAN: 1.0012004647989117\n",
      "Test VOL: 0.004410925228467409\n",
      "\n",
      "Deep NNF Training & Results for model 17.0:\n",
      "Epoch 1 of 10 | MSE: 0.023055603727698326\n",
      "Epoch 10 of 10 | MSE: 0.019204439595341682\n",
      "Training time: 0.11\n",
      "Validation RMSE: 0.002053325756234444\n",
      "Test RMSE: 0.0014840444344624867\n",
      "Test MEAN: 0.9972313607555842\n",
      "Test VOL: 0.008738476492538323\n",
      "\n",
      "Deep NNF Training & Results for model 18.0:\n",
      "Epoch 1 of 10 | MSE: 0.02334744669497013\n",
      "Epoch 10 of 10 | MSE: 0.003266899846494198\n",
      "Training time: 0.11\n",
      "Validation RMSE: 0.0019060062560832026\n",
      "Test RMSE: 0.001769853443753028\n",
      "Test MEAN: 1.0036269100206254\n",
      "Test VOL: 0.006663551160972144\n",
      "\n",
      "Deep NNF Training & Results for model 19.0:\n",
      "Epoch 1 of 10 | MSE: 0.020416177809238434\n",
      "Epoch 10 of 10 | MSE: 0.010903139598667622\n",
      "Training time: 0.12\n",
      "Validation RMSE: 0.0020768192292191083\n",
      "Test RMSE: 0.0019334743532721207\n",
      "Test MEAN: 1.000261289106973\n",
      "Test VOL: 0.00520716311043468\n",
      "\n",
      "Deep NNF Training & Results for model 20.0:\n",
      "Epoch 1 of 10 | MSE: 0.04298492148518562\n",
      "Epoch 10 of 10 | MSE: 0.018837638199329376\n",
      "Training time: 0.16\n",
      "Validation RMSE: 0.0018599368652241\n",
      "Test RMSE: 0.0013792315130054984\n",
      "Test MEAN: 0.9993156476164881\n",
      "Test VOL: 0.014246702900298525\n",
      "\n",
      "Deep NNF Training & Results for model 21.0:\n",
      "Epoch 1 of 10 | MSE: 0.04193160682916641\n",
      "Epoch 10 of 10 | MSE: 0.0024612070992588997\n",
      "Training time: 0.26\n",
      "Validation RMSE: 0.0018838257309757365\n",
      "Test RMSE: 0.002266358752215184\n",
      "Test MEAN: 1.0021417406433553\n",
      "Test VOL: 0.005312199900048107\n",
      "\n",
      "Deep NNF Training & Results for model 22.0:\n",
      "Epoch 1 of 10 | MSE: 0.02815515361726284\n",
      "Epoch 10 of 10 | MSE: 0.010101266205310822\n",
      "Training time: 0.17\n",
      "Validation RMSE: 0.0019828387541481135\n",
      "Test RMSE: 0.0020066651544066194\n",
      "Test MEAN: 1.0013283627731986\n",
      "Test VOL: 0.007893403927609698\n",
      "\n",
      "Deep NNF Training & Results for model 23.0:\n",
      "Epoch 1 of 10 | MSE: 0.026544926688075066\n",
      "Epoch 10 of 10 | MSE: 0.007414921186864376\n",
      "Training time: 0.27\n",
      "Validation RMSE: 0.00201956576256737\n",
      "Test RMSE: 0.0009193911167054321\n",
      "Test MEAN: 1.001104787103317\n",
      "Test VOL: 0.003415010255361769\n",
      "\n",
      "Deep NNF Training & Results for model 24.0:\n",
      "Epoch 1 of 10 | MSE: 0.017605246976017952\n",
      "Epoch 10 of 10 | MSE: 0.015093228779733181\n",
      "Training time: 0.21\n",
      "Validation RMSE: 0.001776064999703008\n",
      "Test RMSE: 0.0013302420692384283\n",
      "Test MEAN: 1.001702958468713\n",
      "Test VOL: 0.004500298347341532\n",
      "\n",
      "Min Valid RMSE is: 0.0014704474061788399 for model i = 1\n",
      "Selected Model Test Results are:\n",
      "RMSE = 0.0014339130477000297\n",
      "MEAN = 1.001897959974057\n",
      "VOL = 0.005360620568554472\n"
     ]
    }
   ],
   "source": [
    "# deep nnf\n",
    "'''\n",
    "in this cell,firstly, train, validation and test datasets are sliced in each loop. then deep NNf model gets trained and\n",
    "then best model will be chosen. Also RMSE, Mean and volatility of all models and then the best model is printed.\n",
    "'''\n",
    "deep_nnf_valid_rmse_list = []\n",
    "deep_nnf_test_results = []\n",
    "deep_nnf_test_plot = [] # storing the deep model test data return for plotting later on\n",
    "index_test_plot = [] # storing the index test data return for plotting later on\n",
    "\n",
    "for i in range(int(24/rbp)):\n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i*rbp))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i*rbp))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i*rbp))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i*rbp))\n",
    "    x_test = data_process(date_slicer(df, '2018-01-01', 1, i*rbp))\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i*rbp))\n",
    "    train_deep_nnf(x_train, y_train, i*rbp)\n",
    "    deep_nnf_valid_rmse_list.append(valid_fun(x_valid, i*rbp, deep_NNF))\n",
    "    deep_nnf_test_results.append(test_fun(x_test, i*rbp, deep_NNF))\n",
    "    portfolio_return(df, x_test, deep_NNF, i, deep_nnf_test_plot)\n",
    "    index_return(df_sp, i, index_test_plot)\n",
    "    deep_NNF.reset_parameters()\n",
    "\n",
    "print(f'\\nMin Valid RMSE is: {min(deep_nnf_valid_rmse_list)} for model i = {deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))+1}')\n",
    "print('Selected Model Test Results are:')\n",
    "print('RMSE =', deep_nnf_test_results[deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))]['RMSE'])\n",
    "print('MEAN =', deep_nnf_test_results[deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))]['MEAN'])\n",
    "print('VOL =', deep_nnf_test_results[deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))]['VOL'])\n",
    "\n",
    "deep_best_result_index = deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))\n",
    "deep_nnf_test_plot = np.array(deep_nnf_test_plot).reshape(-1,1)\n",
    "index_test_plot = np.array(index_test_plot).reshape(-1,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Shallow NNF Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf training function\n",
    "'''\n",
    "this function is used to train the model using x_train & y_train given to it, printing MSE of trained model in first and last\n",
    "epoch and also printing train time of the model\n",
    "'''\n",
    "def train_shallow_nnf(x_train, y_train, i):\n",
    "    start_time_shallow_nnf = time.time()\n",
    "    print(f'\\nShallow NNF Training & Results for model {(i/rbp)+1}:')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = shallow_NNF(x_train)[0]\n",
    "        loss_shallow_nnf = shallow_NNF_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_shallow_nnf.item()}')\n",
    "        shallow_NNF_optimizer.zero_grad()\n",
    "        loss_shallow_nnf.backward()\n",
    "        shallow_NNF_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_shallow_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shallow NNF Training & Results for model 1.0:\n",
      "Epoch 1 of 10 | MSE: 0.0436849407851696\n",
      "Epoch 10 of 10 | MSE: 0.00036164841731078923\n",
      "Training time: 0.10\n",
      "Validation RMSE: 0.0014737933842850386\n",
      "Test RMSE: 0.0014335311847101513\n",
      "Test MEAN: 1.0019152986298194\n",
      "Test VOL: 0.005343951406957578\n",
      "\n",
      "Shallow NNF Training & Results for model 2.0:\n",
      "Epoch 1 of 10 | MSE: 0.05439304560422897\n",
      "Epoch 10 of 10 | MSE: 0.007282321806997061\n",
      "Training time: 0.09\n",
      "Validation RMSE: 0.001547898324354915\n",
      "Test RMSE: 0.0022317113839817955\n",
      "Test MEAN: 0.9979281083421905\n",
      "Test VOL: 0.015463557649808425\n",
      "\n",
      "Shallow NNF Training & Results for model 3.0:\n",
      "Epoch 1 of 10 | MSE: 0.04768081381917\n",
      "Epoch 10 of 10 | MSE: 0.006824583746492863\n",
      "Training time: 0.09\n",
      "Validation RMSE: 0.0016995933456803746\n",
      "Test RMSE: 0.002137346894756386\n",
      "Test MEAN: 1.0002453144617798\n",
      "Test VOL: 0.011020957820500847\n",
      "\n",
      "Shallow NNF Training & Results for model 4.0:\n",
      "Epoch 1 of 10 | MSE: 0.05400165542960167\n",
      "Epoch 10 of 10 | MSE: 0.005171079188585281\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.0018989710868976995\n",
      "Test RMSE: 0.001657713111591062\n",
      "Test MEAN: 1.001314176049878\n",
      "Test VOL: 0.00877964006453161\n",
      "\n",
      "Shallow NNF Training & Results for model 5.0:\n",
      "Epoch 1 of 10 | MSE: 0.04853641986846924\n",
      "Epoch 10 of 10 | MSE: 0.005918553099036217\n",
      "Training time: 0.09\n",
      "Validation RMSE: 0.001832884293510195\n",
      "Test RMSE: 0.001259850106164033\n",
      "Test MEAN: 1.0007606891936016\n",
      "Test VOL: 0.0063033397547798435\n",
      "\n",
      "Shallow NNF Training & Results for model 6.0:\n",
      "Epoch 1 of 10 | MSE: 0.048433274030685425\n",
      "Epoch 10 of 10 | MSE: 0.004218555521219969\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.001779226534705212\n",
      "Test RMSE: 0.001222315934308333\n",
      "Test MEAN: 1.0001433440389387\n",
      "Test VOL: 0.004730604981145709\n",
      "\n",
      "Shallow NNF Training & Results for model 7.0:\n",
      "Epoch 1 of 10 | MSE: 0.036627236753702164\n",
      "Epoch 10 of 10 | MSE: 0.004757968243211508\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.001753310438740906\n",
      "Test RMSE: 0.002650698255452058\n",
      "Test MEAN: 1.0015942206655173\n",
      "Test VOL: 0.0049406213917767595\n",
      "\n",
      "Shallow NNF Training & Results for model 8.0:\n",
      "Epoch 1 of 10 | MSE: 0.04606238007545471\n",
      "Epoch 10 of 10 | MSE: 0.0017390346620231867\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.001969462931159503\n",
      "Test RMSE: 0.0012356714275751084\n",
      "Test MEAN: 1.0012846968965103\n",
      "Test VOL: 0.004692141137051907\n",
      "\n",
      "Shallow NNF Training & Results for model 9.0:\n",
      "Epoch 1 of 10 | MSE: 0.021471740677952766\n",
      "Epoch 10 of 10 | MSE: 0.0037125027738511562\n",
      "Training time: 0.09\n",
      "Validation RMSE: 0.0018938847801453298\n",
      "Test RMSE: 0.0019120666616891967\n",
      "Test MEAN: 1.000178587843853\n",
      "Test VOL: 0.0035166107158999854\n",
      "\n",
      "Shallow NNF Training & Results for model 10.0:\n",
      "Epoch 1 of 10 | MSE: 0.032276470214128494\n",
      "Epoch 10 of 10 | MSE: 0.003338285256177187\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.0018613959059279191\n",
      "Test RMSE: 0.0031211664480145455\n",
      "Test MEAN: 0.9968018887897323\n",
      "Test VOL: 0.01263539100758589\n",
      "\n",
      "Shallow NNF Training & Results for model 11.0:\n",
      "Epoch 1 of 10 | MSE: 0.030246581882238388\n",
      "Epoch 10 of 10 | MSE: 0.006111513823270798\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.0021201264930912032\n",
      "Test RMSE: 0.002529091959508468\n",
      "Test MEAN: 1.0008357086467579\n",
      "Test VOL: 0.009758621863452954\n",
      "\n",
      "Shallow NNF Training & Results for model 12.0:\n",
      "Epoch 1 of 10 | MSE: 0.03942202404141426\n",
      "Epoch 10 of 10 | MSE: 0.004462333396077156\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.002348462265415261\n",
      "Test RMSE: 0.0021419608194058397\n",
      "Test MEAN: 0.9939209483765834\n",
      "Test VOL: 0.0170741003615082\n",
      "\n",
      "Shallow NNF Training & Results for model 13.0:\n",
      "Epoch 1 of 10 | MSE: 0.03222070261836052\n",
      "Epoch 10 of 10 | MSE: 0.0016550241271033883\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0024108924398444647\n",
      "Test RMSE: 0.0026628547528691235\n",
      "Test MEAN: 1.004769744660503\n",
      "Test VOL: 0.010326929243166177\n",
      "\n",
      "Shallow NNF Training & Results for model 14.0:\n",
      "Epoch 1 of 10 | MSE: 0.0262470506131649\n",
      "Epoch 10 of 10 | MSE: 0.0008962060674093664\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.002371649867501517\n",
      "Test RMSE: 0.001415767937466248\n",
      "Test MEAN: 1.0020201086056677\n",
      "Test VOL: 0.004548794858702962\n",
      "\n",
      "Shallow NNF Training & Results for model 15.0:\n",
      "Epoch 1 of 10 | MSE: 0.041553497314453125\n",
      "Epoch 10 of 10 | MSE: 0.0006060092127881944\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.002416390817070506\n",
      "Test RMSE: 0.0014327287262125034\n",
      "Test MEAN: 1.0002600026251263\n",
      "Test VOL: 0.007621677856527881\n",
      "\n",
      "Shallow NNF Training & Results for model 16.0:\n",
      "Epoch 1 of 10 | MSE: 0.033275410532951355\n",
      "Epoch 10 of 10 | MSE: 0.0016002114862203598\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.002332132094270663\n",
      "Test RMSE: 0.0019667067416924587\n",
      "Test MEAN: 1.001199663724116\n",
      "Test VOL: 0.004400692214569102\n",
      "\n",
      "Shallow NNF Training & Results for model 17.0:\n",
      "Epoch 1 of 10 | MSE: 0.025174109265208244\n",
      "Epoch 10 of 10 | MSE: 0.004784214310348034\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0021147255294746044\n",
      "Test RMSE: 0.0014830339698757792\n",
      "Test MEAN: 0.9972266293776276\n",
      "Test VOL: 0.008728992020912965\n",
      "\n",
      "Shallow NNF Training & Results for model 18.0:\n",
      "Epoch 1 of 10 | MSE: 0.02452762983739376\n",
      "Epoch 10 of 10 | MSE: 0.003924562595784664\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0019003156230364593\n",
      "Test RMSE: 0.0017492287484195783\n",
      "Test MEAN: 1.0036366095344895\n",
      "Test VOL: 0.006671007274150354\n",
      "\n",
      "Shallow NNF Training & Results for model 19.0:\n",
      "Epoch 1 of 10 | MSE: 0.01994466781616211\n",
      "Epoch 10 of 10 | MSE: 0.004544912837445736\n",
      "Training time: 0.09\n",
      "Validation RMSE: 0.0020844017331894966\n",
      "Test RMSE: 0.0018981166302777176\n",
      "Test MEAN: 1.0002781510137773\n",
      "Test VOL: 0.005194603854158001\n",
      "\n",
      "Shallow NNF Training & Results for model 20.0:\n",
      "Epoch 1 of 10 | MSE: 0.04377543553709984\n",
      "Epoch 10 of 10 | MSE: 0.0010140264639630914\n",
      "Training time: 0.08\n",
      "Validation RMSE: 0.001875113091092904\n",
      "Test RMSE: 0.001376198522104921\n",
      "Test MEAN: 0.9993129658393446\n",
      "Test VOL: 0.01428397248367654\n",
      "\n",
      "Shallow NNF Training & Results for model 21.0:\n",
      "Epoch 1 of 10 | MSE: 0.041299715638160706\n",
      "Epoch 10 of 10 | MSE: 1.63657186931232e-05\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0018470374868212863\n",
      "Test RMSE: 0.002216525411144152\n",
      "Test MEAN: 1.0021158517256625\n",
      "Test VOL: 0.005371667020584716\n",
      "\n",
      "Shallow NNF Training & Results for model 22.0:\n",
      "Epoch 1 of 10 | MSE: 0.027588773518800735\n",
      "Epoch 10 of 10 | MSE: 0.0025181567762047052\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.001987487919330503\n",
      "Test RMSE: 0.002000355702900316\n",
      "Test MEAN: 1.0013328141513997\n",
      "Test VOL: 0.007913551805448983\n",
      "\n",
      "Shallow NNF Training & Results for model 23.0:\n",
      "Epoch 1 of 10 | MSE: 0.030715756118297577\n",
      "Epoch 10 of 10 | MSE: 1.592742250977608e-06\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0019846179052880413\n",
      "Test RMSE: 0.0009414566958898379\n",
      "Test MEAN: 1.0011263033176367\n",
      "Test VOL: 0.003455209982463734\n",
      "\n",
      "Shallow NNF Training & Results for model 24.0:\n",
      "Epoch 1 of 10 | MSE: 0.017407607287168503\n",
      "Epoch 10 of 10 | MSE: 0.0036013557109981775\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0018684296381167307\n",
      "Test RMSE: 0.001331408324396727\n",
      "Test MEAN: 1.0017060843920986\n",
      "Test VOL: 0.004495217023582469\n",
      "Selected Model Test Results for model i = 1 are: \n",
      "RMSE = 0.0014335311847101513\n",
      "MEAN = 1.0019152986298194\n",
      "VOL = 0.005343951406957578\n"
     ]
    }
   ],
   "source": [
    "#shallow nnf\n",
    "'''\n",
    "in this cell,firstly, train, validation and test datasets are sliced in each loop. then shallow NNf model gets trained and\n",
    "then best model will be chosen. Also RMSE, Mean and volatility of all models and then the best model is printed.\n",
    "'''\n",
    "shallow_nnf_valid_rmse_list = []\n",
    "shallow_nnf_test_results = [] \n",
    "shallow_nnf_test_plot = [] # storing the shallow model test data return for plotting later on\n",
    "\n",
    "for i in range(int(24/rbp)):\n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i*rbp))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i*rbp))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i*rbp))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i*rbp))\n",
    "    x_test = data_process(date_slicer(df, '2018-01-01', 1, i*rbp))\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i*rbp))\n",
    "    \n",
    "    train_shallow_nnf(x_train, y_train, i*rbp)\n",
    "    shallow_nnf_valid_rmse_list.append(valid_fun(x_valid, i*rbp, shallow_NNF))\n",
    "    shallow_nnf_test_results.append(test_fun(x_test, i*rbp, shallow_NNF))\n",
    "    portfolio_return(df, x_test, shallow_NNF, i, shallow_nnf_test_plot)\n",
    "    shallow_NNF.reset_parameters()\n",
    "    \n",
    "\n",
    "# print(f'\\nMin Valid RMSE is: {min(valid_rmse_list)} for model i = {(deep_best_result_index)+1}')\n",
    "print('Selected Model Test Results for model i =', (deep_best_result_index)+1, 'are: ')\n",
    "print('RMSE =', shallow_nnf_test_results[(deep_best_result_index)]['RMSE'])\n",
    "print('MEAN =', shallow_nnf_test_results[(deep_best_result_index)]['MEAN'])\n",
    "print('VOL =', shallow_nnf_test_results[(deep_best_result_index)]['VOL'])\n",
    "\n",
    "shallow_nnf_test_plot = np.array(shallow_nnf_test_plot).reshape(-1,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1/N Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Equal Weights Model Results for model 1:\n",
      "Validation RMSE: 0.0013752466607634818\n",
      "Test RMSE: 0.00141308068973907\n",
      "Test MEAN: 1.00194947794337\n",
      "Test VOL: 0.005348201810361211\n",
      "\n",
      "Equal Weights Model Results for model 2:\n",
      "Validation RMSE: 0.0014103582761839522\n",
      "Test RMSE: 0.002225473810475016\n",
      "Test MEAN: 0.9979382024584036\n",
      "Test VOL: 0.015471723202182033\n",
      "\n",
      "Equal Weights Model Results for model 3:\n",
      "Validation RMSE: 0.00161101492926301\n",
      "Test RMSE: 0.0021228799964131116\n",
      "Test MEAN: 1.0002504247997188\n",
      "Test VOL: 0.011031703269168955\n",
      "\n",
      "Equal Weights Model Results for model 4:\n",
      "Validation RMSE: 0.00178815568268382\n",
      "Test RMSE: 0.0016167972928903618\n",
      "Test MEAN: 1.001305977361471\n",
      "Test VOL: 0.008808539875808678\n",
      "\n",
      "Equal Weights Model Results for model 5:\n",
      "Validation RMSE: 0.0017533218637125797\n",
      "Test RMSE: 0.0012496906685729259\n",
      "Test MEAN: 1.0007751300633236\n",
      "Test VOL: 0.0062942423298088844\n",
      "\n",
      "Equal Weights Model Results for model 6:\n",
      "Validation RMSE: 0.0017002638599400465\n",
      "Test RMSE: 0.0012049049143032751\n",
      "Test MEAN: 1.000132556099627\n",
      "Test VOL: 0.004753505074253049\n",
      "\n",
      "Equal Weights Model Results for model 7:\n",
      "Validation RMSE: 0.0016838896697022906\n",
      "Test RMSE: 0.002608250111522712\n",
      "Test MEAN: 1.0015818555353888\n",
      "Test VOL: 0.004983170010212011\n",
      "\n",
      "Equal Weights Model Results for model 8:\n",
      "Validation RMSE: 0.0019078407523448037\n",
      "Test RMSE: 0.0011962789884695558\n",
      "Test MEAN: 1.0012933034193634\n",
      "Test VOL: 0.004707598960828587\n",
      "\n",
      "Equal Weights Model Results for model 9:\n",
      "Validation RMSE: 0.0017918743187162148\n",
      "Test RMSE: 0.001888238767926475\n",
      "Test MEAN: 1.000176838763966\n",
      "Test VOL: 0.0035131312053199725\n",
      "\n",
      "Equal Weights Model Results for model 10:\n",
      "Validation RMSE: 0.0017472761704575702\n",
      "Test RMSE: 0.003108435537956791\n",
      "Test MEAN: 0.9967994846709011\n",
      "Test VOL: 0.012654039350899505\n",
      "\n",
      "Equal Weights Model Results for model 11:\n",
      "Validation RMSE: 0.002080505442953261\n",
      "Test RMSE: 0.0024845370945334663\n",
      "Test MEAN: 1.000826368012285\n",
      "Test VOL: 0.009815043138294987\n",
      "\n",
      "Equal Weights Model Results for model 12:\n",
      "Validation RMSE: 0.00228250529001297\n",
      "Test RMSE: 0.002110325599208719\n",
      "Test MEAN: 0.99392170780843\n",
      "Test VOL: 0.017125701805097735\n",
      "\n",
      "Equal Weights Model Results for model 13:\n",
      "Validation RMSE: 0.002378854806423318\n",
      "Test RMSE: 0.0025991203186737635\n",
      "Test MEAN: 1.0047820361360924\n",
      "Test VOL: 0.010457672576285474\n",
      "\n",
      "Equal Weights Model Results for model 14:\n",
      "Validation RMSE: 0.0023376364047417086\n",
      "Test RMSE: 0.001402228062171977\n",
      "Test MEAN: 1.002025461923509\n",
      "Test VOL: 0.004559034383661699\n",
      "\n",
      "Equal Weights Model Results for model 15:\n",
      "Validation RMSE: 0.002388129123328023\n",
      "Test RMSE: 0.0014276920122888483\n",
      "Test MEAN: 1.000264732576357\n",
      "Test VOL: 0.007639654783347461\n",
      "\n",
      "Equal Weights Model Results for model 16:\n",
      "Validation RMSE: 0.0023085543362458107\n",
      "Test RMSE: 0.0019700691339755265\n",
      "Test MEAN: 1.0012020349198691\n",
      "Test VOL: 0.004404697243899707\n",
      "\n",
      "Equal Weights Model Results for model 17:\n",
      "Validation RMSE: 0.002032437718144319\n",
      "Test RMSE: 0.001475205067385024\n",
      "Test MEAN: 0.9972273915102033\n",
      "Test VOL: 0.008748691989180815\n",
      "\n",
      "Equal Weights Model Results for model 18:\n",
      "Validation RMSE: 0.0018717109499381298\n",
      "Test RMSE: 0.001720766888220823\n",
      "Test MEAN: 1.0036391934325273\n",
      "Test VOL: 0.006673775895724877\n",
      "\n",
      "Equal Weights Model Results for model 19:\n",
      "Validation RMSE: 0.0019686564797122682\n",
      "Test RMSE: 0.0018643344043743812\n",
      "Test MEAN: 1.0002658041495434\n",
      "Test VOL: 0.005183267607845902\n",
      "\n",
      "Equal Weights Model Results for model 20:\n",
      "Validation RMSE: 0.0018238046048378409\n",
      "Test RMSE: 0.001359914467857588\n",
      "Test MEAN: 0.9993162870787218\n",
      "Test VOL: 0.014303584166600736\n",
      "\n",
      "Equal Weights Model Results for model 21:\n",
      "Validation RMSE: 0.0018329033576296974\n",
      "Test RMSE: 0.002201019621821213\n",
      "Test MEAN: 1.0021142585317577\n",
      "Test VOL: 0.00539380418680695\n",
      "\n",
      "Equal Weights Model Results for model 22:\n",
      "Validation RMSE: 0.0019462210070632896\n",
      "Test RMSE: 0.0019706191075476273\n",
      "Test MEAN: 1.0013487467662525\n",
      "Test VOL: 0.007930844134341473\n",
      "\n",
      "Equal Weights Model Results for model 23:\n",
      "Validation RMSE: 0.0019529162145969603\n",
      "Test RMSE: 0.0009264363066448112\n",
      "Test MEAN: 1.0011367709735588\n",
      "Test VOL: 0.0034522863961233786\n",
      "\n",
      "Equal Weights Model Results for model 24:\n",
      "Validation RMSE: 0.0017551968016899662\n",
      "Test RMSE: 0.0013201770489190275\n",
      "Test MEAN: 1.0017054738565843\n",
      "Test VOL: 0.004493494843845112\n",
      "Selected Model Test Results for model i = 1 are: \n",
      "RMSE = 0.00141308068973907\n",
      "MEAN = 1.00194947794337\n",
      "VOL = 0.005348201810361211\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "here we run the 1/N model, for the number of stocks, each stock gets the weight of 1/N meaning that\n",
    "every stock is equally important, this model play the role of a benchmark to see how effective our model are\n",
    "'''\n",
    "equal_w_model_valid_rmse_list = []\n",
    "equal_w_model_test_results = []\n",
    "equal_w_model_test_plot = [] # storing the 1/n model test data return for plotting later on\n",
    "\n",
    "for i in range(int(24/rbp)):\n",
    "    print(f'\\nEqual Weights Model Results for model {i+1}:')\n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i*rbp))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i*rbp))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i*rbp))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i*rbp))\n",
    "    x_test = data_process(date_slicer(df, '2018-01-01', 1, i*rbp))\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i*rbp))\n",
    "    \n",
    "    equal_w_model_valid_rmse_list.append(valid_fun(x_valid, i*rbp, equal_w_model))\n",
    "    equal_w_model_test_results.append(test_fun(x_test, i*rbp, equal_w_model))\n",
    "    portfolio_return(df, x_test, equal_w_model, i, equal_w_model_test_plot)\n",
    "    \n",
    "print('Selected Model Test Results for model i =', (deep_best_result_index)+1, 'are: ')\n",
    "print('RMSE =', equal_w_model_test_results[(deep_best_result_index)]['RMSE'])\n",
    "print('MEAN =', equal_w_model_test_results[(deep_best_result_index)]['MEAN'])\n",
    "print('VOL =', equal_w_model_test_results[(deep_best_result_index)]['VOL'])\n",
    "\n",
    "equal_w_model_test_plot = np.array(equal_w_model_test_plot).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models test results with rebalancing period of 1 month(s) are: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep NNF</th>\n",
       "      <th>Shallow NNF</th>\n",
       "      <th>1/N Model</th>\n",
       "      <th>S&amp;P 500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN</th>\n",
       "      <td>1.001898</td>\n",
       "      <td>1.001915</td>\n",
       "      <td>1.001949</td>\n",
       "      <td>1.002337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOL</th>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.005344</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.005601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Deep NNF  Shallow NNF  1/N Model   S&P 500\n",
       "RMSE  0.001434     0.001434   0.001413         -\n",
       "MEAN  1.001898     1.001915   1.001949  1.002337\n",
       "VOL   0.005361     0.005344   0.005348  0.005601"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print test results\n",
    "'''\n",
    "here we compare the results in a dataframe featuring RMSE, MEAN and, volatility of each model in the test dataset\n",
    "that has the best results for deep nnf model. this dataframe can cope with the understanding of why we bother \n",
    "implementing a complex neural network\n",
    "'''\n",
    "print(f'Models test results with rebalancing period of {rbp} month(s) are: ')\n",
    "deep_temp = pd.DataFrame(deep_nnf_test_results)\n",
    "deep_temp = deep_temp.iloc[deep_best_result_index]\n",
    "shallow_temp = pd.DataFrame(shallow_nnf_test_results)\n",
    "shallow_temp = shallow_temp.iloc[deep_best_result_index]\n",
    "equal_w_temp = pd.DataFrame(equal_w_model_test_results)\n",
    "equal_w_temp = equal_w_temp.iloc[deep_best_result_index]\n",
    "\n",
    "# extract the mean and volatility of the s&p index on the test dataset\n",
    "sp_temp_rmse = '-'\n",
    "sp_temp_mean = daily_return(date_slicer(df_sp, '2018-01-01', 1, deep_best_result_index)).mean()[0]\n",
    "sp_temp_std = daily_return(date_slicer(df_sp, '2018-01-01', 1, deep_best_result_index)).std()[0]\n",
    "sp_temp = pd.DataFrame([sp_temp_rmse, sp_temp_mean, sp_temp_std], index=deep_temp.index)\n",
    "\n",
    "# concatinating the result in a unified dataframe\n",
    "final_result = pd.concat([deep_temp, shallow_temp, equal_w_temp, sp_temp], axis=1, join='inner')\n",
    "final_result.columns = ['Deep NNF', 'Shallow NNF', '1/N Model', 'S&P 500']\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of test RMSE for each model: \n",
      "Deep NNF: 0.0018668248427246078\n",
      "Shallow NNF: 0.0018336460979335976\n",
      "Equal weight model: 0.001811103162995504\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "to further showcase the results, here we compute the average RMSE of each model in test dataset\n",
    "'''\n",
    "print(f'Average of test RMSE for each model: ')\n",
    "\n",
    "deep_nnf_test_rmse_mean = 0 # temp variable for storing each tmse for deep nnf model\n",
    "for i in range(int(24/rbp)):\n",
    "    deep_nnf_test_rmse_mean += deep_nnf_test_results[i]['RMSE']\n",
    "print(f'Deep NNF: {deep_nnf_test_rmse_mean/int(24/rbp)}')\n",
    "\n",
    "shallow_nnf_test_rmse_mean = 0 # temp variable for storing each tmse for shallow nnf model\n",
    "for i in range(int(24/rbp)):\n",
    "    shallow_nnf_test_rmse_mean += shallow_nnf_test_results[i]['RMSE']\n",
    "print(f'Shallow NNF: {shallow_nnf_test_rmse_mean/int(24/rbp)}')\n",
    "\n",
    "equal_w_model_test_rmse_mean = 0 # temp variable for storing each tmse for 1/n model model\n",
    "for i in range(int(24/rbp)):\n",
    "    equal_w_model_test_rmse_mean += equal_w_model_test_results[i]['RMSE']\n",
    "print(f'Equal weight model: {equal_w_model_test_rmse_mean/int(24/rbp)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinating the test dataset return results of each model + index return for plot\n",
    "plot_test = pd.concat([pd.DataFrame(deep_nnf_test_plot), pd.DataFrame(shallow_nnf_test_plot),\n",
    "                       pd.DataFrame(equal_w_model_test_plot), pd.DataFrame(index_test_plot)], axis=1, join='inner')\n",
    "plot_test.columns = ['Deep NNF', 'Shallow NNF', '1/N Model', 'S&P 500']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "Deep NNF",
         "text": "",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477
         ],
         "y": [
          1.0052614857834639,
          1.0084491674487412,
          1.0142009504115734,
          1.017902308074024,
          1.0180746436428654,
          1.0154131380639717,
          1.0247094331874467,
          1.030843718889444,
          1.0244855110363562,
          1.0332377766176526,
          1.03075912796234,
          1.037513817072758,
          1.043927958751617,
          1.0469001543975522,
          1.0467333938384307,
          1.046364041361339,
          1.0564274903930269,
          1.0490097873585458,
          1.0384752740953824,
          1.0385596752053499,
          0.97965241520258,
          0.944017859030801,
          0.9560996824924406,
          0.9536487382501361,
          0.9213468654859587,
          0.9334940834728545,
          0.9447539986869904,
          0.9480652100724067,
          0.9618004540340327,
          0.9720687706377219,
          0.972272553730843,
          0.9661289069453146,
          0.9606852156705036,
          0.9614534824905001,
          0.9763167946535767,
          0.9834826786488629,
          0.9703666520716796,
          0.9603749997079983,
          1.006605149776329,
          1.0182330933772095,
          1.0232866194100372,
          1.022678502453561,
          1.026226185108125,
          1.0425931672307078,
          1.0414296530841831,
          1.0373137742651473,
          1.0316757363431304,
          1.0292112524516113,
          1.0340955596686083,
          1.0224605238899833,
          1.0234269927831763,
          1.0233938081505893,
          1.000084139975636,
          0.9806804255101035,
          1.0034237655060114,
          0.9911736853317589,
          0.9900740334954169,
          1.0029830871603398,
          1.0121429032031142,
          1.0238002706326135,
          1.0302535330647082,
          1.0085214186115106,
          1.009901335837784,
          1.0248304534739692,
          1.0200953517320848,
          1.0254465645343296,
          1.0227960935059774,
          1.0329167756087552,
          1.0419766291070114,
          1.0446573988270003,
          1.037870131038925,
          1.030467923075697,
          1.031838741169796,
          1.021647904649229,
          1.0244664430483565,
          1.0319388134660534,
          1.0347354674988098,
          1.0256354286163314,
          0.991348424243541,
          0.9886715585742407,
          1.000911005309212,
          1.002395486266622,
          1.0016528680217456,
          1.0093722781614127,
          1.0179414805059122,
          1.0190619880384413,
          1.019266611498096,
          1.0143568427344825,
          1.0198317031562576,
          1.0210094657695585,
          1.0191894090983167,
          1.0261340301484732,
          1.0219216852822595,
          1.0239849233994205,
          1.0236018892592758,
          1.0217413202166041,
          1.0111664480499314,
          1.024191155056835,
          1.0146257845513265,
          1.0048890631623826,
          1.0065497590326646,
          1.0144122814876912,
          1.0147821388484057,
          1.019790518361892,
          1.0222904670072546,
          1.0254004195593354,
          1.0194275112999085,
          1.0224198747405626,
          1.0231548556653038,
          1.021355100500933,
          1.017121471402682,
          1.019556444336148,
          1.0139649952402092,
          1.0169022808466341,
          1.0060063173069962,
          1.0067225456082394,
          0.9982577209751607,
          1.0022953601939801,
          1.0033281192246937,
          0.9985175680052494,
          1.0066181742753475,
          1.0142894095323107,
          1.0220101938533823,
          1.025193590313207,
          1.017242018651957,
          1.022748348188744,
          1.0238094141674978,
          1.020808330733986,
          1.0247233702999354,
          1.0272000695653,
          1.0270330303233326,
          1.0234401863350673,
          1.0237088270160397,
          1.0228893894759077,
          1.03139588518069,
          1.0354641735790076,
          1.0291056667620782,
          1.0244071165877846,
          1.032307834032368,
          1.005098165098463,
          1.0103767234920609,
          1.0128644027063856,
          1.0155095711902102,
          1.0134000835365613,
          1.012095816021469,
          1.0047117699579597,
          1.0000942888216053,
          1.0083544199486612,
          1.001660524019301,
          1.0098197758088125,
          1.0153413725589258,
          1.019952010936845,
          1.0230281503838228,
          1.020714923740984,
          1.0179811480223584,
          1.0235658618282162,
          1.0294412262193626,
          1.0297930845955023,
          1.0337334981237984,
          1.0272528343649485,
          1.028136910902094,
          1.0003198472418529,
          0.9983448955777545,
          0.9950513424274149,
          0.9991139616026786,
          1.00004004242509,
          1.0019602683129705,
          1.0064966885103752,
          1.0076819348770027,
          1.0040494932196697,
          1.0084822083280205,
          1.008383921841993,
          1.0150083988947356,
          1.0161011708638676,
          1.0084340599796342,
          1.005513366965772,
          1.0011017113288354,
          1.0013030710538398,
          1.003087316045087,
          0.9983924477231207,
          0.9981259922961737,
          0.9911847793561614,
          0.9864232517709809,
          0.9876996562664848,
          0.9826369695384791,
          0.9551634148534562,
          0.9346859141216146,
          0.9430504589881289,
          0.9425229838805597,
          0.9611457602462626,
          0.9588402274899721,
          0.9465573292542164,
          0.9448039681258592,
          0.9393265529442194,
          0.9338800852857836,
          0.9101714469231581,
          0.9220473916828065,
          0.9079596683131069,
          0.9079617800847989,
          0.9263558859546538,
          0.9317586889065106,
          0.9967828100167494,
          1.0035157669818897,
          1.0109440017008469,
          1.027017457635606,
          1.025154689952993,
          1.0171058190769053,
          1.0013212042607034,
          1.0012612124405567,
          0.9953716824792816,
          1.0044165043337225,
          1.0077102296746219,
          0.9943204921565405,
          0.9779477436033922,
          0.9832841881230341,
          0.9802768451813877,
          0.9936586734459564,
          0.9938662202898869,
          1.0124708550064774,
          1.0093184316631445,
          1.015514859352665,
          0.9686914449705049,
          0.9668174800114988,
          0.9460251080203935,
          0.9445785350546079,
          0.9431596911217416,
          0.9481954378659851,
          0.9439833679923255,
          0.9304611405817514,
          0.910436319358875,
          0.9097372353790436,
          0.8964026397197572,
          0.8821879368536604,
          0.8662154626032498,
          0.8428825768944975,
          0.8804407821247875,
          0.8881247618925826,
          0.8866597968848721,
          0.8938972494524229,
          0.9808486872399637,
          1.01241905303651,
          1.0228425809679746,
          1.0338505669270746,
          1.0406883758496686,
          1.047372634488866,
          1.048616923712189,
          1.043387129231076,
          1.0509371983590003,
          1.0533644326679383,
          1.0628889479374506,
          1.078541593896889,
          1.0645286631778192,
          1.0643182527197286,
          1.0689776215085551,
          1.079740663316358,
          1.0755773757165612,
          1.077660402477209,
          1.0894141037130372,
          1.0978469747821953,
          1.005392981775413,
          1.0096179375243832,
          1.0086372881694468,
          1.0032443679473584,
          1.0047168623088623,
          1.0071775761153976,
          1.0192098429818195,
          1.0234597659628695,
          1.021342499295029,
          1.032802758830653,
          1.0348198954157852,
          1.0380893253210517,
          1.034858088389277,
          1.0405590091253847,
          1.0402444799359116,
          1.0376549788310785,
          1.0379235040406716,
          1.0359862503772843,
          0.9949897036237253,
          0.9920607470646623,
          0.9841064904160441,
          0.9768512058298642,
          0.9742490400486465,
          0.9870730880387721,
          0.9899565759941926,
          0.995990471063664,
          0.9947241355343185,
          0.998060140974603,
          1.002499416535422,
          1.0005785862179366,
          0.9944104350747448,
          1.0073793617360416,
          0.9878553452443154,
          0.9882392266341179,
          0.9963166272527236,
          0.9932089731919039,
          0.9984513297124727,
          1.004544902242652,
          0.9991606232395414,
          1.0018145086266605,
          1.0050904103806941,
          1.0116453083847459,
          1.012248422664534,
          1.0042054183291254,
          1.0096289143613923,
          1.011148300386931,
          1.0182600507123758,
          1.0161606788994766,
          1.0158964167482596,
          1.0103810147179497,
          1.0126443109614216,
          1.01012768737109,
          1.0194330121382698,
          1.0192235417216122,
          1.014027097470233,
          1.020532051431396,
          1.0205017866936508,
          1.023879959230471,
          1.0009224680734277,
          1.0101142765604416,
          1.0056080255366802,
          0.9894065574040191,
          0.9874677255368343,
          0.9862874398677416,
          0.9904475018493334,
          0.9669346816588362,
          0.9759374967058008,
          0.9790306587489778,
          0.9860881903782144,
          0.9797089197471122,
          0.9737017691613727,
          0.9838445977274801,
          0.9793190186510655,
          0.9677177706229602,
          0.9697053261364375,
          0.959624231118305,
          0.9527371704491219,
          0.9540954710268221,
          0.9441894881577285,
          1.0224272047690266,
          1.0299757855817813,
          1.0347345446237879,
          1.0422083172471726,
          1.0462701917114325,
          1.0455503136539013,
          1.043669322973296,
          1.0505472301190584,
          1.047715942295683,
          1.046774921225463,
          1.0571546494583632,
          1.0611336551237613,
          1.0708497114962388,
          1.0681994407395976,
          1.0638942670703024,
          1.056575137673839,
          1.0542497438097878,
          1.06091293280422,
          1.0705828281482679,
          1.0002890684128556,
          1.0097195922652455,
          1.0082468211056896,
          1.0029717187681173,
          1.0026498192873718,
          1.003779370858949,
          1.0054771997331364,
          1.0127258684704825,
          1.011657019235343,
          1.0104177974082453,
          1.0019580010041715,
          1.0055312856644403,
          1.0004944441593135,
          1.000654319290037,
          1.0096733331809649,
          1.0163128370858698,
          1.0100545755865842,
          1.015766859060316,
          1.013558760619922,
          1.0139547855953797,
          1.0045632198800099,
          0.9922728714351761,
          0.9642210454206004,
          0.9750352509303156,
          0.97666345079814,
          0.9944893274189989,
          0.9865718167744497,
          0.9742973732367428,
          0.986575242290647,
          0.9566763473097685,
          0.9574231414256875,
          0.9723758988451103,
          0.9840883791363589,
          0.9758639884988703,
          0.9839978701466378,
          0.9845324141609766,
          0.9586241450151496,
          0.967143169188909,
          0.9622701983375394,
          0.9698578750561604,
          0.9827564004088865,
          0.9844452361834303,
          1.011683663480542,
          1.026565988096503,
          1.0291847040571802,
          1.0352114029889439,
          1.0411386503765785,
          1.0493494634026659,
          1.0498264921902938,
          1.0506588800912997,
          1.0509511666185636,
          1.050745290470583,
          1.049518243961455,
          1.0467823495287094,
          1.0428585047469165,
          1.0434154220434826,
          1.0355170665619775,
          1.041529648412371,
          1.0395139359222616,
          1.0358804134791588,
          1.0409127339219169,
          0.9813405921682496,
          0.9880829283487721,
          0.9998211278458836,
          0.9949246272803186,
          0.9775520261850829,
          0.9859041946232612,
          0.9930685422928449,
          1.0071376285642326,
          1.0046535041630686,
          1.0134012879943672,
          1.0116685869377025,
          1.0154213314445497,
          1.0144048631159273,
          1.0217160656936033,
          1.0219005298586459,
          1.0249915868609396,
          1.0254171744288783,
          1.0290247378537547,
          1.0313843776172429,
          1.033910514588886,
          1.034072189510118,
          1.0286044728863615,
          1.005084857992515,
          1.004975956795784,
          1.0044652076984701,
          1.0068411386747345,
          1.0086581791961429,
          1.0060582283346136,
          1.0067066075346878,
          1.0060174570862357,
          1.0081614749873795,
          1.0155700258942881,
          1.0146212690307521,
          1.0137095442804818,
          1.0101233045436078,
          1.007436920810464,
          1.0110905203100802,
          1.019325174525517,
          1.021234907018718,
          1.0255179434281505,
          1.0205829127811032,
          0.9919507429641717,
          0.9994558667666772,
          1.0013055982504826,
          1.010248407867184,
          1.0076816473090635,
          1.0065194738261176,
          1.0091064756016208,
          1.0195378062978895,
          1.01677930364838,
          1.0230352275691161,
          1.0236854348919073,
          1.0251144433888206,
          1.0286405328362622,
          1.034675655166382,
          1.0348720600247008,
          1.0351206303606058,
          1.0375642420701898,
          1.036654947505087,
          1.0326751318855802
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "Shallow NNF",
         "text": "",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477
         ],
         "y": [
          1.0052431152115084,
          1.008365832087296,
          1.014170454155317,
          1.0179256146414053,
          1.0181193282785184,
          1.01541288171817,
          1.0246383116820927,
          1.0307791787236054,
          1.0244662670676186,
          1.0332487465651452,
          1.030805341824563,
          1.0375752534680316,
          1.0439635321165353,
          1.0469604830476258,
          1.0468748189152313,
          1.0465223848007934,
          1.0565661525431502,
          1.0491916017238803,
          1.0387033443108151,
          1.0387658703062612,
          0.9799102795337883,
          0.9442441342767885,
          0.9563331787514424,
          0.953901021230094,
          0.9213467150840441,
          0.9336837525505507,
          0.944994780405784,
          0.948198614004465,
          0.9619789881772642,
          0.9723630413440117,
          0.9726264834533345,
          0.96654936418151,
          0.9611359400975273,
          0.9617498459343999,
          0.9765788428736158,
          0.9837631999693311,
          0.9707266817115734,
          0.9607983521629028,
          1.0066433338243,
          1.0182582312285857,
          1.0233299900796808,
          1.0229792948398262,
          1.026521109250897,
          1.042920663497424,
          1.0417731509488428,
          1.0376332018380183,
          1.0320632778225394,
          1.029731340440271,
          1.034479426635454,
          1.0228585510588493,
          1.0239680894724223,
          1.0238140333814774,
          1.0004676173262503,
          0.9810645650544007,
          1.0039239635682127,
          0.9913958947456025,
          0.990164224228598,
          1.0030935159061132,
          1.0121274349551368,
          1.0237548065625637,
          1.0302451559693144,
          1.0083698375852506,
          1.0098308568270251,
          1.0248290365475472,
          1.0200332929046483,
          1.0255493631714974,
          1.0228472458164768,
          1.0329944221422311,
          1.042242242993656,
          1.0450004820655052,
          1.0381785403725723,
          1.0307888955136366,
          1.0321115530119445,
          1.0216838026583053,
          1.0244279709368802,
          1.0319908498005699,
          1.0347599148739655,
          1.02570131173408,
          0.9914802182448923,
          0.9891677422408576,
          1.0013703274092884,
          1.0029447514428773,
          1.0024552832880653,
          1.0102477654672348,
          1.0188621411474654,
          1.0198786005736296,
          1.0199811393338332,
          1.014880863101429,
          1.020267425407474,
          1.021357597477873,
          1.0197516290863584,
          1.0266804569452401,
          1.0224075893356324,
          1.0247869967709697,
          1.0245014626848903,
          1.0226349744143393,
          1.0120911925814309,
          1.0250087204838465,
          1.0155991067086192,
          1.0049513705376505,
          1.0066650917819728,
          1.014556789626653,
          1.014795741098083,
          1.0197562773320052,
          1.0220747868629874,
          1.0252140547504254,
          1.0194015203972946,
          1.0224341856722805,
          1.0231800872127204,
          1.0214683345778814,
          1.0171422795254352,
          1.0195201096164666,
          1.0138480553158964,
          1.0166084427879087,
          1.0054776006400203,
          1.0062685650366876,
          0.9976493104494459,
          1.0017924361190549,
          1.002792205965778,
          0.9983958388182474,
          1.006498859245815,
          1.0141487518782306,
          1.0219640169266804,
          1.0250633731261685,
          1.0171318828355465,
          1.0228715466791292,
          1.0239248533850052,
          1.0208743164981988,
          1.0249638059025323,
          1.0274807672526771,
          1.0272455403597698,
          1.0237239524607133,
          1.0240049840495815,
          1.023136067244534,
          1.031622924439384,
          1.0355521213739134,
          1.0290593541505648,
          1.0238390836505575,
          1.0316303668473261,
          1.005128115946471,
          1.010261514965213,
          1.0128560881812902,
          1.0156068227157098,
          1.0135956099188468,
          1.0122985542147613,
          1.0048981437281086,
          1.0002805908781485,
          1.008581714312188,
          1.0017965552759134,
          1.0098284199244334,
          1.0152242577356796,
          1.0198150818249416,
          1.0230180953873789,
          1.0207715383324296,
          1.0181203309737235,
          1.0238762526369203,
          1.0297978490693416,
          1.0301436187082906,
          1.03410107567535,
          1.0274905508572278,
          1.028399516417202,
          1.0001774956573657,
          0.998216462641457,
          0.9949580411823075,
          0.9990037727684288,
          1.0000231501816352,
          1.0019001167937023,
          1.0064326310193703,
          1.0076606189051245,
          1.0039045053703313,
          1.0083772358674765,
          1.0082675799664504,
          1.0148603019520759,
          1.0159124365601846,
          1.0083194423820154,
          1.005481917878715,
          1.0010262484291188,
          1.0012607376920932,
          1.0029963527256403,
          0.9983201551517088,
          0.9981369859925285,
          0.9910750272222546,
          0.9862031576537372,
          0.9871797162476169,
          0.9821623119433494,
          0.954405047605125,
          0.9340070755912114,
          0.9425990575610509,
          0.941935832074736,
          0.9607122318261859,
          0.9584353918863084,
          0.9460156917172604,
          0.944043291520717,
          0.9386453808873056,
          0.9331487722222949,
          0.9091275340635804,
          0.9210207896245509,
          0.9069578588879973,
          0.9065709388824897,
          0.9249705018898289,
          0.9306803040551023,
          0.9968189050495588,
          1.0034951743254388,
          1.0109639097714647,
          1.0270564890256062,
          1.025189881346755,
          1.0171639581731138,
          1.0013590006055795,
          1.0012798107616765,
          0.9953585295644923,
          1.0044343041276316,
          1.0076242500639,
          0.9942162188073268,
          0.9778134858004172,
          0.9831356378838533,
          0.9801007534467426,
          0.9935146976680048,
          0.9937553418263583,
          1.0124310891192365,
          1.0092813271662677,
          1.0154810153496723,
          0.9685397841752222,
          0.9667101696331001,
          0.9457293564587463,
          0.9443990701260105,
          0.9429046809109527,
          0.9479696144145836,
          0.9437371824400258,
          0.9301500889318302,
          0.910141053801554,
          0.9094984397609663,
          0.8961480395812985,
          0.8819807311149122,
          0.865979225482273,
          0.8426817435668384,
          0.8803162878299314,
          0.888047789205243,
          0.8866174183278371,
          0.8938777085415883,
          0.9808731268770668,
          1.0124688760677618,
          1.0228304781971973,
          1.0338697816509497,
          1.040716211168738,
          1.0474434956264942,
          1.0486793791441025,
          1.0434606527272932,
          1.0510723111681584,
          1.0535815258517165,
          1.0630908373418146,
          1.0787636662644555,
          1.0648342220271223,
          1.0646019498541897,
          1.0691613521056262,
          1.0798251923736548,
          1.0756041315669558,
          1.077681888696385,
          1.0894381845620846,
          1.0979125543562187,
          1.0054394549727204,
          1.0097295813510685,
          1.0087052450320393,
          1.0032696564571717,
          1.004914407432053,
          1.0073707779076204,
          1.0195817503676692,
          1.0237996994923215,
          1.0216820110494222,
          1.0331394750774485,
          1.0351115074120543,
          1.0383559143836394,
          1.0350912753125703,
          1.0409309537531788,
          1.0407228643331476,
          1.038087931863231,
          1.0383551039529588,
          1.0364178028688853,
          0.9949499197187561,
          0.991985884361278,
          0.9840081178867911,
          0.9767570607937659,
          0.9741439713313009,
          0.9870220432970871,
          0.9899255543276948,
          0.9959667358522959,
          0.9947063329721424,
          0.998058231932655,
          1.0024784711179004,
          1.0006240345638202,
          0.9944820929145577,
          1.0075487530836105,
          0.9879199561498582,
          0.9882728567675926,
          0.9963365345389332,
          0.9931489611274077,
          0.9984288059797218,
          1.004564662522556,
          0.9991864788022979,
          1.001940100168984,
          1.005078393737089,
          1.0116389935095684,
          1.0122367427513592,
          1.0041383954841112,
          1.0095338535372291,
          1.0110804892463083,
          1.0181777812755968,
          1.01607944832113,
          1.015881617886253,
          1.0104193130336145,
          1.0127266840323341,
          1.0103098818241505,
          1.0195997204661111,
          1.019325388345153,
          1.014114906079125,
          1.0205890595432183,
          1.0205410061352558,
          1.023899391363427,
          1.0009765587823272,
          1.010123562404756,
          1.0056186552988702,
          0.9894192509723764,
          0.9874621706083923,
          0.9862653966057969,
          0.9904438168011829,
          0.9669622956076719,
          0.9759586438992158,
          0.9790404951879024,
          0.9860817475766663,
          0.9797038550716121,
          0.9737356498596783,
          0.9838136025531551,
          0.9792971323364111,
          0.9677193178108291,
          0.96971856174582,
          0.9596358640118507,
          0.9527453395749059,
          0.9540808219250454,
          0.9441195234692066,
          1.0224549132098624,
          1.0300296524837,
          1.0348173126332874,
          1.042332628094179,
          1.0464669518086605,
          1.0457257740164132,
          1.0437861044118386,
          1.0505699136847364,
          1.0476983744565072,
          1.0467569517818918,
          1.0572146483343547,
          1.0611807738230525,
          1.0709544666721114,
          1.0683213219435426,
          1.0640551871195436,
          1.0567503262472944,
          1.0544450965112246,
          1.0611289542120517,
          1.0707725726120159,
          1.0003148649749452,
          1.0097236073328495,
          1.008275899242583,
          1.0030046848051348,
          1.0027434671887938,
          1.003931790938494,
          1.0057334044441757,
          1.013011483168829,
          1.0119745724323785,
          1.0106860607710912,
          1.0022879296207345,
          1.0058593648540701,
          1.0008563660957592,
          1.0010656040161423,
          1.010002261343367,
          1.0166050079317561,
          1.0103618881360439,
          1.0161415774220102,
          1.0139168913432004,
          1.0143301582878017,
          1.0048978099592676,
          0.9922608596179271,
          0.9640722336381142,
          0.9749263604396826,
          0.9765379859908709,
          0.9944625098841529,
          0.9864893559253675,
          0.9741362424904956,
          0.9864483902116462,
          0.9565073948554045,
          0.9572319146060786,
          0.9722187940786512,
          0.9839469761512458,
          0.975755794571921,
          0.9838705607005147,
          0.9844324859009927,
          0.9584548867647814,
          0.9670046707483638,
          0.9621424383036475,
          0.9697141758469058,
          0.9826228694189602,
          0.9843527326752574,
          1.011697460526082,
          1.0268220065502323,
          1.0292891685781622,
          1.03510076051156,
          1.0408666621211309,
          1.049160990233188,
          1.0496738925510236,
          1.0504828567776399,
          1.0509248391063923,
          1.050730820518943,
          1.0494626899826787,
          1.0467246071503384,
          1.0427414807717357,
          1.043239304141504,
          1.0351379759126615,
          1.04124767043228,
          1.0391790408232562,
          1.035263537581497,
          1.0403458185775367,
          0.9813775462188732,
          0.9881354391037058,
          0.9998598638695213,
          0.9949393266273125,
          0.9774703281260708,
          0.9858484753728328,
          0.9929843683282522,
          1.0071394496604202,
          1.0046668332461266,
          1.0134802356351773,
          1.0116913988012897,
          1.015473342162419,
          1.0144183539248584,
          1.02175894380886,
          1.0218190651141663,
          1.0249271642562503,
          1.0254671959249755,
          1.029128311755664,
          1.0315389436293587,
          1.0340655633426175,
          1.0342834131173608,
          1.028756615137783,
          1.0052466879340067,
          1.005093040923814,
          1.0044917269166869,
          1.0069316582877383,
          1.0087639767315821,
          1.0061882155330601,
          1.0069729952941486,
          1.0062221904706212,
          1.0084267359459576,
          1.0159051435528483,
          1.014894709885682,
          1.014037820141994,
          1.0103897220330345,
          1.0076998097211856,
          1.0113631436450983,
          1.0197102250487273,
          1.021635371850171,
          1.025952966366768,
          1.0210011448428422,
          0.9919635980357909,
          0.9994420614104035,
          1.001316928724009,
          1.0102270676635203,
          1.007667003101678,
          1.0065087616997455,
          1.0090943142822029,
          1.0195198946379926,
          1.0167450022768327,
          1.022991609732749,
          1.0236436295005298,
          1.0250792482414306,
          1.0286183348486804,
          1.0346886797349315,
          1.0349271182936706,
          1.0351871048978636,
          1.0376339905434895,
          1.0367216050510142,
          1.0327396450755288
         ]
        },
        {
         "line": {
          "color": "rgba(50, 171, 96, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "1/N Model",
         "text": "",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477
         ],
         "y": [
          1.005443342664013,
          1.008572994842972,
          1.014449464317343,
          1.0182419050805815,
          1.0185056900797973,
          1.0156959100764915,
          1.024812748553089,
          1.0309717887089722,
          1.0246954300306539,
          1.033650034225885,
          1.0312830197699063,
          1.0381040743734162,
          1.0443933846164353,
          1.047401484570692,
          1.0472057042226137,
          1.0469113994063004,
          1.0570299319192908,
          1.0496729636655506,
          1.0392336873748804,
          1.0394948393540526,
          0.9799002432619366,
          0.9442233563075461,
          0.9563128311974386,
          0.9538936707193497,
          0.9213029108110568,
          0.9336559864593101,
          0.944993631808935,
          0.9482296317511052,
          0.9620262346937991,
          0.9724224459133792,
          0.9726636698055255,
          0.9666233403404936,
          0.9612472701000855,
          0.9618554811462964,
          0.9766986401078889,
          0.9838713997955385,
          0.9709029137407595,
          0.960967103349419,
          1.006637391318661,
          1.0182918740912303,
          1.0233566074903748,
          1.0230489824093478,
          1.0266332853020017,
          1.0430616777644697,
          1.041904152761347,
          1.0377558722405456,
          1.0322213478591742,
          1.0299008297352743,
          1.0346559767326187,
          1.023049609813605,
          1.0242071506436974,
          1.0240319892338574,
          1.000661288083951,
          0.9812608980841633,
          1.004147585646594,
          0.9915547020001465,
          0.9902604723839443,
          1.0031956391844399,
          1.0120855571192562,
          1.0237142253482234,
          1.030206273864736,
          1.0082529142879362,
          1.0097221411078974,
          1.0248020659480968,
          1.0199819822643068,
          1.0255497429835476,
          1.0228367293687626,
          1.0329481517202699,
          1.0422999720724024,
          1.0450880028621745,
          1.0381663131205339,
          1.030850620716514,
          1.0321077802688658,
          1.0215061894192192,
          1.0242093051479066,
          1.031826827764115,
          1.0345327923640886,
          1.0255201508922966,
          0.9915081423965098,
          0.9893456720051855,
          1.0015518731092998,
          1.0031625245204687,
          1.002745545855196,
          1.0105739380670804,
          1.019207918181998,
          1.0201642360730336,
          1.020254158032857,
          1.015104967630127,
          1.0204150165834929,
          1.0215050070187917,
          1.0200053287735218,
          1.0269378286644042,
          1.0225753929322008,
          1.0250539506109553,
          1.0247416479065519,
          1.0229103578466423,
          1.012397414182743,
          1.0252901479231717,
          1.0159122350862542,
          1.0049707293291201,
          1.0067162930964415,
          1.0146520394856335,
          1.0148123194974803,
          1.0197855207330582,
          1.0220715852394695,
          1.025252026199786,
          1.0194412925483314,
          1.0224356439857285,
          1.0231684267722703,
          1.0214622661620296,
          1.0170888879712843,
          1.0194812164897868,
          1.0138124426665334,
          1.0164836211060189,
          1.0052648449439585,
          1.0060772778011176,
          0.9973863134626133,
          1.0015625918050255,
          1.0025701151438495,
          0.9982900353087949,
          1.0064154550811855,
          1.0141002127462522,
          1.0220657755366178,
          1.0251172080882731,
          1.0171563659789877,
          1.023029778866516,
          1.024056586060722,
          1.020991849637657,
          1.0252014612395055,
          1.0277807822498775,
          1.0273917820305858,
          1.0239961043450088,
          1.0242534919054636,
          1.0233192454314328,
          1.0317973943658245,
          1.0356221043654523,
          1.0291183453508002,
          1.0235975562790818,
          1.0313620709825542,
          1.0052388779847212,
          1.0102684338695789,
          1.0129083644459322,
          1.0156618363361558,
          1.013681128727133,
          1.0123523932420353,
          1.0049170911083092,
          1.0002877965784476,
          1.008574022523303,
          1.0016073674123194,
          1.009623867504817,
          1.0149053151148397,
          1.0194891832432407,
          1.0227594401259996,
          1.0206623423086392,
          1.01800610514766,
          1.0238791046646516,
          1.029895813977138,
          1.0302380224622194,
          1.0342582005818266,
          1.027697307843729,
          1.028602829164031,
          1.000072716663728,
          0.9981090620476213,
          0.9948700718092104,
          0.9989255346686817,
          0.9999562768732599,
          1.0018175885682377,
          1.0063573217405315,
          1.0076126076335372,
          1.0038142017004836,
          1.0083064563406972,
          1.0082097981021694,
          1.014821971077671,
          1.0158551660959105,
          1.0083411158500215,
          1.0055043859794313,
          1.0010459519965522,
          1.0012659063617126,
          1.0029669710973295,
          0.9982820629657406,
          0.998130361492734,
          0.9910422748441834,
          0.9861629356813625,
          0.9870935366751656,
          0.9820778777729959,
          0.9542963116748875,
          0.9338997950355324,
          0.9424956363454339,
          0.9417732507613,
          0.9605637795052012,
          0.958299443023155,
          0.9458454581073856,
          0.943812124039161,
          0.9384269211576811,
          0.9329431296673716,
          0.9089103702148211,
          0.9208861534367766,
          0.9068471292603368,
          0.9064343688431429,
          0.9248943003964439,
          0.9306163391612574,
          0.9968136676413681,
          1.0034241116703817,
          1.0108538588177591,
          1.0270077392364376,
          1.0251075122154008,
          1.016976085275572,
          1.0010168196476705,
          1.0009627313350096,
          0.9950631290882429,
          1.0042223729636834,
          1.0073820053570375,
          0.9937351026403017,
          0.9774116425691708,
          0.982765508998034,
          0.9797371074358034,
          0.9932464476726408,
          0.9934103674713658,
          1.0122120144927764,
          1.0090327367402445,
          1.0152598215329245,
          0.9684241112549253,
          0.9665977466689051,
          0.9455534751437957,
          0.9442768673179054,
          0.9428311319580917,
          0.9479558639419493,
          0.9436930928246507,
          0.9300744441972718,
          0.9100602645644033,
          0.9094673912330824,
          0.8960326585683293,
          0.8818218546658511,
          0.8657919306444628,
          0.8425123473785396,
          0.8802645541358531,
          0.8880187823194293,
          0.8865810053232152,
          0.8938660890485721,
          0.9805450126719798,
          1.01237314956618,
          1.0229162416580715,
          1.0340003635559638,
          1.0408615872322298,
          1.0476040698272857,
          1.0487511009973736,
          1.0434327240887262,
          1.0510882967570403,
          1.0535284494758133,
          1.063043081242437,
          1.0788287556950427,
          1.0647208238870658,
          1.0644314743958507,
          1.0693335674309268,
          1.0801500998657867,
          1.0756644971693083,
          1.0775101385605288,
          1.0895527054572538,
          1.0981041743473015,
          1.005462348515306,
          1.0097743034981717,
          1.0086895452471127,
          1.0032095415882458,
          1.0049132792405115,
          1.007324547883383,
          1.019545440167558,
          1.0237384337235433,
          1.0217227747235904,
          1.0331986965019213,
          1.035162276931138,
          1.0384265782034852,
          1.0351313385584764,
          1.0410225585377952,
          1.0408459775737358,
          1.0382025924357072,
          1.0384997869242865,
          1.0365150386358755,
          0.9949240275479585,
          0.9919403672720388,
          0.9839148218534932,
          0.9766845003425241,
          0.9740782268574915,
          0.9869922564969158,
          0.9899149573065528,
          0.995978094687409,
          0.9947090117673436,
          0.9981155462206186,
          1.002512158511703,
          1.0007164145966823,
          0.9946177584254281,
          1.007754438579759,
          0.9880675836504316,
          0.9884087033827774,
          0.9964729163234572,
          0.9932479810878121,
          0.9985286854512843,
          1.0046588990506224,
          0.9992204969722017,
          1.0020236629464987,
          1.0051378083692273,
          1.011692578057859,
          1.0123058963155103,
          1.0042062504684555,
          1.0096629850214445,
          1.0111747840219765,
          1.0182635050485496,
          1.016142302424912,
          1.015956003952552,
          1.010407006429896,
          1.0127254622699744,
          1.0103416510975394,
          1.0196017462718763,
          1.0193225411006401,
          1.0141294565210652,
          1.0206066430531708,
          1.0205750586335423,
          1.023935313688307,
          1.0009367100509614,
          1.010079988127478,
          1.0055868996577517,
          0.9893482419632176,
          0.9874125287269507,
          0.9862168131668447,
          0.9903796014697095,
          0.9668323746499007,
          0.9758714671237488,
          0.9789857902310706,
          0.986051702902669,
          0.9796630262605792,
          0.9736525703131335,
          0.9837872644070002,
          0.9792849989119821,
          0.9676698724818218,
          0.9696548610511231,
          0.9596268217017132,
          0.952712617917459,
          0.9540795039396539,
          0.9441386802366818,
          1.022423667171756,
          1.0301187461748647,
          1.034938668567928,
          1.0425112845197415,
          1.0467121065730371,
          1.0458482569679406,
          1.0439971895821865,
          1.0506764495964311,
          1.0478105421958888,
          1.046887678857214,
          1.0573726409979483,
          1.0614464762668727,
          1.0711774504498746,
          1.0685033785621145,
          1.064291935439254,
          1.056880155684432,
          1.0545504431353594,
          1.061264226008105,
          1.0708290944221477,
          1.0003469677598489,
          1.0097489754652786,
          1.0082754806143486,
          1.0029662161579784,
          1.0027255421103332,
          1.0039314114784175,
          1.0057589549113686,
          1.0129756448833842,
          1.011942460936397,
          1.0106149256231074,
          1.0022850210003191,
          1.0058531886297322,
          1.000794517022307,
          1.0010378726703573,
          1.0099166601943672,
          1.0164600758926907,
          1.0102090821384249,
          1.0159881747385613,
          1.0137768761793824,
          1.0140742509528244,
          1.0046368515543038,
          0.9921821962186009,
          0.9639471208637771,
          0.974900254085206,
          0.9764612300409367,
          0.994441177863714,
          0.9864482807697572,
          0.9740849617605101,
          0.9864440866441988,
          0.956485090422442,
          0.9572229169744378,
          0.9722258546497455,
          0.9839545692720564,
          0.9757594906954808,
          0.9839053536219673,
          0.9844562336275365,
          0.9584856616109824,
          0.9670462298142577,
          0.9622078011011312,
          0.9697398026616689,
          0.9826812985229402,
          0.9844037369284769,
          1.011692419811061,
          1.026928319470596,
          1.0293950186672747,
          1.035119409754866,
          1.0408297897989018,
          1.0491452692152132,
          1.04969576230964,
          1.0504971856263567,
          1.0509933307636476,
          1.0507850777040468,
          1.0495488036818401,
          1.0468264144984143,
          1.0428303457046617,
          1.043325260541347,
          1.0351635867662856,
          1.041310235557371,
          1.0392017043846284,
          1.035209853711937,
          1.0403179839497725,
          0.981395113932634,
          0.9882544437148923,
          1.000007762710438,
          0.9951065474000065,
          0.9775799096047503,
          0.985985753868158,
          0.993100279306108,
          1.0072753432469257,
          1.004822852186623,
          1.013674030476082,
          1.0117738590409537,
          1.0155822240700514,
          1.0144326956726346,
          1.0217892399219795,
          1.0217267689708056,
          1.024843465264599,
          1.0254867710945779,
          1.0292494594090904,
          1.031757201886155,
          1.0343489068403935,
          1.0346404818200796,
          1.0291176957393835,
          1.0051818384430729,
          1.005019907861984,
          1.0044199810328494,
          1.006932606789332,
          1.0087693595630758,
          1.0062295273290982,
          1.007016080224759,
          1.006272074760273,
          1.0084543859873978,
          1.0159690373838683,
          1.0149793776971234,
          1.0142057872778334,
          1.010598332627208,
          1.0078916160338123,
          1.0115022078076934,
          1.0198950201812902,
          1.021827479397883,
          1.026159116029552,
          1.0212031931862264,
          0.9919897289748665,
          0.9994713791624729,
          1.001321433020612,
          1.0102513318815265,
          1.0076599842521878,
          1.0065037973301556,
          1.009102725435664,
          1.019507518852647,
          1.0167783504260837,
          1.023021562283747,
          1.0236297269276766,
          1.0250692198185642,
          1.0286186133052613,
          1.0346978669924138,
          1.034931247447906,
          1.0351898582574872,
          1.0376339130988324,
          1.036738145716607,
          1.032728182705108
         ]
        },
        {
         "line": {
          "color": "rgba(128, 0, 128, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "S&P 500",
         "text": "",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477
         ],
         "y": [
          1.0063988187678174,
          1.0104532331222378,
          1.01756052613646,
          1.0192520618530718,
          1.0205800775224427,
          1.0194449608291194,
          1.0266153766139654,
          1.0335446225887093,
          1.0299019074919185,
          1.0395984871573627,
          1.0379180905786511,
          1.0424696056080711,
          1.0508789228462483,
          1.053163917658637,
          1.0525741713615295,
          1.0532084745811838,
          1.0656797230238397,
          1.0585055944403243,
          1.0469691373757133,
          1.0474810899872826,
          0.9787914523050585,
          0.9386813371369133,
          0.9550528040953712,
          0.9502760228653357,
          0.9146060632223194,
          0.9282667019487502,
          0.9411831475856182,
          0.943642392884729,
          0.9562895208774654,
          0.9678310868101905,
          0.9681925422447539,
          0.9625369525123278,
          0.9572463650149637,
          0.9581782933130517,
          0.9735363356475689,
          0.9849822173437246,
          0.9724661579633176,
          0.9616758790755133,
          1.005071602697713,
          1.016159579134265,
          1.0188410806669994,
          1.0183480893579684,
          1.02289305656995,
          1.0406697424149502,
          1.0393439449479687,
          1.0327300001691544,
          1.0268181142903392,
          1.0260152139842424,
          1.0277629768289267,
          1.0131644306530774,
          1.014665743031788,
          1.0127947099523045,
          0.9873098694051805,
          0.9666090613837801,
          0.9928595108594567,
          0.9757065632079799,
          0.9728607617380555,
          0.9862567806817226,
          1.0126148657086849,
          1.0243272579849914,
          1.0313570764980473,
          1.0087494728739093,
          1.0121152146565606,
          1.029044819045906,
          1.0233589712662865,
          1.031802450431812,
          1.0288240233366426,
          1.037166796810276,
          1.0482245556115208,
          1.0490960136583551,
          1.0430887589823636,
          1.0341843981903012,
          1.0342425519413678,
          1.0204038059039324,
          1.022278348182939,
          1.0329450097814639,
          1.0340953231711592,
          1.0256286771649166,
          0.9927941364144521,
          0.990556701620733,
          1.0032469010248992,
          1.0067160741565893,
          1.0064486487434146,
          1.016193306164882,
          1.0257156914795584,
          1.0274671992820958,
          1.0283749557818398,
          1.0213386699391316,
          1.0254858786918764,
          1.0246081937600573,
          1.0219112252999667,
          1.0294598310819911,
          1.0262316900386654,
          1.029565311342211,
          1.0274822810205553,
          1.0250602786545306,
          1.0132062894955904,
          1.0260697452623868,
          1.0190108370003281,
          1.0044795984363044,
          1.0051853388746206,
          1.013797156235869,
          1.0130731138039089,
          1.016239883457275,
          1.0173259469223745,
          1.0190995380584336,
          1.01499651295076,
          1.0175051272030116,
          1.0164702200206917,
          1.0143090745060876,
          1.0102281010902103,
          1.0119577672952513,
          1.005536378857846,
          1.0074086217219176,
          0.9935822716687778,
          0.9957727005926209,
          0.9872047185704218,
          0.9933043504338407,
          0.9940576755436773,
          0.995052649459258,
          1.003630802740886,
          1.0121428782208493,
          1.0210730007304945,
          1.0246194600673186,
          1.01735060188897,
          1.0262514455236553,
          1.0273590147346074,
          1.0263027502102562,
          1.0303809679741733,
          1.0326071189351556,
          1.0285252300803842,
          1.0275497277211143,
          1.0294384148472329,
          1.03436006848548,
          1.0437744053116034,
          1.040609372314535,
          1.0337806764626405,
          1.0278321266601336,
          1.032852807699117,
          1.0049264450595978,
          1.0095935073980913,
          1.0131656786160577,
          1.016027043209936,
          1.0157604580692234,
          1.0142960621713257,
          1.0070804736124737,
          1.0030461173380103,
          1.0094548344287018,
          1.001780792294429,
          1.0097143035233918,
          1.013069701211911,
          1.015529452447731,
          1.0176301120772238,
          1.017224940696154,
          1.0155045466420984,
          1.021799496569033,
          1.0296371171228813,
          1.0299143763326282,
          1.0357863651188828,
          1.031197490780373,
          1.0313361637497624,
          0.9971968733321512,
          0.9935548060610239,
          0.9913557267355201,
          0.9932371481551123,
          0.9969516977518016,
          0.99730728234759,
          1.0025753131385442,
          1.0028515041435464,
          0.9972659000251012,
          1.0026202353268479,
          1.0038767917204379,
          1.0117477800203973,
          1.0113749176067663,
          1.0078192390796339,
          1.0065039383125098,
          1.003193266899322,
          1.0059653777973,
          1.0059584665320758,
          0.9996033098775927,
          1.0003145473287949,
          0.9921424950818614,
          0.9866579524562761,
          0.9862681077376338,
          0.9848696744950467,
          0.9525026920627381,
          0.9329068467389267,
          0.9461599060852729,
          0.9405728516576987,
          0.96079102966583,
          0.9605482739364328,
          0.9467241376357972,
          0.9463822093757982,
          0.9423132131602848,
          0.9371193427227399,
          0.908195684892166,
          0.925110865656466,
          0.9090812254028265,
          0.9031180167222123,
          0.9172669681153622,
          0.9272205363502554,
          0.9936833138368367,
          0.9992482555596338,
          1.005502845731112,
          1.026828411076269,
          1.0242521842534016,
          1.0148300745026697,
          0.994836410632192,
          0.9933621429867606,
          0.9858449635108176,
          0.996288761895005,
          0.9985038163368646,
          0.981885608556284,
          0.9640631667273433,
          0.9669970912180984,
          0.9606585777113843,
          0.9755798804019727,
          0.9787619217422666,
          1.0012479781394434,
          0.9990621456627131,
          1.007225230226082,
          0.9676350970612119,
          0.966162135472726,
          0.9436311197422418,
          0.9452939432407204,
          0.9449570911527936,
          0.950078289560467,
          0.9498883402068774,
          0.9317580973076341,
          0.9124022385020405,
          0.9124810706966155,
          0.8984327726729308,
          0.884262595477043,
          0.8660571951645509,
          0.8425764323077432,
          0.8843629509812443,
          0.8919354686452154,
          0.8908280571297416,
          0.8983934004766292,
          0.9752432698883858,
          1.0087289441747151,
          1.0158005727189647,
          1.025649048918211,
          1.029852205405627,
          1.034505509097238,
          1.034354163099138,
          1.028916019793164,
          1.0399477372149,
          1.0422584860637139,
          1.0501706874200907,
          1.0640151433024947,
          1.048951554993528,
          1.0512623038423419,
          1.052708552276846,
          1.0616446732558196,
          1.0533141306892309,
          1.0517802454545853,
          1.0681346509898666,
          1.0773178275788666,
          1.0067762366585589,
          1.0115165624123952,
          1.0092665064607713,
          0.9998226585351513,
          1.0004987397093463,
          1.001208196460029,
          1.0141139948903926,
          1.0171806702684842,
          1.0144834716703601,
          1.0255197866862462,
          1.0270567775769541,
          1.028881971070863,
          1.025253683967162,
          1.0318266902923765,
          1.0330977587686687,
          1.032281139342201,
          1.0317195276165916,
          1.0288043953566641,
          0.9961194417967204,
          0.9949922996852526,
          0.9885008718230445,
          0.9804685931210823,
          0.9783785388984994,
          0.9927274797038621,
          0.9956593199476047,
          1.0025787377178452,
          1.0017084767220341,
          1.0067018962137082,
          1.0104326800093903,
          1.01030075636313,
          1.0073260736501675,
          1.0182580610114618,
          0.9989371221273714,
          0.9980989930726437,
          1.0052680646971726,
          1.0005992731134172,
          1.0041909056447977,
          1.0109534084175678,
          1.0000174557671553,
          1.0021658701124747,
          1.004255020508249,
          1.0089111811654476,
          1.009967975470098,
          1.0038400002185275,
          1.0073312268920238,
          1.0073696293007466,
          1.0140276618667168,
          1.0133894641757184,
          1.013905642395667,
          1.0116002115954688,
          1.0131976216360477,
          1.0142229956295734,
          1.023189949870154,
          1.0209473596922052,
          1.0205706570592352,
          1.025352328759443,
          1.0264510163472285,
          1.0274275993632191,
          0.9978760145285372,
          1.0074938223262329,
          1.0029893290624603,
          0.9864283188695834,
          0.984844681860806,
          0.9818690476334619,
          0.9855218921413533,
          0.9617406998029281,
          0.9694499599446598,
          0.9751105541558941,
          0.9837844423649551,
          0.9780417646502367,
          0.9714405911041079,
          0.979693790669411,
          0.9769267475240655,
          0.9652874955299399,
          0.9665940693333113,
          0.9584981896994471,
          0.9518731343309619,
          0.953870612565939,
          0.9412839345034183,
          1.021432370802961,
          1.029769153185042,
          1.036087391196153,
          1.0469639233001995,
          1.0518428215271907,
          1.051474802791913,
          1.0493323396007523,
          1.0536318550631134,
          1.0519339144618276,
          1.052914053304957,
          1.063145640144341,
          1.0663193037765843,
          1.0764196778023158,
          1.0750642255017029,
          1.0732023358366578,
          1.0630107799695856,
          1.0616990949090916,
          1.065758157088725,
          1.0718942092305626,
          1.0029281260087797,
          1.010622970172487,
          1.0087978846193795,
          1.0039198984911424,
          1.00516130275557,
          1.0096952732130933,
          1.0120026559336488,
          1.0166782850421827,
          1.0168570873300702,
          1.0133959309372158,
          1.0067771953430888,
          1.0103834688412185,
          1.0041425983871153,
          1.0069830114917453,
          1.013878310416685,
          1.0186315219785724,
          1.0132710740588453,
          1.0207568075689852,
          1.0191071478241773,
          1.016479222190047,
          1.0054143110172231,
          0.9927172599946105,
          0.9631563039768206,
          0.9756937263621089,
          0.976441962374194,
          0.994762262933215,
          0.9881803124694816,
          0.9760085772476247,
          0.9907772347757092,
          0.9617546422813407,
          0.9641246634964737,
          0.9780332460813522,
          0.9898731847660052,
          0.982038608343735,
          0.9901372830014966,
          0.9896361992346404,
          0.9639587650585846,
          0.974545912560365,
          0.9714242658642347,
          0.977782704028637,
          0.9901881186022634,
          0.9908245989725447,
          1.0108420789476402,
          1.0239929461199893,
          1.0249253993956144,
          1.0248290459948386,
          1.0251593528807763,
          1.0325709281479636,
          1.0355438576901401,
          1.0347936951157761,
          1.0315490096821769,
          1.0342122137020153,
          1.0345666298412286,
          1.0345872951612392,
          1.0295223937932652,
          1.0294225961151402,
          1.0207585935184373,
          1.027045008364364,
          1.0245504018928016,
          1.0191035308549894,
          1.024247564581078,
          0.9820967968710144,
          0.9899259869058753,
          1.0039996632939374,
          0.9995034568489072,
          0.9839503644247936,
          0.992908732930873,
          0.9992789330839211,
          1.010210022957231,
          1.0088087414335511,
          1.018852115296318,
          1.016814876626137,
          1.0196241649519595,
          1.0156279061304307,
          1.0226069113170644,
          1.0189575682339933,
          1.0218586922880701,
          1.0238211169118265,
          1.0279908337726376,
          1.0337283979253455,
          1.0328679170138584,
          1.0362282186888858,
          1.033095845251253,
          1.0037040892383409,
          1.0025139978744835,
          1.0032182611433682,
          1.0059571427020124,
          1.0085330729466828,
          1.0065538599361377,
          1.0081287604511808,
          1.0088460788801936,
          1.009690526247189,
          1.0174605875413794,
          1.0179725256305474,
          1.0173692809793886,
          1.0135478544177075,
          1.0119436592697673,
          1.0141445716518327,
          1.0217580505833912,
          1.0240013923173887,
          1.0282760085846303,
          1.024151367378019,
          0.9933619048889829,
          0.999643496048875,
          1.001143212422562,
          1.0102893806729702,
          1.0070940158612913,
          1.0059893002274503,
          1.0089148760086188,
          1.017566548682094,
          1.0176404056482997,
          1.024914280649169,
          1.0252579266458848,
          1.0248147074530016,
          1.0293846552881123,
          1.0344747372133245,
          1.035370740866389,
          1.035168379503736,
          1.0404768953951842,
          1.040512255893812,
          1.0344972391152558
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"cfa77f81-d74f-4738-8fe7-e004697dbd66\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';                                    if (document.getElementById(\"cfa77f81-d74f-4738-8fe7-e004697dbd66\")) {                    Plotly.newPlot(                        \"cfa77f81-d74f-4738-8fe7-e004697dbd66\",                        [{\"line\":{\"color\":\"rgba(255, 153, 51, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"Deep NNF\",\"text\":\"\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477],\"y\":[1.0052614857834639,1.0084491674487412,1.0142009504115734,1.017902308074024,1.0180746436428654,1.0154131380639717,1.0247094331874467,1.030843718889444,1.0244855110363562,1.0332377766176526,1.03075912796234,1.037513817072758,1.043927958751617,1.0469001543975522,1.0467333938384307,1.046364041361339,1.0564274903930269,1.0490097873585458,1.0384752740953824,1.0385596752053499,0.97965241520258,0.944017859030801,0.9560996824924406,0.9536487382501361,0.9213468654859587,0.9334940834728545,0.9447539986869904,0.9480652100724067,0.9618004540340327,0.9720687706377219,0.972272553730843,0.9661289069453146,0.9606852156705036,0.9614534824905001,0.9763167946535767,0.9834826786488629,0.9703666520716796,0.9603749997079983,1.006605149776329,1.0182330933772095,1.0232866194100372,1.022678502453561,1.026226185108125,1.0425931672307078,1.0414296530841831,1.0373137742651473,1.0316757363431304,1.0292112524516113,1.0340955596686083,1.0224605238899833,1.0234269927831763,1.0233938081505893,1.000084139975636,0.9806804255101035,1.0034237655060114,0.9911736853317589,0.9900740334954169,1.0029830871603398,1.0121429032031142,1.0238002706326135,1.0302535330647082,1.0085214186115106,1.009901335837784,1.0248304534739692,1.0200953517320848,1.0254465645343296,1.0227960935059774,1.0329167756087552,1.0419766291070114,1.0446573988270003,1.037870131038925,1.030467923075697,1.031838741169796,1.021647904649229,1.0244664430483565,1.0319388134660534,1.0347354674988098,1.0256354286163314,0.991348424243541,0.9886715585742407,1.000911005309212,1.002395486266622,1.0016528680217456,1.0093722781614127,1.0179414805059122,1.0190619880384413,1.019266611498096,1.0143568427344825,1.0198317031562576,1.0210094657695585,1.0191894090983167,1.0261340301484732,1.0219216852822595,1.0239849233994205,1.0236018892592758,1.0217413202166041,1.0111664480499314,1.024191155056835,1.0146257845513265,1.0048890631623826,1.0065497590326646,1.0144122814876912,1.0147821388484057,1.019790518361892,1.0222904670072546,1.0254004195593354,1.0194275112999085,1.0224198747405626,1.0231548556653038,1.021355100500933,1.017121471402682,1.019556444336148,1.0139649952402092,1.0169022808466341,1.0060063173069962,1.0067225456082394,0.9982577209751607,1.0022953601939801,1.0033281192246937,0.9985175680052494,1.0066181742753475,1.0142894095323107,1.0220101938533823,1.025193590313207,1.017242018651957,1.022748348188744,1.0238094141674978,1.020808330733986,1.0247233702999354,1.0272000695653,1.0270330303233326,1.0234401863350673,1.0237088270160397,1.0228893894759077,1.03139588518069,1.0354641735790076,1.0291056667620782,1.0244071165877846,1.032307834032368,1.005098165098463,1.0103767234920609,1.0128644027063856,1.0155095711902102,1.0134000835365613,1.012095816021469,1.0047117699579597,1.0000942888216053,1.0083544199486612,1.001660524019301,1.0098197758088125,1.0153413725589258,1.019952010936845,1.0230281503838228,1.020714923740984,1.0179811480223584,1.0235658618282162,1.0294412262193626,1.0297930845955023,1.0337334981237984,1.0272528343649485,1.028136910902094,1.0003198472418529,0.9983448955777545,0.9950513424274149,0.9991139616026786,1.00004004242509,1.0019602683129705,1.0064966885103752,1.0076819348770027,1.0040494932196697,1.0084822083280205,1.008383921841993,1.0150083988947356,1.0161011708638676,1.0084340599796342,1.005513366965772,1.0011017113288354,1.0013030710538398,1.003087316045087,0.9983924477231207,0.9981259922961737,0.9911847793561614,0.9864232517709809,0.9876996562664848,0.9826369695384791,0.9551634148534562,0.9346859141216146,0.9430504589881289,0.9425229838805597,0.9611457602462626,0.9588402274899721,0.9465573292542164,0.9448039681258592,0.9393265529442194,0.9338800852857836,0.9101714469231581,0.9220473916828065,0.9079596683131069,0.9079617800847989,0.9263558859546538,0.9317586889065106,0.9967828100167494,1.0035157669818897,1.0109440017008469,1.027017457635606,1.025154689952993,1.0171058190769053,1.0013212042607034,1.0012612124405567,0.9953716824792816,1.0044165043337225,1.0077102296746219,0.9943204921565405,0.9779477436033922,0.9832841881230341,0.9802768451813877,0.9936586734459564,0.9938662202898869,1.0124708550064774,1.0093184316631445,1.015514859352665,0.9686914449705049,0.9668174800114988,0.9460251080203935,0.9445785350546079,0.9431596911217416,0.9481954378659851,0.9439833679923255,0.9304611405817514,0.910436319358875,0.9097372353790436,0.8964026397197572,0.8821879368536604,0.8662154626032498,0.8428825768944975,0.8804407821247875,0.8881247618925826,0.8866597968848721,0.8938972494524229,0.9808486872399637,1.01241905303651,1.0228425809679746,1.0338505669270746,1.0406883758496686,1.047372634488866,1.048616923712189,1.043387129231076,1.0509371983590003,1.0533644326679383,1.0628889479374506,1.078541593896889,1.0645286631778192,1.0643182527197286,1.0689776215085551,1.079740663316358,1.0755773757165612,1.077660402477209,1.0894141037130372,1.0978469747821953,1.005392981775413,1.0096179375243832,1.0086372881694468,1.0032443679473584,1.0047168623088623,1.0071775761153976,1.0192098429818195,1.0234597659628695,1.021342499295029,1.032802758830653,1.0348198954157852,1.0380893253210517,1.034858088389277,1.0405590091253847,1.0402444799359116,1.0376549788310785,1.0379235040406716,1.0359862503772843,0.9949897036237253,0.9920607470646623,0.9841064904160441,0.9768512058298642,0.9742490400486465,0.9870730880387721,0.9899565759941926,0.995990471063664,0.9947241355343185,0.998060140974603,1.002499416535422,1.0005785862179366,0.9944104350747448,1.0073793617360416,0.9878553452443154,0.9882392266341179,0.9963166272527236,0.9932089731919039,0.9984513297124727,1.004544902242652,0.9991606232395414,1.0018145086266605,1.0050904103806941,1.0116453083847459,1.012248422664534,1.0042054183291254,1.0096289143613923,1.011148300386931,1.0182600507123758,1.0161606788994766,1.0158964167482596,1.0103810147179497,1.0126443109614216,1.01012768737109,1.0194330121382698,1.0192235417216122,1.014027097470233,1.020532051431396,1.0205017866936508,1.023879959230471,1.0009224680734277,1.0101142765604416,1.0056080255366802,0.9894065574040191,0.9874677255368343,0.9862874398677416,0.9904475018493334,0.9669346816588362,0.9759374967058008,0.9790306587489778,0.9860881903782144,0.9797089197471122,0.9737017691613727,0.9838445977274801,0.9793190186510655,0.9677177706229602,0.9697053261364375,0.959624231118305,0.9527371704491219,0.9540954710268221,0.9441894881577285,1.0224272047690266,1.0299757855817813,1.0347345446237879,1.0422083172471726,1.0462701917114325,1.0455503136539013,1.043669322973296,1.0505472301190584,1.047715942295683,1.046774921225463,1.0571546494583632,1.0611336551237613,1.0708497114962388,1.0681994407395976,1.0638942670703024,1.056575137673839,1.0542497438097878,1.06091293280422,1.0705828281482679,1.0002890684128556,1.0097195922652455,1.0082468211056896,1.0029717187681173,1.0026498192873718,1.003779370858949,1.0054771997331364,1.0127258684704825,1.011657019235343,1.0104177974082453,1.0019580010041715,1.0055312856644403,1.0004944441593135,1.000654319290037,1.0096733331809649,1.0163128370858698,1.0100545755865842,1.015766859060316,1.013558760619922,1.0139547855953797,1.0045632198800099,0.9922728714351761,0.9642210454206004,0.9750352509303156,0.97666345079814,0.9944893274189989,0.9865718167744497,0.9742973732367428,0.986575242290647,0.9566763473097685,0.9574231414256875,0.9723758988451103,0.9840883791363589,0.9758639884988703,0.9839978701466378,0.9845324141609766,0.9586241450151496,0.967143169188909,0.9622701983375394,0.9698578750561604,0.9827564004088865,0.9844452361834303,1.011683663480542,1.026565988096503,1.0291847040571802,1.0352114029889439,1.0411386503765785,1.0493494634026659,1.0498264921902938,1.0506588800912997,1.0509511666185636,1.050745290470583,1.049518243961455,1.0467823495287094,1.0428585047469165,1.0434154220434826,1.0355170665619775,1.041529648412371,1.0395139359222616,1.0358804134791588,1.0409127339219169,0.9813405921682496,0.9880829283487721,0.9998211278458836,0.9949246272803186,0.9775520261850829,0.9859041946232612,0.9930685422928449,1.0071376285642326,1.0046535041630686,1.0134012879943672,1.0116685869377025,1.0154213314445497,1.0144048631159273,1.0217160656936033,1.0219005298586459,1.0249915868609396,1.0254171744288783,1.0290247378537547,1.0313843776172429,1.033910514588886,1.034072189510118,1.0286044728863615,1.005084857992515,1.004975956795784,1.0044652076984701,1.0068411386747345,1.0086581791961429,1.0060582283346136,1.0067066075346878,1.0060174570862357,1.0081614749873795,1.0155700258942881,1.0146212690307521,1.0137095442804818,1.0101233045436078,1.007436920810464,1.0110905203100802,1.019325174525517,1.021234907018718,1.0255179434281505,1.0205829127811032,0.9919507429641717,0.9994558667666772,1.0013055982504826,1.010248407867184,1.0076816473090635,1.0065194738261176,1.0091064756016208,1.0195378062978895,1.01677930364838,1.0230352275691161,1.0236854348919073,1.0251144433888206,1.0286405328362622,1.034675655166382,1.0348720600247008,1.0351206303606058,1.0375642420701898,1.036654947505087,1.0326751318855802],\"type\":\"scatter\"},{\"line\":{\"color\":\"rgba(55, 128, 191, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"Shallow NNF\",\"text\":\"\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477],\"y\":[1.0052431152115084,1.008365832087296,1.014170454155317,1.0179256146414053,1.0181193282785184,1.01541288171817,1.0246383116820927,1.0307791787236054,1.0244662670676186,1.0332487465651452,1.030805341824563,1.0375752534680316,1.0439635321165353,1.0469604830476258,1.0468748189152313,1.0465223848007934,1.0565661525431502,1.0491916017238803,1.0387033443108151,1.0387658703062612,0.9799102795337883,0.9442441342767885,0.9563331787514424,0.953901021230094,0.9213467150840441,0.9336837525505507,0.944994780405784,0.948198614004465,0.9619789881772642,0.9723630413440117,0.9726264834533345,0.96654936418151,0.9611359400975273,0.9617498459343999,0.9765788428736158,0.9837631999693311,0.9707266817115734,0.9607983521629028,1.0066433338243,1.0182582312285857,1.0233299900796808,1.0229792948398262,1.026521109250897,1.042920663497424,1.0417731509488428,1.0376332018380183,1.0320632778225394,1.029731340440271,1.034479426635454,1.0228585510588493,1.0239680894724223,1.0238140333814774,1.0004676173262503,0.9810645650544007,1.0039239635682127,0.9913958947456025,0.990164224228598,1.0030935159061132,1.0121274349551368,1.0237548065625637,1.0302451559693144,1.0083698375852506,1.0098308568270251,1.0248290365475472,1.0200332929046483,1.0255493631714974,1.0228472458164768,1.0329944221422311,1.042242242993656,1.0450004820655052,1.0381785403725723,1.0307888955136366,1.0321115530119445,1.0216838026583053,1.0244279709368802,1.0319908498005699,1.0347599148739655,1.02570131173408,0.9914802182448923,0.9891677422408576,1.0013703274092884,1.0029447514428773,1.0024552832880653,1.0102477654672348,1.0188621411474654,1.0198786005736296,1.0199811393338332,1.014880863101429,1.020267425407474,1.021357597477873,1.0197516290863584,1.0266804569452401,1.0224075893356324,1.0247869967709697,1.0245014626848903,1.0226349744143393,1.0120911925814309,1.0250087204838465,1.0155991067086192,1.0049513705376505,1.0066650917819728,1.014556789626653,1.014795741098083,1.0197562773320052,1.0220747868629874,1.0252140547504254,1.0194015203972946,1.0224341856722805,1.0231800872127204,1.0214683345778814,1.0171422795254352,1.0195201096164666,1.0138480553158964,1.0166084427879087,1.0054776006400203,1.0062685650366876,0.9976493104494459,1.0017924361190549,1.002792205965778,0.9983958388182474,1.006498859245815,1.0141487518782306,1.0219640169266804,1.0250633731261685,1.0171318828355465,1.0228715466791292,1.0239248533850052,1.0208743164981988,1.0249638059025323,1.0274807672526771,1.0272455403597698,1.0237239524607133,1.0240049840495815,1.023136067244534,1.031622924439384,1.0355521213739134,1.0290593541505648,1.0238390836505575,1.0316303668473261,1.005128115946471,1.010261514965213,1.0128560881812902,1.0156068227157098,1.0135956099188468,1.0122985542147613,1.0048981437281086,1.0002805908781485,1.008581714312188,1.0017965552759134,1.0098284199244334,1.0152242577356796,1.0198150818249416,1.0230180953873789,1.0207715383324296,1.0181203309737235,1.0238762526369203,1.0297978490693416,1.0301436187082906,1.03410107567535,1.0274905508572278,1.028399516417202,1.0001774956573657,0.998216462641457,0.9949580411823075,0.9990037727684288,1.0000231501816352,1.0019001167937023,1.0064326310193703,1.0076606189051245,1.0039045053703313,1.0083772358674765,1.0082675799664504,1.0148603019520759,1.0159124365601846,1.0083194423820154,1.005481917878715,1.0010262484291188,1.0012607376920932,1.0029963527256403,0.9983201551517088,0.9981369859925285,0.9910750272222546,0.9862031576537372,0.9871797162476169,0.9821623119433494,0.954405047605125,0.9340070755912114,0.9425990575610509,0.941935832074736,0.9607122318261859,0.9584353918863084,0.9460156917172604,0.944043291520717,0.9386453808873056,0.9331487722222949,0.9091275340635804,0.9210207896245509,0.9069578588879973,0.9065709388824897,0.9249705018898289,0.9306803040551023,0.9968189050495588,1.0034951743254388,1.0109639097714647,1.0270564890256062,1.025189881346755,1.0171639581731138,1.0013590006055795,1.0012798107616765,0.9953585295644923,1.0044343041276316,1.0076242500639,0.9942162188073268,0.9778134858004172,0.9831356378838533,0.9801007534467426,0.9935146976680048,0.9937553418263583,1.0124310891192365,1.0092813271662677,1.0154810153496723,0.9685397841752222,0.9667101696331001,0.9457293564587463,0.9443990701260105,0.9429046809109527,0.9479696144145836,0.9437371824400258,0.9301500889318302,0.910141053801554,0.9094984397609663,0.8961480395812985,0.8819807311149122,0.865979225482273,0.8426817435668384,0.8803162878299314,0.888047789205243,0.8866174183278371,0.8938777085415883,0.9808731268770668,1.0124688760677618,1.0228304781971973,1.0338697816509497,1.040716211168738,1.0474434956264942,1.0486793791441025,1.0434606527272932,1.0510723111681584,1.0535815258517165,1.0630908373418146,1.0787636662644555,1.0648342220271223,1.0646019498541897,1.0691613521056262,1.0798251923736548,1.0756041315669558,1.077681888696385,1.0894381845620846,1.0979125543562187,1.0054394549727204,1.0097295813510685,1.0087052450320393,1.0032696564571717,1.004914407432053,1.0073707779076204,1.0195817503676692,1.0237996994923215,1.0216820110494222,1.0331394750774485,1.0351115074120543,1.0383559143836394,1.0350912753125703,1.0409309537531788,1.0407228643331476,1.038087931863231,1.0383551039529588,1.0364178028688853,0.9949499197187561,0.991985884361278,0.9840081178867911,0.9767570607937659,0.9741439713313009,0.9870220432970871,0.9899255543276948,0.9959667358522959,0.9947063329721424,0.998058231932655,1.0024784711179004,1.0006240345638202,0.9944820929145577,1.0075487530836105,0.9879199561498582,0.9882728567675926,0.9963365345389332,0.9931489611274077,0.9984288059797218,1.004564662522556,0.9991864788022979,1.001940100168984,1.005078393737089,1.0116389935095684,1.0122367427513592,1.0041383954841112,1.0095338535372291,1.0110804892463083,1.0181777812755968,1.01607944832113,1.015881617886253,1.0104193130336145,1.0127266840323341,1.0103098818241505,1.0195997204661111,1.019325388345153,1.014114906079125,1.0205890595432183,1.0205410061352558,1.023899391363427,1.0009765587823272,1.010123562404756,1.0056186552988702,0.9894192509723764,0.9874621706083923,0.9862653966057969,0.9904438168011829,0.9669622956076719,0.9759586438992158,0.9790404951879024,0.9860817475766663,0.9797038550716121,0.9737356498596783,0.9838136025531551,0.9792971323364111,0.9677193178108291,0.96971856174582,0.9596358640118507,0.9527453395749059,0.9540808219250454,0.9441195234692066,1.0224549132098624,1.0300296524837,1.0348173126332874,1.042332628094179,1.0464669518086605,1.0457257740164132,1.0437861044118386,1.0505699136847364,1.0476983744565072,1.0467569517818918,1.0572146483343547,1.0611807738230525,1.0709544666721114,1.0683213219435426,1.0640551871195436,1.0567503262472944,1.0544450965112246,1.0611289542120517,1.0707725726120159,1.0003148649749452,1.0097236073328495,1.008275899242583,1.0030046848051348,1.0027434671887938,1.003931790938494,1.0057334044441757,1.013011483168829,1.0119745724323785,1.0106860607710912,1.0022879296207345,1.0058593648540701,1.0008563660957592,1.0010656040161423,1.010002261343367,1.0166050079317561,1.0103618881360439,1.0161415774220102,1.0139168913432004,1.0143301582878017,1.0048978099592676,0.9922608596179271,0.9640722336381142,0.9749263604396826,0.9765379859908709,0.9944625098841529,0.9864893559253675,0.9741362424904956,0.9864483902116462,0.9565073948554045,0.9572319146060786,0.9722187940786512,0.9839469761512458,0.975755794571921,0.9838705607005147,0.9844324859009927,0.9584548867647814,0.9670046707483638,0.9621424383036475,0.9697141758469058,0.9826228694189602,0.9843527326752574,1.011697460526082,1.0268220065502323,1.0292891685781622,1.03510076051156,1.0408666621211309,1.049160990233188,1.0496738925510236,1.0504828567776399,1.0509248391063923,1.050730820518943,1.0494626899826787,1.0467246071503384,1.0427414807717357,1.043239304141504,1.0351379759126615,1.04124767043228,1.0391790408232562,1.035263537581497,1.0403458185775367,0.9813775462188732,0.9881354391037058,0.9998598638695213,0.9949393266273125,0.9774703281260708,0.9858484753728328,0.9929843683282522,1.0071394496604202,1.0046668332461266,1.0134802356351773,1.0116913988012897,1.015473342162419,1.0144183539248584,1.02175894380886,1.0218190651141663,1.0249271642562503,1.0254671959249755,1.029128311755664,1.0315389436293587,1.0340655633426175,1.0342834131173608,1.028756615137783,1.0052466879340067,1.005093040923814,1.0044917269166869,1.0069316582877383,1.0087639767315821,1.0061882155330601,1.0069729952941486,1.0062221904706212,1.0084267359459576,1.0159051435528483,1.014894709885682,1.014037820141994,1.0103897220330345,1.0076998097211856,1.0113631436450983,1.0197102250487273,1.021635371850171,1.025952966366768,1.0210011448428422,0.9919635980357909,0.9994420614104035,1.001316928724009,1.0102270676635203,1.007667003101678,1.0065087616997455,1.0090943142822029,1.0195198946379926,1.0167450022768327,1.022991609732749,1.0236436295005298,1.0250792482414306,1.0286183348486804,1.0346886797349315,1.0349271182936706,1.0351871048978636,1.0376339905434895,1.0367216050510142,1.0327396450755288],\"type\":\"scatter\"},{\"line\":{\"color\":\"rgba(50, 171, 96, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"1/N Model\",\"text\":\"\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477],\"y\":[1.005443342664013,1.008572994842972,1.014449464317343,1.0182419050805815,1.0185056900797973,1.0156959100764915,1.024812748553089,1.0309717887089722,1.0246954300306539,1.033650034225885,1.0312830197699063,1.0381040743734162,1.0443933846164353,1.047401484570692,1.0472057042226137,1.0469113994063004,1.0570299319192908,1.0496729636655506,1.0392336873748804,1.0394948393540526,0.9799002432619366,0.9442233563075461,0.9563128311974386,0.9538936707193497,0.9213029108110568,0.9336559864593101,0.944993631808935,0.9482296317511052,0.9620262346937991,0.9724224459133792,0.9726636698055255,0.9666233403404936,0.9612472701000855,0.9618554811462964,0.9766986401078889,0.9838713997955385,0.9709029137407595,0.960967103349419,1.006637391318661,1.0182918740912303,1.0233566074903748,1.0230489824093478,1.0266332853020017,1.0430616777644697,1.041904152761347,1.0377558722405456,1.0322213478591742,1.0299008297352743,1.0346559767326187,1.023049609813605,1.0242071506436974,1.0240319892338574,1.000661288083951,0.9812608980841633,1.004147585646594,0.9915547020001465,0.9902604723839443,1.0031956391844399,1.0120855571192562,1.0237142253482234,1.030206273864736,1.0082529142879362,1.0097221411078974,1.0248020659480968,1.0199819822643068,1.0255497429835476,1.0228367293687626,1.0329481517202699,1.0422999720724024,1.0450880028621745,1.0381663131205339,1.030850620716514,1.0321077802688658,1.0215061894192192,1.0242093051479066,1.031826827764115,1.0345327923640886,1.0255201508922966,0.9915081423965098,0.9893456720051855,1.0015518731092998,1.0031625245204687,1.002745545855196,1.0105739380670804,1.019207918181998,1.0201642360730336,1.020254158032857,1.015104967630127,1.0204150165834929,1.0215050070187917,1.0200053287735218,1.0269378286644042,1.0225753929322008,1.0250539506109553,1.0247416479065519,1.0229103578466423,1.012397414182743,1.0252901479231717,1.0159122350862542,1.0049707293291201,1.0067162930964415,1.0146520394856335,1.0148123194974803,1.0197855207330582,1.0220715852394695,1.025252026199786,1.0194412925483314,1.0224356439857285,1.0231684267722703,1.0214622661620296,1.0170888879712843,1.0194812164897868,1.0138124426665334,1.0164836211060189,1.0052648449439585,1.0060772778011176,0.9973863134626133,1.0015625918050255,1.0025701151438495,0.9982900353087949,1.0064154550811855,1.0141002127462522,1.0220657755366178,1.0251172080882731,1.0171563659789877,1.023029778866516,1.024056586060722,1.020991849637657,1.0252014612395055,1.0277807822498775,1.0273917820305858,1.0239961043450088,1.0242534919054636,1.0233192454314328,1.0317973943658245,1.0356221043654523,1.0291183453508002,1.0235975562790818,1.0313620709825542,1.0052388779847212,1.0102684338695789,1.0129083644459322,1.0156618363361558,1.013681128727133,1.0123523932420353,1.0049170911083092,1.0002877965784476,1.008574022523303,1.0016073674123194,1.009623867504817,1.0149053151148397,1.0194891832432407,1.0227594401259996,1.0206623423086392,1.01800610514766,1.0238791046646516,1.029895813977138,1.0302380224622194,1.0342582005818266,1.027697307843729,1.028602829164031,1.000072716663728,0.9981090620476213,0.9948700718092104,0.9989255346686817,0.9999562768732599,1.0018175885682377,1.0063573217405315,1.0076126076335372,1.0038142017004836,1.0083064563406972,1.0082097981021694,1.014821971077671,1.0158551660959105,1.0083411158500215,1.0055043859794313,1.0010459519965522,1.0012659063617126,1.0029669710973295,0.9982820629657406,0.998130361492734,0.9910422748441834,0.9861629356813625,0.9870935366751656,0.9820778777729959,0.9542963116748875,0.9338997950355324,0.9424956363454339,0.9417732507613,0.9605637795052012,0.958299443023155,0.9458454581073856,0.943812124039161,0.9384269211576811,0.9329431296673716,0.9089103702148211,0.9208861534367766,0.9068471292603368,0.9064343688431429,0.9248943003964439,0.9306163391612574,0.9968136676413681,1.0034241116703817,1.0108538588177591,1.0270077392364376,1.0251075122154008,1.016976085275572,1.0010168196476705,1.0009627313350096,0.9950631290882429,1.0042223729636834,1.0073820053570375,0.9937351026403017,0.9774116425691708,0.982765508998034,0.9797371074358034,0.9932464476726408,0.9934103674713658,1.0122120144927764,1.0090327367402445,1.0152598215329245,0.9684241112549253,0.9665977466689051,0.9455534751437957,0.9442768673179054,0.9428311319580917,0.9479558639419493,0.9436930928246507,0.9300744441972718,0.9100602645644033,0.9094673912330824,0.8960326585683293,0.8818218546658511,0.8657919306444628,0.8425123473785396,0.8802645541358531,0.8880187823194293,0.8865810053232152,0.8938660890485721,0.9805450126719798,1.01237314956618,1.0229162416580715,1.0340003635559638,1.0408615872322298,1.0476040698272857,1.0487511009973736,1.0434327240887262,1.0510882967570403,1.0535284494758133,1.063043081242437,1.0788287556950427,1.0647208238870658,1.0644314743958507,1.0693335674309268,1.0801500998657867,1.0756644971693083,1.0775101385605288,1.0895527054572538,1.0981041743473015,1.005462348515306,1.0097743034981717,1.0086895452471127,1.0032095415882458,1.0049132792405115,1.007324547883383,1.019545440167558,1.0237384337235433,1.0217227747235904,1.0331986965019213,1.035162276931138,1.0384265782034852,1.0351313385584764,1.0410225585377952,1.0408459775737358,1.0382025924357072,1.0384997869242865,1.0365150386358755,0.9949240275479585,0.9919403672720388,0.9839148218534932,0.9766845003425241,0.9740782268574915,0.9869922564969158,0.9899149573065528,0.995978094687409,0.9947090117673436,0.9981155462206186,1.002512158511703,1.0007164145966823,0.9946177584254281,1.007754438579759,0.9880675836504316,0.9884087033827774,0.9964729163234572,0.9932479810878121,0.9985286854512843,1.0046588990506224,0.9992204969722017,1.0020236629464987,1.0051378083692273,1.011692578057859,1.0123058963155103,1.0042062504684555,1.0096629850214445,1.0111747840219765,1.0182635050485496,1.016142302424912,1.015956003952552,1.010407006429896,1.0127254622699744,1.0103416510975394,1.0196017462718763,1.0193225411006401,1.0141294565210652,1.0206066430531708,1.0205750586335423,1.023935313688307,1.0009367100509614,1.010079988127478,1.0055868996577517,0.9893482419632176,0.9874125287269507,0.9862168131668447,0.9903796014697095,0.9668323746499007,0.9758714671237488,0.9789857902310706,0.986051702902669,0.9796630262605792,0.9736525703131335,0.9837872644070002,0.9792849989119821,0.9676698724818218,0.9696548610511231,0.9596268217017132,0.952712617917459,0.9540795039396539,0.9441386802366818,1.022423667171756,1.0301187461748647,1.034938668567928,1.0425112845197415,1.0467121065730371,1.0458482569679406,1.0439971895821865,1.0506764495964311,1.0478105421958888,1.046887678857214,1.0573726409979483,1.0614464762668727,1.0711774504498746,1.0685033785621145,1.064291935439254,1.056880155684432,1.0545504431353594,1.061264226008105,1.0708290944221477,1.0003469677598489,1.0097489754652786,1.0082754806143486,1.0029662161579784,1.0027255421103332,1.0039314114784175,1.0057589549113686,1.0129756448833842,1.011942460936397,1.0106149256231074,1.0022850210003191,1.0058531886297322,1.000794517022307,1.0010378726703573,1.0099166601943672,1.0164600758926907,1.0102090821384249,1.0159881747385613,1.0137768761793824,1.0140742509528244,1.0046368515543038,0.9921821962186009,0.9639471208637771,0.974900254085206,0.9764612300409367,0.994441177863714,0.9864482807697572,0.9740849617605101,0.9864440866441988,0.956485090422442,0.9572229169744378,0.9722258546497455,0.9839545692720564,0.9757594906954808,0.9839053536219673,0.9844562336275365,0.9584856616109824,0.9670462298142577,0.9622078011011312,0.9697398026616689,0.9826812985229402,0.9844037369284769,1.011692419811061,1.026928319470596,1.0293950186672747,1.035119409754866,1.0408297897989018,1.0491452692152132,1.04969576230964,1.0504971856263567,1.0509933307636476,1.0507850777040468,1.0495488036818401,1.0468264144984143,1.0428303457046617,1.043325260541347,1.0351635867662856,1.041310235557371,1.0392017043846284,1.035209853711937,1.0403179839497725,0.981395113932634,0.9882544437148923,1.000007762710438,0.9951065474000065,0.9775799096047503,0.985985753868158,0.993100279306108,1.0072753432469257,1.004822852186623,1.013674030476082,1.0117738590409537,1.0155822240700514,1.0144326956726346,1.0217892399219795,1.0217267689708056,1.024843465264599,1.0254867710945779,1.0292494594090904,1.031757201886155,1.0343489068403935,1.0346404818200796,1.0291176957393835,1.0051818384430729,1.005019907861984,1.0044199810328494,1.006932606789332,1.0087693595630758,1.0062295273290982,1.007016080224759,1.006272074760273,1.0084543859873978,1.0159690373838683,1.0149793776971234,1.0142057872778334,1.010598332627208,1.0078916160338123,1.0115022078076934,1.0198950201812902,1.021827479397883,1.026159116029552,1.0212031931862264,0.9919897289748665,0.9994713791624729,1.001321433020612,1.0102513318815265,1.0076599842521878,1.0065037973301556,1.009102725435664,1.019507518852647,1.0167783504260837,1.023021562283747,1.0236297269276766,1.0250692198185642,1.0286186133052613,1.0346978669924138,1.034931247447906,1.0351898582574872,1.0376339130988324,1.036738145716607,1.032728182705108],\"type\":\"scatter\"},{\"line\":{\"color\":\"rgba(128, 0, 128, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"S&P 500\",\"text\":\"\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477],\"y\":[1.0063988187678174,1.0104532331222378,1.01756052613646,1.0192520618530718,1.0205800775224427,1.0194449608291194,1.0266153766139654,1.0335446225887093,1.0299019074919185,1.0395984871573627,1.0379180905786511,1.0424696056080711,1.0508789228462483,1.053163917658637,1.0525741713615295,1.0532084745811838,1.0656797230238397,1.0585055944403243,1.0469691373757133,1.0474810899872826,0.9787914523050585,0.9386813371369133,0.9550528040953712,0.9502760228653357,0.9146060632223194,0.9282667019487502,0.9411831475856182,0.943642392884729,0.9562895208774654,0.9678310868101905,0.9681925422447539,0.9625369525123278,0.9572463650149637,0.9581782933130517,0.9735363356475689,0.9849822173437246,0.9724661579633176,0.9616758790755133,1.005071602697713,1.016159579134265,1.0188410806669994,1.0183480893579684,1.02289305656995,1.0406697424149502,1.0393439449479687,1.0327300001691544,1.0268181142903392,1.0260152139842424,1.0277629768289267,1.0131644306530774,1.014665743031788,1.0127947099523045,0.9873098694051805,0.9666090613837801,0.9928595108594567,0.9757065632079799,0.9728607617380555,0.9862567806817226,1.0126148657086849,1.0243272579849914,1.0313570764980473,1.0087494728739093,1.0121152146565606,1.029044819045906,1.0233589712662865,1.031802450431812,1.0288240233366426,1.037166796810276,1.0482245556115208,1.0490960136583551,1.0430887589823636,1.0341843981903012,1.0342425519413678,1.0204038059039324,1.022278348182939,1.0329450097814639,1.0340953231711592,1.0256286771649166,0.9927941364144521,0.990556701620733,1.0032469010248992,1.0067160741565893,1.0064486487434146,1.016193306164882,1.0257156914795584,1.0274671992820958,1.0283749557818398,1.0213386699391316,1.0254858786918764,1.0246081937600573,1.0219112252999667,1.0294598310819911,1.0262316900386654,1.029565311342211,1.0274822810205553,1.0250602786545306,1.0132062894955904,1.0260697452623868,1.0190108370003281,1.0044795984363044,1.0051853388746206,1.013797156235869,1.0130731138039089,1.016239883457275,1.0173259469223745,1.0190995380584336,1.01499651295076,1.0175051272030116,1.0164702200206917,1.0143090745060876,1.0102281010902103,1.0119577672952513,1.005536378857846,1.0074086217219176,0.9935822716687778,0.9957727005926209,0.9872047185704218,0.9933043504338407,0.9940576755436773,0.995052649459258,1.003630802740886,1.0121428782208493,1.0210730007304945,1.0246194600673186,1.01735060188897,1.0262514455236553,1.0273590147346074,1.0263027502102562,1.0303809679741733,1.0326071189351556,1.0285252300803842,1.0275497277211143,1.0294384148472329,1.03436006848548,1.0437744053116034,1.040609372314535,1.0337806764626405,1.0278321266601336,1.032852807699117,1.0049264450595978,1.0095935073980913,1.0131656786160577,1.016027043209936,1.0157604580692234,1.0142960621713257,1.0070804736124737,1.0030461173380103,1.0094548344287018,1.001780792294429,1.0097143035233918,1.013069701211911,1.015529452447731,1.0176301120772238,1.017224940696154,1.0155045466420984,1.021799496569033,1.0296371171228813,1.0299143763326282,1.0357863651188828,1.031197490780373,1.0313361637497624,0.9971968733321512,0.9935548060610239,0.9913557267355201,0.9932371481551123,0.9969516977518016,0.99730728234759,1.0025753131385442,1.0028515041435464,0.9972659000251012,1.0026202353268479,1.0038767917204379,1.0117477800203973,1.0113749176067663,1.0078192390796339,1.0065039383125098,1.003193266899322,1.0059653777973,1.0059584665320758,0.9996033098775927,1.0003145473287949,0.9921424950818614,0.9866579524562761,0.9862681077376338,0.9848696744950467,0.9525026920627381,0.9329068467389267,0.9461599060852729,0.9405728516576987,0.96079102966583,0.9605482739364328,0.9467241376357972,0.9463822093757982,0.9423132131602848,0.9371193427227399,0.908195684892166,0.925110865656466,0.9090812254028265,0.9031180167222123,0.9172669681153622,0.9272205363502554,0.9936833138368367,0.9992482555596338,1.005502845731112,1.026828411076269,1.0242521842534016,1.0148300745026697,0.994836410632192,0.9933621429867606,0.9858449635108176,0.996288761895005,0.9985038163368646,0.981885608556284,0.9640631667273433,0.9669970912180984,0.9606585777113843,0.9755798804019727,0.9787619217422666,1.0012479781394434,0.9990621456627131,1.007225230226082,0.9676350970612119,0.966162135472726,0.9436311197422418,0.9452939432407204,0.9449570911527936,0.950078289560467,0.9498883402068774,0.9317580973076341,0.9124022385020405,0.9124810706966155,0.8984327726729308,0.884262595477043,0.8660571951645509,0.8425764323077432,0.8843629509812443,0.8919354686452154,0.8908280571297416,0.8983934004766292,0.9752432698883858,1.0087289441747151,1.0158005727189647,1.025649048918211,1.029852205405627,1.034505509097238,1.034354163099138,1.028916019793164,1.0399477372149,1.0422584860637139,1.0501706874200907,1.0640151433024947,1.048951554993528,1.0512623038423419,1.052708552276846,1.0616446732558196,1.0533141306892309,1.0517802454545853,1.0681346509898666,1.0773178275788666,1.0067762366585589,1.0115165624123952,1.0092665064607713,0.9998226585351513,1.0004987397093463,1.001208196460029,1.0141139948903926,1.0171806702684842,1.0144834716703601,1.0255197866862462,1.0270567775769541,1.028881971070863,1.025253683967162,1.0318266902923765,1.0330977587686687,1.032281139342201,1.0317195276165916,1.0288043953566641,0.9961194417967204,0.9949922996852526,0.9885008718230445,0.9804685931210823,0.9783785388984994,0.9927274797038621,0.9956593199476047,1.0025787377178452,1.0017084767220341,1.0067018962137082,1.0104326800093903,1.01030075636313,1.0073260736501675,1.0182580610114618,0.9989371221273714,0.9980989930726437,1.0052680646971726,1.0005992731134172,1.0041909056447977,1.0109534084175678,1.0000174557671553,1.0021658701124747,1.004255020508249,1.0089111811654476,1.009967975470098,1.0038400002185275,1.0073312268920238,1.0073696293007466,1.0140276618667168,1.0133894641757184,1.013905642395667,1.0116002115954688,1.0131976216360477,1.0142229956295734,1.023189949870154,1.0209473596922052,1.0205706570592352,1.025352328759443,1.0264510163472285,1.0274275993632191,0.9978760145285372,1.0074938223262329,1.0029893290624603,0.9864283188695834,0.984844681860806,0.9818690476334619,0.9855218921413533,0.9617406998029281,0.9694499599446598,0.9751105541558941,0.9837844423649551,0.9780417646502367,0.9714405911041079,0.979693790669411,0.9769267475240655,0.9652874955299399,0.9665940693333113,0.9584981896994471,0.9518731343309619,0.953870612565939,0.9412839345034183,1.021432370802961,1.029769153185042,1.036087391196153,1.0469639233001995,1.0518428215271907,1.051474802791913,1.0493323396007523,1.0536318550631134,1.0519339144618276,1.052914053304957,1.063145640144341,1.0663193037765843,1.0764196778023158,1.0750642255017029,1.0732023358366578,1.0630107799695856,1.0616990949090916,1.065758157088725,1.0718942092305626,1.0029281260087797,1.010622970172487,1.0087978846193795,1.0039198984911424,1.00516130275557,1.0096952732130933,1.0120026559336488,1.0166782850421827,1.0168570873300702,1.0133959309372158,1.0067771953430888,1.0103834688412185,1.0041425983871153,1.0069830114917453,1.013878310416685,1.0186315219785724,1.0132710740588453,1.0207568075689852,1.0191071478241773,1.016479222190047,1.0054143110172231,0.9927172599946105,0.9631563039768206,0.9756937263621089,0.976441962374194,0.994762262933215,0.9881803124694816,0.9760085772476247,0.9907772347757092,0.9617546422813407,0.9641246634964737,0.9780332460813522,0.9898731847660052,0.982038608343735,0.9901372830014966,0.9896361992346404,0.9639587650585846,0.974545912560365,0.9714242658642347,0.977782704028637,0.9901881186022634,0.9908245989725447,1.0108420789476402,1.0239929461199893,1.0249253993956144,1.0248290459948386,1.0251593528807763,1.0325709281479636,1.0355438576901401,1.0347936951157761,1.0315490096821769,1.0342122137020153,1.0345666298412286,1.0345872951612392,1.0295223937932652,1.0294225961151402,1.0207585935184373,1.027045008364364,1.0245504018928016,1.0191035308549894,1.024247564581078,0.9820967968710144,0.9899259869058753,1.0039996632939374,0.9995034568489072,0.9839503644247936,0.992908732930873,0.9992789330839211,1.010210022957231,1.0088087414335511,1.018852115296318,1.016814876626137,1.0196241649519595,1.0156279061304307,1.0226069113170644,1.0189575682339933,1.0218586922880701,1.0238211169118265,1.0279908337726376,1.0337283979253455,1.0328679170138584,1.0362282186888858,1.033095845251253,1.0037040892383409,1.0025139978744835,1.0032182611433682,1.0059571427020124,1.0085330729466828,1.0065538599361377,1.0081287604511808,1.0088460788801936,1.009690526247189,1.0174605875413794,1.0179725256305474,1.0173692809793886,1.0135478544177075,1.0119436592697673,1.0141445716518327,1.0217580505833912,1.0240013923173887,1.0282760085846303,1.024151367378019,0.9933619048889829,0.999643496048875,1.001143212422562,1.0102893806729702,1.0070940158612913,1.0059893002274503,1.0089148760086188,1.017566548682094,1.0176404056482997,1.024914280649169,1.0252579266458848,1.0248147074530016,1.0293846552881123,1.0344747372133245,1.035370740866389,1.035168379503736,1.0404768953951842,1.040512255893812,1.0344972391152558],\"type\":\"scatter\"}],                        {\"legend\":{\"bgcolor\":\"#F5F6F9\",\"font\":{\"color\":\"#4D5663\"}},\"paper_bgcolor\":\"#F5F6F9\",\"plot_bgcolor\":\"#F5F6F9\",\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"color\":\"#4D5663\"}},\"xaxis\":{\"gridcolor\":\"#E1E5ED\",\"showgrid\":true,\"tickfont\":{\"color\":\"#4D5663\"},\"title\":{\"font\":{\"color\":\"#4D5663\"},\"text\":\"\"},\"zerolinecolor\":\"#E1E5ED\"},\"yaxis\":{\"gridcolor\":\"#E1E5ED\",\"showgrid\":true,\"tickfont\":{\"color\":\"#4D5663\"},\"title\":{\"font\":{\"color\":\"#4D5663\"},\"text\":\"\"},\"zerolinecolor\":\"#E1E5ED\"}},                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('cfa77f81-d74f-4738-8fe7-e004697dbd66');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing a module for better and more interactive plot\n",
    "import cufflinks as cf\n",
    "cf.set_config_file(offline = True)\n",
    "\n",
    "'''\n",
    "plotting deep nnf, shallow nnf and, 1/n model performance on the test dataset, compare them with\n",
    "index (s&p) for better understanding\n",
    "'''\n",
    "plot_test.iplot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72a5606bcafec1593511b6d198bb0982fb8ea54acb1913d581966686ae52246b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
