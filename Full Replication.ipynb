{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta as rd\n",
    "import time\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks data csv read\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df.set_index('Date')\n",
    "\n",
    "# s&p data csv read\n",
    "df_sp = pd.read_csv('sp500.csv')\n",
    "df_sp = df_sp.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_slicer(df, start, duration, rebalancing_period=0):\n",
    "    '''\n",
    "    this function is used to slice out specific section of the data\n",
    "    '''\n",
    "    start = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=rebalancing_period))\n",
    "    end = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=duration) - rd(days=1))\n",
    "    return df.loc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(df):\n",
    "    '''\n",
    "    this function gets the dataframe as input, processes it, and ouputs the cumulative change of the stocks\n",
    "    that is used as input for training the model.\n",
    "    '''\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    df = df.cumprod()\n",
    "    df = df - 1\n",
    "    df = df.iloc[-1,:]\n",
    "    df = df.to_numpy()\n",
    "    df = torch.from_numpy(df).type(torch.Tensor)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_change(df):\n",
    "    '''\n",
    "    this function calculate the daily change of stocks included in the dataframe.\n",
    "    '''\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_return(df):\n",
    "    '''\n",
    "    this function calculate the daily return of stocks included in the dataframe, note that \n",
    "    daily return is equal to daily change + 1\n",
    "    '''\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf biuld\n",
    "class shallow_NNF(nn.Module):\n",
    "    '''\n",
    "    this class is used to train the data with Shallow NNF model, consisted of 2 fully connected layers, \n",
    "    a relU activation function in between and a softmax layer output that is translated into stock weights in portfolio.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_size, num_classes):\n",
    "        super(shallow_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size) # fully connected layer\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # fully connected layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.softmax(self.fc2(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf build\n",
    "class deep_NNF(nn.Module):\n",
    "    '''\n",
    "    this class is used to train the data with Deep NNF model, consisted of 6 fully connected layers, \n",
    "    relU activation functions in between and a softmax layer output that is translated into stock weights in portfolio.\n",
    "    dropout is also included in deep NNF model.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_size1, hidden_size2, hidden_size3,\n",
    "                 hidden_size4, hidden_size5, num_classes, dropout_p = 0.2):\n",
    "        super(deep_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size1) # fully connected layer\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2) # fully connected layer\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3) # fully connected layer\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4) # fully connected layer\n",
    "        self.fc5 = nn.Linear(hidden_size4, hidden_size5) # fully connected layer\n",
    "        self.fc6 = nn.Linear(hidden_size5, num_classes) # fully connected layer\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        self.fc3.reset_parameters()\n",
    "        self.fc4.reset_parameters()\n",
    "        self.fc5.reset_parameters()\n",
    "        self.fc6.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc4(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc5(out))\n",
    "        out = self.softmax(self.fc6(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/N model build\n",
    "class equal_w_model():\n",
    "    '''\n",
    "    this class is used to construct a portfolio with equal weights.\n",
    "    '''\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.performance()\n",
    "        \n",
    "    def performance(self):\n",
    "        self.df = np.array(self.df)\n",
    "        weights = np.ones((len(self.df), 1)) * (1/len(self.df))\n",
    "        cumulative_change = sum(np.multiply(weights, self.df.reshape(-1,1)))\n",
    "        return cumulative_change, weights.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebalancing period = one or three months\n",
    "rbp = 1\n",
    "\n",
    "# epochs\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size = 471\n",
    "num_classes = 471\n",
    "lr = 1e-2 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf tune\n",
    "'''\n",
    "loss function is set to MSE and Adam optimizer is used in this model.\n",
    "'''\n",
    "shallow_NNF = shallow_NNF(input_dim=input_dim, hidden_size=hidden_size, num_classes=num_classes)\n",
    "shallow_NNF_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "shallow_NNF_optimizer = torch.optim.Adam(shallow_NNF.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size1 = 471\n",
    "hidden_size2 = 471\n",
    "hidden_size3 = 471\n",
    "hidden_size4 = 471\n",
    "hidden_size5 = 471\n",
    "num_classes = 471\n",
    "lr = 1e-10 # learning rate\n",
    "# probability of a neuron being shutdown that shuffles every epoch minimizing the overfit phenomenon\n",
    "dropout_p = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf tune\n",
    "'''\n",
    "like in shallow NNF, loss function is set to MSE and Adam optimizer is used.\n",
    "'''\n",
    "deep_NNF = deep_NNF(input_dim=input_dim, hidden_size1=hidden_size1, hidden_size2=hidden_size2, \n",
    "                    hidden_size3=hidden_size3, hidden_size4=hidden_size4, hidden_size5=hidden_size5,\n",
    "                    num_classes=num_classes)\n",
    "deep_NNF_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "deep_NNF_optimizer = torch.optim.Adam(deep_NNF.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "def RMSE(x, y, weights):\n",
    "    '''\n",
    "    this function calculates the root mean squere error of constructed portfollio and benchmark index \n",
    "    that is used for evaluating trained models.\n",
    "    '''\n",
    "    temp = 0\n",
    "    for i in range(len(x)):\n",
    "        temp += (sum(x.iloc[i] * weights) - y.iloc[i]) ** 2\n",
    "    return math.sqrt(temp/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEAN\n",
    "def MEAN(x, weights):\n",
    "    '''\n",
    "    this function calculates the mean return of the constructed portfolio during the given period.\n",
    "    '''\n",
    "    temp = []\n",
    "    for i in range(len(x)):\n",
    "        temp.append(sum(x.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility\n",
    "def VOL(x, weights):\n",
    "    '''\n",
    "    this function calculates the volatility of the constructed portfolio during the given period.\n",
    "    '''\n",
    "    temp = []\n",
    "    for i in range(len(x)):\n",
    "        temp.append(sum(x.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_return(df, x_test, model, i, temp):   \n",
    "    '''\n",
    "    this function outputs the cumulative return of the portfolio test dataset of the given dataframe\n",
    "    ''' \n",
    "    x_return = date_slicer(df, '2018-01-01', 1, i)\n",
    "    x_return =  x_return.pct_change()\n",
    "    x_return =  x_return.tail(-1)\n",
    "    x_return =  x_return + 1\n",
    "    x_return =  x_return.cumprod()\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_test).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_test)[1].detach())\n",
    "    \n",
    "    for i in range(len(x_return)):\n",
    "        temp.append(sum(x_return.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_return(df_sp, i, temp):\n",
    "    '''\n",
    "    this function outputs the cumulative return of the benchmark index test dataset of the given dataframe\n",
    "    '''\n",
    "    y_return = date_slicer(df_sp, '2018-01-01', 1, i)\n",
    "    y_return = y_return.pct_change()\n",
    "    y_return = y_return.tail(-1)\n",
    "    y_return = y_return + 1\n",
    "    y_return = y_return.cumprod()\n",
    "    \n",
    "    for i in range(len(y_return)):\n",
    "        temp.append(sum(y_return.iloc[i]))\n",
    "    temp = np.array(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fun(x_valid, i, model):\n",
    "    '''\n",
    "    this function gets validation dataset, model and rebalaning period as input, then outputs the RMSE of given dataset.\n",
    "    '''\n",
    "    x_change = daily_change(date_slicer(df, '2017-07-01', 6, i))\n",
    "    y_change = daily_change(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    # x_return = daily_return(date_slicer(df, '2017-07-01', 6, i))\n",
    "    # y_return = daily_return(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_valid).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_valid)[1].detach())\n",
    "    \n",
    "    valid_rmse = RMSE(x_change, y_change, weights)\n",
    "    # valid_mean = MEAN(x_return, weights)\n",
    "    # valid_vol  = VOL(x_return, weights)\n",
    "    \n",
    "    print(f'Validation RMSE: {valid_rmse}')\n",
    "    # print(f'Validation MEAN: {valid_mean}')\n",
    "    # print(f'Validation VOL: {valid_vol}')\n",
    "    \n",
    "    return valid_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fun(x_test, i, model):\n",
    "    '''\n",
    "    this function gets test dataset, model and rebalaning period as input, then outputs the RMSE, Mean and volatility \n",
    "    of the given dataset.\n",
    "    '''\n",
    "    x_change = daily_change(date_slicer(df, '2018-01-01', 1, i))\n",
    "    y_change = daily_change(date_slicer(df_sp, '2018-01-01', 1, i))\n",
    "    x_return = daily_return(date_slicer(df, '2018-01-01', 1, i))\n",
    "    y_return = daily_return(date_slicer(df_sp, '2018-01-01', 1, i))\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_test).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_test)[1].detach())\n",
    "    \n",
    "    test_rmse = RMSE(x_change, y_change, weights)\n",
    "    test_mean = MEAN(x_return, weights)\n",
    "    test_vol  = VOL(x_return, weights)\n",
    "    test_dic = {'RMSE': test_rmse, 'MEAN': test_mean, 'VOL': test_vol} # a dictionary for storing the results\n",
    "    \n",
    "    print(f'Test RMSE: {test_rmse}')\n",
    "    print(f'Test MEAN: {test_mean}')\n",
    "    print(f'Test VOL: {test_vol}')\n",
    "    \n",
    "    return test_dic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deep NNF Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf training function\n",
    "'''\n",
    "this function is used to train the model using x_train & y_train given to it, printing MSE of trained model in first and last\n",
    " epich and also printing train time of the model\n",
    "'''\n",
    "def train_deep_nnf(x_train, y_train, i):\n",
    "    start_time_deep_nnf = time.time()\n",
    "    print(f'\\nDeep NNF Training & Results for model {(i/rbp)+1}:')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = deep_NNF(x_train)[0]\n",
    "        loss_deep_nnf = deep_NNF_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_deep_nnf.item()}')\n",
    "        deep_NNF_optimizer.zero_grad()\n",
    "        loss_deep_nnf.backward()\n",
    "        deep_NNF_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_deep_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deep NNF Training & Results for model 1.0:\n",
      "Epoch 1 of 100 | MSE: 0.04591207206249237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamidrezarahimzadeh/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 of 100 | MSE: 0.04603005573153496\n",
      "Training time: 1.22\n",
      "Validation RMSE: 0.0013773015225169115\n",
      "Test RMSE: 0.0014124789998141121\n",
      "Test MEAN: 1.00195311673848\n",
      "Test VOL: 0.005354001740402835\n",
      "\n",
      "Deep NNF Training & Results for model 2.0:\n",
      "Epoch 1 of 100 | MSE: 0.05343734845519066\n",
      "Epoch 100 of 100 | MSE: 0.053347084671258926\n",
      "Training time: 1.22\n",
      "Validation RMSE: 0.0014116157838104807\n",
      "Test RMSE: 0.0022292380175393998\n",
      "Test MEAN: 0.997938594308412\n",
      "Test VOL: 0.01546957423247805\n",
      "\n",
      "Deep NNF Training & Results for model 3.0:\n",
      "Epoch 1 of 100 | MSE: 0.04575419798493385\n",
      "Epoch 100 of 100 | MSE: 0.04557095468044281\n",
      "Training time: 1.18\n",
      "Validation RMSE: 0.001608785703561048\n",
      "Test RMSE: 0.0021150930197339373\n",
      "Test MEAN: 1.0002466574557312\n",
      "Test VOL: 0.01103983484387354\n",
      "\n",
      "Deep NNF Training & Results for model 4.0:\n",
      "Epoch 1 of 100 | MSE: 0.059435803443193436\n",
      "Epoch 100 of 100 | MSE: 0.05955417454242706\n",
      "Training time: 1.17\n",
      "Validation RMSE: 0.0017888651873876837\n",
      "Test RMSE: 0.0016161226390108095\n",
      "Test MEAN: 1.0013093044447194\n",
      "Test VOL: 0.008811655328159808\n",
      "\n",
      "Deep NNF Training & Results for model 5.0:\n",
      "Epoch 1 of 100 | MSE: 0.047005072236061096\n",
      "Epoch 100 of 100 | MSE: 0.04696932062506676\n",
      "Training time: 1.22\n",
      "Validation RMSE: 0.0017501031080217322\n",
      "Test RMSE: 0.0012539930535172565\n",
      "Test MEAN: 1.0007668594261698\n",
      "Test VOL: 0.006298318345349538\n",
      "\n",
      "Deep NNF Training & Results for model 6.0:\n",
      "Epoch 1 of 100 | MSE: 0.04955502599477768\n",
      "Epoch 100 of 100 | MSE: 0.049569010734558105\n",
      "Training time: 1.16\n",
      "Validation RMSE: 0.001701885284269512\n",
      "Test RMSE: 0.0012062148738656842\n",
      "Test MEAN: 1.000140536984501\n",
      "Test VOL: 0.004748374931335705\n",
      "\n",
      "Deep NNF Training & Results for model 7.0:\n",
      "Epoch 1 of 100 | MSE: 0.038871634751558304\n",
      "Epoch 100 of 100 | MSE: 0.038757164031267166\n",
      "Training time: 1.20\n",
      "Validation RMSE: 0.001680547967668349\n",
      "Test RMSE: 0.0026029941416977824\n",
      "Test MEAN: 1.0015832512626517\n",
      "Test VOL: 0.004982107704185747\n",
      "\n",
      "Deep NNF Training & Results for model 8.0:\n",
      "Epoch 1 of 100 | MSE: 0.03783009946346283\n",
      "Epoch 100 of 100 | MSE: 0.03792211040854454\n",
      "Training time: 1.18\n",
      "Validation RMSE: 0.0019141582175501196\n",
      "Test RMSE: 0.0011958354087457386\n",
      "Test MEAN: 1.001292539865422\n",
      "Test VOL: 0.004710285830174362\n",
      "\n",
      "Deep NNF Training & Results for model 9.0:\n",
      "Epoch 1 of 100 | MSE: 0.027760284021496773\n",
      "Epoch 100 of 100 | MSE: 0.027672234922647476\n",
      "Training time: 1.21\n",
      "Validation RMSE: 0.0017881153337469642\n",
      "Test RMSE: 0.0018837821608511773\n",
      "Test MEAN: 1.000169162764387\n",
      "Test VOL: 0.0035089416265782014\n",
      "\n",
      "Deep NNF Training & Results for model 10.0:\n",
      "Epoch 1 of 100 | MSE: 0.031141748651862144\n",
      "Epoch 100 of 100 | MSE: 0.03116106428205967\n",
      "Training time: 1.14\n",
      "Validation RMSE: 0.0017457163238777578\n",
      "Test RMSE: 0.003105421638951434\n",
      "Test MEAN: 0.9967947065990899\n",
      "Test VOL: 0.01264992987908858\n",
      "\n",
      "Deep NNF Training & Results for model 11.0:\n",
      "Epoch 1 of 100 | MSE: 0.036090556532144547\n",
      "Epoch 100 of 100 | MSE: 0.03608756512403488\n",
      "Training time: 1.15\n",
      "Validation RMSE: 0.0020711993315383364\n",
      "Test RMSE: 0.002477827028251002\n",
      "Test MEAN: 1.0008244315153232\n",
      "Test VOL: 0.009817151604466676\n",
      "\n",
      "Deep NNF Training & Results for model 12.0:\n",
      "Epoch 1 of 100 | MSE: 0.03404118865728378\n",
      "Epoch 100 of 100 | MSE: 0.03412588685750961\n",
      "Training time: 1.16\n",
      "Validation RMSE: 0.00228799841768947\n",
      "Test RMSE: 0.0021159497092578827\n",
      "Test MEAN: 0.9939235090537815\n",
      "Test VOL: 0.017119892063295925\n",
      "\n",
      "Deep NNF Training & Results for model 13.0:\n",
      "Epoch 1 of 100 | MSE: 0.035125020891427994\n",
      "Epoch 100 of 100 | MSE: 0.0351429283618927\n",
      "Training time: 1.15\n",
      "Validation RMSE: 0.0023790221371864043\n",
      "Test RMSE: 0.002590409441772519\n",
      "Test MEAN: 1.0047759750855447\n",
      "Test VOL: 0.010457817224498744\n",
      "\n",
      "Deep NNF Training & Results for model 14.0:\n",
      "Epoch 1 of 100 | MSE: 0.03391863405704498\n",
      "Epoch 100 of 100 | MSE: 0.03408525884151459\n",
      "Training time: 1.18\n",
      "Validation RMSE: 0.002330636914054238\n",
      "Test RMSE: 0.001396947239289976\n",
      "Test MEAN: 1.0020294887254046\n",
      "Test VOL: 0.004558173150714552\n",
      "\n",
      "Deep NNF Training & Results for model 15.0:\n",
      "Epoch 1 of 100 | MSE: 0.03601036220788956\n",
      "Epoch 100 of 100 | MSE: 0.036342620849609375\n",
      "Training time: 1.17\n",
      "Validation RMSE: 0.002398906911558007\n",
      "Test RMSE: 0.0014314849827398238\n",
      "Test MEAN: 1.000269715089041\n",
      "Test VOL: 0.007638716895903196\n",
      "\n",
      "Deep NNF Training & Results for model 16.0:\n",
      "Epoch 1 of 100 | MSE: 0.03937210142612457\n",
      "Epoch 100 of 100 | MSE: 0.03927314653992653\n",
      "Training time: 1.18\n",
      "Validation RMSE: 0.002306814516125057\n",
      "Test RMSE: 0.0019738173846858983\n",
      "Test MEAN: 1.0012019621739248\n",
      "Test VOL: 0.004406011544570898\n",
      "\n",
      "Deep NNF Training & Results for model 17.0:\n",
      "Epoch 1 of 100 | MSE: 0.02291029319167137\n",
      "Epoch 100 of 100 | MSE: 0.022843066602945328\n",
      "Training time: 1.21\n",
      "Validation RMSE: 0.002026268237764373\n",
      "Test RMSE: 0.0014760005339705712\n",
      "Test MEAN: 0.9972194567158693\n",
      "Test VOL: 0.00875510303221644\n",
      "\n",
      "Deep NNF Training & Results for model 18.0:\n",
      "Epoch 1 of 100 | MSE: 0.02305326797068119\n",
      "Epoch 100 of 100 | MSE: 0.023009099066257477\n",
      "Training time: 1.18\n",
      "Validation RMSE: 0.0018725517117411392\n",
      "Test RMSE: 0.0017196905141830228\n",
      "Test MEAN: 1.003640770453338\n",
      "Test VOL: 0.006678461778941843\n",
      "\n",
      "Deep NNF Training & Results for model 19.0:\n",
      "Epoch 1 of 100 | MSE: 0.020379506051540375\n",
      "Epoch 100 of 100 | MSE: 0.02036859840154648\n",
      "Training time: 1.16\n",
      "Validation RMSE: 0.001969704990618942\n",
      "Test RMSE: 0.0018673943247066549\n",
      "Test MEAN: 1.0002626160432988\n",
      "Test VOL: 0.005181787870334201\n",
      "\n",
      "Deep NNF Training & Results for model 20.0:\n",
      "Epoch 1 of 100 | MSE: 0.04237934201955795\n",
      "Epoch 100 of 100 | MSE: 0.04239603132009506\n",
      "Training time: 1.17\n",
      "Validation RMSE: 0.001823913588857829\n",
      "Test RMSE: 0.0013681709371625242\n",
      "Test MEAN: 0.9993199127326445\n",
      "Test VOL: 0.014308307264089486\n",
      "\n",
      "Deep NNF Training & Results for model 21.0:\n",
      "Epoch 1 of 100 | MSE: 0.04218906909227371\n",
      "Epoch 100 of 100 | MSE: 0.04200343042612076\n",
      "Training time: 1.28\n",
      "Validation RMSE: 0.0018296617496469498\n",
      "Test RMSE: 0.00220867818972881\n",
      "Test MEAN: 1.0021161939044227\n",
      "Test VOL: 0.005398017883856264\n",
      "\n",
      "Deep NNF Training & Results for model 22.0:\n",
      "Epoch 1 of 100 | MSE: 0.028263771906495094\n",
      "Epoch 100 of 100 | MSE: 0.02832220308482647\n",
      "Training time: 1.30\n",
      "Validation RMSE: 0.0019518348590802787\n",
      "Test RMSE: 0.0019738651297767223\n",
      "Test MEAN: 1.0013487106195016\n",
      "Test VOL: 0.007932622973470058\n",
      "\n",
      "Deep NNF Training & Results for model 23.0:\n",
      "Epoch 1 of 100 | MSE: 0.026714636012911797\n",
      "Epoch 100 of 100 | MSE: 0.02667141892015934\n",
      "Training time: 1.53\n",
      "Validation RMSE: 0.0019483047322523931\n",
      "Test RMSE: 0.0009321951634130287\n",
      "Test MEAN: 1.0011339947760123\n",
      "Test VOL: 0.0034536518866357473\n",
      "\n",
      "Deep NNF Training & Results for model 24.0:\n",
      "Epoch 1 of 100 | MSE: 0.017222054302692413\n",
      "Epoch 100 of 100 | MSE: 0.017259081825613976\n",
      "Training time: 2.58\n",
      "Validation RMSE: 0.0017508228946146451\n",
      "Test RMSE: 0.001315219852618145\n",
      "Test MEAN: 1.0017064594947553\n",
      "Test VOL: 0.004492480710913461\n",
      "\n",
      "Min Valid RMSE is: 0.0013773015225169115 for model i = 1\n",
      "Selected Model Test Results are:\n",
      "RMSE = 0.0014124789998141121\n",
      "MEAN = 1.00195311673848\n",
      "VOL = 0.005354001740402835\n"
     ]
    }
   ],
   "source": [
    "# deep nnf\n",
    "'''\n",
    "in this cell,firstly, train, validation and test datasets are sliced in each loop. then deep NNf model gets trained and\n",
    "then best model will be chosen. Also RMSE, Mean and volatility of all models and then the best model is printed.\n",
    "'''\n",
    "deep_nnf_valid_rmse_list = []\n",
    "deep_nnf_test_results = []\n",
    "deep_nnf_test_plot = [] # storing the deep model test data return for plotting later on\n",
    "index_test_plot = [] # storing the index test data return for plotting later on\n",
    "\n",
    "for i in range(int(24/rbp)):\n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i*rbp))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i*rbp))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i*rbp))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i*rbp))\n",
    "    x_test = data_process(date_slicer(df, '2018-01-01', 1, i*rbp))\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i*rbp))\n",
    "    train_deep_nnf(x_train, y_train, i*rbp)\n",
    "    deep_nnf_valid_rmse_list.append(valid_fun(x_valid, i*rbp, deep_NNF))\n",
    "    deep_nnf_test_results.append(test_fun(x_test, i*rbp, deep_NNF))\n",
    "    portfolio_return(df, x_test, deep_NNF, i, deep_nnf_test_plot)\n",
    "    index_return(df_sp, i, index_test_plot)\n",
    "    deep_NNF.reset_parameters()\n",
    "\n",
    "print(f'\\nMin Valid RMSE is: {min(deep_nnf_valid_rmse_list)} for model i = {deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))+1}')\n",
    "print('Selected Model Test Results are:')\n",
    "print('RMSE =', deep_nnf_test_results[deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))]['RMSE'])\n",
    "print('MEAN =', deep_nnf_test_results[deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))]['MEAN'])\n",
    "print('VOL =', deep_nnf_test_results[deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))]['VOL'])\n",
    "\n",
    "deep_best_result_index = deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))\n",
    "deep_nnf_test_plot = np.array(deep_nnf_test_plot).reshape(-1,1)\n",
    "index_test_plot = np.array(index_test_plot).reshape(-1,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Shallow NNF Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf training function\n",
    "'''\n",
    "this function is used to train the model using x_train & y_train given to it, printing MSE of trained model in first and last\n",
    "epoch and also printing train time of the model\n",
    "'''\n",
    "def train_shallow_nnf(x_train, y_train, i):\n",
    "    start_time_shallow_nnf = time.time()\n",
    "    print(f'\\nShallow NNF Training & Results for model {(i/rbp)+1}:')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = shallow_NNF(x_train)[0]\n",
    "        loss_shallow_nnf = shallow_NNF_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_shallow_nnf.item()}')\n",
    "        shallow_NNF_optimizer.zero_grad()\n",
    "        loss_shallow_nnf.backward()\n",
    "        shallow_NNF_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_shallow_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shallow NNF Training & Results for model 1.0:\n",
      "Epoch 1 of 100 | MSE: 0.04515352472662926\n",
      "Epoch 100 of 100 | MSE: 2.395228875684552e-05\n",
      "Training time: 1.06\n",
      "Validation RMSE: 0.00491036790348907\n",
      "Test RMSE: 0.003911203078241354\n",
      "Test MEAN: 1.0010024477980122\n",
      "Test VOL: 0.004704220264448412\n",
      "\n",
      "Shallow NNF Training & Results for model 2.0:\n",
      "Epoch 1 of 100 | MSE: 0.051357485353946686\n",
      "Epoch 100 of 100 | MSE: 6.790323823224753e-07\n",
      "Training time: 1.49\n",
      "Validation RMSE: 0.00805324842634709\n",
      "Test RMSE: 0.003316657018021812\n",
      "Test MEAN: 0.9974118026919273\n",
      "Test VOL: 0.014810658035143486\n",
      "\n",
      "Shallow NNF Training & Results for model 3.0:\n",
      "Epoch 1 of 100 | MSE: 0.045442190021276474\n",
      "Epoch 100 of 100 | MSE: 0.0011111318599432707\n",
      "Training time: 1.09\n",
      "Validation RMSE: 0.009907707259388155\n",
      "Test RMSE: 0.0030436030251882523\n",
      "Test MEAN: 1.0001808368873146\n",
      "Test VOL: 0.011150956745009048\n",
      "\n",
      "Shallow NNF Training & Results for model 4.0:\n",
      "Epoch 1 of 100 | MSE: 0.05762476846575737\n",
      "Epoch 100 of 100 | MSE: 0.03032963164150715\n",
      "Training time: 0.88\n",
      "Validation RMSE: 0.009231528271078681\n",
      "Test RMSE: 0.007276818824132668\n",
      "Test MEAN: 1.000917197392642\n",
      "Test VOL: 0.008376762882884336\n",
      "\n",
      "Shallow NNF Training & Results for model 5.0:\n",
      "Epoch 1 of 100 | MSE: 0.04508083313703537\n",
      "Epoch 100 of 100 | MSE: 0.00014589073543902487\n",
      "Training time: 1.12\n",
      "Validation RMSE: 0.011238500639979903\n",
      "Test RMSE: 0.007059554484813161\n",
      "Test MEAN: 1.0011107553194796\n",
      "Test VOL: 0.008645330669999349\n",
      "\n",
      "Shallow NNF Training & Results for model 6.0:\n",
      "Epoch 1 of 100 | MSE: 0.05625779926776886\n",
      "Epoch 100 of 100 | MSE: 0.005442459601908922\n",
      "Training time: 0.91\n",
      "Validation RMSE: 0.013856563813694912\n",
      "Test RMSE: 0.0026749832135706027\n",
      "Test MEAN: 1.000772853475007\n",
      "Test VOL: 0.004774407931317925\n",
      "\n",
      "Shallow NNF Training & Results for model 7.0:\n",
      "Epoch 1 of 100 | MSE: 0.03859590366482735\n",
      "Epoch 100 of 100 | MSE: 0.007067754399031401\n",
      "Training time: 0.96\n",
      "Validation RMSE: 0.011784441821155617\n",
      "Test RMSE: 0.013244908220194172\n",
      "Test MEAN: 1.0010087343951297\n",
      "Test VOL: 0.011211548242584739\n",
      "\n",
      "Shallow NNF Training & Results for model 8.0:\n",
      "Epoch 1 of 100 | MSE: 0.03929710388183594\n",
      "Epoch 100 of 100 | MSE: 7.000672485446557e-05\n",
      "Training time: 0.83\n",
      "Validation RMSE: 0.007405994177273435\n",
      "Test RMSE: 0.00893769041368567\n",
      "Test MEAN: 1.000164967533482\n",
      "Test VOL: 0.00845069986191062\n",
      "\n",
      "Shallow NNF Training & Results for model 9.0:\n",
      "Epoch 1 of 100 | MSE: 0.026033470407128334\n",
      "Epoch 100 of 100 | MSE: 0.0027148621156811714\n",
      "Training time: 0.72\n",
      "Validation RMSE: 0.012109463488614264\n",
      "Test RMSE: 0.0028823804216097505\n",
      "Test MEAN: 1.0003589825193777\n",
      "Test VOL: 0.004006756803230203\n",
      "\n",
      "Shallow NNF Training & Results for model 10.0:\n",
      "Epoch 1 of 100 | MSE: 0.02989465370774269\n",
      "Epoch 100 of 100 | MSE: 0.000605866895057261\n",
      "Training time: 0.69\n",
      "Validation RMSE: 0.01962619934352468\n",
      "Test RMSE: 0.008450097413593288\n",
      "Test MEAN: 0.9945185081143703\n",
      "Test VOL: 0.015869473697312828\n",
      "\n",
      "Shallow NNF Training & Results for model 11.0:\n",
      "Epoch 1 of 100 | MSE: 0.03954996541142464\n",
      "Epoch 100 of 100 | MSE: 0.000824745453428477\n",
      "Training time: 0.70\n",
      "Validation RMSE: 0.006089658705754462\n",
      "Test RMSE: 0.008790730497347339\n",
      "Test MEAN: 1.0023611333694618\n",
      "Test VOL: 0.009738736309897713\n",
      "\n",
      "Shallow NNF Training & Results for model 12.0:\n",
      "Epoch 1 of 100 | MSE: 0.04132217913866043\n",
      "Epoch 100 of 100 | MSE: 0.010678594931960106\n",
      "Training time: 0.69\n",
      "Validation RMSE: 0.0088440452401986\n",
      "Test RMSE: 0.007167633192858705\n",
      "Test MEAN: 0.9937936188558649\n",
      "Test VOL: 0.018217431391978747\n",
      "\n",
      "Shallow NNF Training & Results for model 13.0:\n",
      "Epoch 1 of 100 | MSE: 0.04314024746417999\n",
      "Epoch 100 of 100 | MSE: 0.0022930616978555918\n",
      "Training time: 0.68\n",
      "Validation RMSE: 0.008596965544713496\n",
      "Test RMSE: 0.006782072284853121\n",
      "Test MEAN: 1.001425591922026\n",
      "Test VOL: 0.010464823420581642\n",
      "\n",
      "Shallow NNF Training & Results for model 14.0:\n",
      "Epoch 1 of 100 | MSE: 0.0366533063352108\n",
      "Epoch 100 of 100 | MSE: 0.011402367614209652\n",
      "Training time: 0.71\n",
      "Validation RMSE: 0.006096665037712275\n",
      "Test RMSE: 0.0065344936752232815\n",
      "Test MEAN: 0.9990423218297377\n",
      "Test VOL: 0.008389839709500403\n",
      "\n",
      "Shallow NNF Training & Results for model 15.0:\n",
      "Epoch 1 of 100 | MSE: 0.028630314394831657\n",
      "Epoch 100 of 100 | MSE: 0.016561225056648254\n",
      "Training time: 0.70\n",
      "Validation RMSE: 0.003927206273122629\n",
      "Test RMSE: 0.009777907257869544\n",
      "Test MEAN: 1.001608426285744\n",
      "Test VOL: 0.00824400587177854\n",
      "\n",
      "Shallow NNF Training & Results for model 16.0:\n",
      "Epoch 1 of 100 | MSE: 0.03763806074857712\n",
      "Epoch 100 of 100 | MSE: 0.0016599162481725216\n",
      "Training time: 0.78\n",
      "Validation RMSE: 0.008441692341780823\n",
      "Test RMSE: 0.007960597217704271\n",
      "Test MEAN: 0.9996731726748834\n",
      "Test VOL: 0.007175858038872038\n",
      "\n",
      "Shallow NNF Training & Results for model 17.0:\n",
      "Epoch 1 of 100 | MSE: 0.02486419677734375\n",
      "Epoch 100 of 100 | MSE: 0.0017286045476794243\n",
      "Training time: 0.68\n",
      "Validation RMSE: 0.008748484018203467\n",
      "Test RMSE: 0.005458068793459462\n",
      "Test MEAN: 0.9945187470862006\n",
      "Test VOL: 0.011638017035134236\n",
      "\n",
      "Shallow NNF Training & Results for model 18.0:\n",
      "Epoch 1 of 100 | MSE: 0.02443239465355873\n",
      "Epoch 100 of 100 | MSE: 6.459338328568265e-05\n",
      "Training time: 0.69\n",
      "Validation RMSE: 0.010421057016091202\n",
      "Test RMSE: 0.012068683258557497\n",
      "Test MEAN: 1.0073059402895668\n",
      "Test VOL: 0.01602526719246879\n",
      "\n",
      "Shallow NNF Training & Results for model 19.0:\n",
      "Epoch 1 of 100 | MSE: 0.02161198854446411\n",
      "Epoch 100 of 100 | MSE: 2.603711664050934e-06\n",
      "Training time: 0.68\n",
      "Validation RMSE: 0.012934859124025064\n",
      "Test RMSE: 0.002438680932981166\n",
      "Test MEAN: 1.000381277520665\n",
      "Test VOL: 0.005522035707090603\n",
      "\n",
      "Shallow NNF Training & Results for model 20.0:\n",
      "Epoch 1 of 100 | MSE: 0.040128618478775024\n",
      "Epoch 100 of 100 | MSE: 1.7213622413692065e-05\n",
      "Training time: 0.68\n",
      "Validation RMSE: 0.01046689397013759\n",
      "Test RMSE: 0.002233775104735203\n",
      "Test MEAN: 1.000059898357629\n",
      "Test VOL: 0.013300868560237999\n",
      "\n",
      "Shallow NNF Training & Results for model 21.0:\n",
      "Epoch 1 of 100 | MSE: 0.04393913224339485\n",
      "Epoch 100 of 100 | MSE: 3.0303335734060965e-05\n",
      "Training time: 0.69\n",
      "Validation RMSE: 0.010241483122573105\n",
      "Test RMSE: 0.012089738139536507\n",
      "Test MEAN: 1.0055557728388644\n",
      "Test VOL: 0.013696943784622844\n",
      "\n",
      "Shallow NNF Training & Results for model 22.0:\n",
      "Epoch 1 of 100 | MSE: 0.030702168121933937\n",
      "Epoch 100 of 100 | MSE: 0.0006195346359163523\n",
      "Training time: 0.71\n",
      "Validation RMSE: 0.01027980278469984\n",
      "Test RMSE: 0.004607299428920739\n",
      "Test MEAN: 1.0014177855286854\n",
      "Test VOL: 0.00828973750932579\n",
      "\n",
      "Shallow NNF Training & Results for model 23.0:\n",
      "Epoch 1 of 100 | MSE: 0.024821262806653976\n",
      "Epoch 100 of 100 | MSE: 0.006491666194051504\n",
      "Training time: 0.72\n",
      "Validation RMSE: 0.008964756524652789\n",
      "Test RMSE: 0.005252170339821972\n",
      "Test MEAN: 1.0022811937650424\n",
      "Test VOL: 0.00690218940880332\n",
      "\n",
      "Shallow NNF Training & Results for model 24.0:\n",
      "Epoch 1 of 100 | MSE: 0.016793739050626755\n",
      "Epoch 100 of 100 | MSE: 0.00038085298729129136\n",
      "Training time: 0.70\n",
      "Validation RMSE: 0.009747527522968083\n",
      "Test RMSE: 0.0017845884560604265\n",
      "Test MEAN: 1.001493663788119\n",
      "Test VOL: 0.004684007247036233\n",
      "Selected Model Test Results for model i = 1 are: \n",
      "RMSE = 0.003911203078241354\n",
      "MEAN = 1.0010024477980122\n",
      "VOL = 0.004704220264448412\n"
     ]
    }
   ],
   "source": [
    "#shallow nnf\n",
    "'''\n",
    "in this cell,firstly, train, validation and test datasets are sliced in each loop. then shallow NNf model gets trained and\n",
    "then best model will be chosen. Also RMSE, Mean and volatility of all models and then the best model is printed.\n",
    "'''\n",
    "shallow_nnf_valid_rmse_list = []\n",
    "shallow_nnf_test_results = [] \n",
    "shallow_nnf_test_plot = [] # storing the shallow model test data return for plotting later on\n",
    "\n",
    "for i in range(int(24/rbp)):\n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i*rbp))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i*rbp))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i*rbp))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i*rbp))\n",
    "    x_test = data_process(date_slicer(df, '2018-01-01', 1, i*rbp))\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i*rbp))\n",
    "    \n",
    "    train_shallow_nnf(x_train, y_train, i*rbp)\n",
    "    shallow_nnf_valid_rmse_list.append(valid_fun(x_valid, i*rbp, shallow_NNF))\n",
    "    shallow_nnf_test_results.append(test_fun(x_test, i*rbp, shallow_NNF))\n",
    "    portfolio_return(df, x_test, shallow_NNF, i, shallow_nnf_test_plot)\n",
    "    shallow_NNF.reset_parameters()\n",
    "    \n",
    "\n",
    "# print(f'\\nMin Valid RMSE is: {min(valid_rmse_list)} for model i = {(deep_best_result_index)+1}')\n",
    "print('Selected Model Test Results for model i =', (deep_best_result_index)+1, 'are: ')\n",
    "print('RMSE =', shallow_nnf_test_results[(deep_best_result_index)]['RMSE'])\n",
    "print('MEAN =', shallow_nnf_test_results[(deep_best_result_index)]['MEAN'])\n",
    "print('VOL =', shallow_nnf_test_results[(deep_best_result_index)]['VOL'])\n",
    "\n",
    "shallow_nnf_test_plot = np.array(shallow_nnf_test_plot).reshape(-1,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1/N Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Equal Weights Model Results for model 1:\n",
      "Validation RMSE: 0.0013752466607634818\n",
      "Test RMSE: 0.00141308068973907\n",
      "Test MEAN: 1.00194947794337\n",
      "Test VOL: 0.005348201810361211\n",
      "\n",
      "Equal Weights Model Results for model 2:\n",
      "Validation RMSE: 0.0014103582761839522\n",
      "Test RMSE: 0.002225473810475016\n",
      "Test MEAN: 0.9979382024584036\n",
      "Test VOL: 0.015471723202182033\n",
      "\n",
      "Equal Weights Model Results for model 3:\n",
      "Validation RMSE: 0.00161101492926301\n",
      "Test RMSE: 0.0021228799964131116\n",
      "Test MEAN: 1.0002504247997188\n",
      "Test VOL: 0.011031703269168955\n",
      "\n",
      "Equal Weights Model Results for model 4:\n",
      "Validation RMSE: 0.00178815568268382\n",
      "Test RMSE: 0.0016167972928903618\n",
      "Test MEAN: 1.001305977361471\n",
      "Test VOL: 0.008808539875808678\n",
      "\n",
      "Equal Weights Model Results for model 5:\n",
      "Validation RMSE: 0.0017533218637125797\n",
      "Test RMSE: 0.0012496906685729259\n",
      "Test MEAN: 1.0007751300633236\n",
      "Test VOL: 0.0062942423298088844\n",
      "\n",
      "Equal Weights Model Results for model 6:\n",
      "Validation RMSE: 0.0017002638599400465\n",
      "Test RMSE: 0.0012049049143032751\n",
      "Test MEAN: 1.000132556099627\n",
      "Test VOL: 0.004753505074253049\n",
      "\n",
      "Equal Weights Model Results for model 7:\n",
      "Validation RMSE: 0.0016838896697022906\n",
      "Test RMSE: 0.002608250111522712\n",
      "Test MEAN: 1.0015818555353888\n",
      "Test VOL: 0.004983170010212011\n",
      "\n",
      "Equal Weights Model Results for model 8:\n",
      "Validation RMSE: 0.0019078407523448037\n",
      "Test RMSE: 0.0011962789884695558\n",
      "Test MEAN: 1.0012933034193634\n",
      "Test VOL: 0.004707598960828587\n",
      "\n",
      "Equal Weights Model Results for model 9:\n",
      "Validation RMSE: 0.0017918743187162148\n",
      "Test RMSE: 0.001888238767926475\n",
      "Test MEAN: 1.000176838763966\n",
      "Test VOL: 0.0035131312053199725\n",
      "\n",
      "Equal Weights Model Results for model 10:\n",
      "Validation RMSE: 0.0017472761704575702\n",
      "Test RMSE: 0.003108435537956791\n",
      "Test MEAN: 0.9967994846709011\n",
      "Test VOL: 0.012654039350899505\n",
      "\n",
      "Equal Weights Model Results for model 11:\n",
      "Validation RMSE: 0.002080505442953261\n",
      "Test RMSE: 0.0024845370945334663\n",
      "Test MEAN: 1.000826368012285\n",
      "Test VOL: 0.009815043138294987\n",
      "\n",
      "Equal Weights Model Results for model 12:\n",
      "Validation RMSE: 0.00228250529001297\n",
      "Test RMSE: 0.002110325599208719\n",
      "Test MEAN: 0.99392170780843\n",
      "Test VOL: 0.017125701805097735\n",
      "\n",
      "Equal Weights Model Results for model 13:\n",
      "Validation RMSE: 0.002378854806423318\n",
      "Test RMSE: 0.0025991203186737635\n",
      "Test MEAN: 1.0047820361360924\n",
      "Test VOL: 0.010457672576285474\n",
      "\n",
      "Equal Weights Model Results for model 14:\n",
      "Validation RMSE: 0.0023376364047417086\n",
      "Test RMSE: 0.001402228062171977\n",
      "Test MEAN: 1.002025461923509\n",
      "Test VOL: 0.004559034383661699\n",
      "\n",
      "Equal Weights Model Results for model 15:\n",
      "Validation RMSE: 0.002388129123328023\n",
      "Test RMSE: 0.0014276920122888483\n",
      "Test MEAN: 1.000264732576357\n",
      "Test VOL: 0.007639654783347461\n",
      "\n",
      "Equal Weights Model Results for model 16:\n",
      "Validation RMSE: 0.0023085543362458107\n",
      "Test RMSE: 0.0019700691339755265\n",
      "Test MEAN: 1.0012020349198691\n",
      "Test VOL: 0.004404697243899707\n",
      "\n",
      "Equal Weights Model Results for model 17:\n",
      "Validation RMSE: 0.002032437718144319\n",
      "Test RMSE: 0.001475205067385024\n",
      "Test MEAN: 0.9972273915102033\n",
      "Test VOL: 0.008748691989180815\n",
      "\n",
      "Equal Weights Model Results for model 18:\n",
      "Validation RMSE: 0.0018717109499381298\n",
      "Test RMSE: 0.001720766888220823\n",
      "Test MEAN: 1.0036391934325273\n",
      "Test VOL: 0.006673775895724877\n",
      "\n",
      "Equal Weights Model Results for model 19:\n",
      "Validation RMSE: 0.0019686564797122682\n",
      "Test RMSE: 0.0018643344043743812\n",
      "Test MEAN: 1.0002658041495434\n",
      "Test VOL: 0.005183267607845902\n",
      "\n",
      "Equal Weights Model Results for model 20:\n",
      "Validation RMSE: 0.0018238046048378409\n",
      "Test RMSE: 0.001359914467857588\n",
      "Test MEAN: 0.9993162870787218\n",
      "Test VOL: 0.014303584166600736\n",
      "\n",
      "Equal Weights Model Results for model 21:\n",
      "Validation RMSE: 0.0018329033576296974\n",
      "Test RMSE: 0.002201019621821213\n",
      "Test MEAN: 1.0021142585317577\n",
      "Test VOL: 0.00539380418680695\n",
      "\n",
      "Equal Weights Model Results for model 22:\n",
      "Validation RMSE: 0.0019462210070632896\n",
      "Test RMSE: 0.0019706191075476273\n",
      "Test MEAN: 1.0013487467662525\n",
      "Test VOL: 0.007930844134341473\n",
      "\n",
      "Equal Weights Model Results for model 23:\n",
      "Validation RMSE: 0.0019529162145969603\n",
      "Test RMSE: 0.0009264363066448112\n",
      "Test MEAN: 1.0011367709735588\n",
      "Test VOL: 0.0034522863961233786\n",
      "\n",
      "Equal Weights Model Results for model 24:\n",
      "Validation RMSE: 0.0017551968016899662\n",
      "Test RMSE: 0.0013201770489190275\n",
      "Test MEAN: 1.0017054738565843\n",
      "Test VOL: 0.004493494843845112\n",
      "Selected Model Test Results for model i = 1 are: \n",
      "RMSE = 0.00141308068973907\n",
      "MEAN = 1.00194947794337\n",
      "VOL = 0.005348201810361211\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "here we run the 1/N model, for the number of stocks, each stock gets the weight of 1/N meaning that\n",
    "every stock is equally important, this model play the role of a benchmark to see how effective our model are\n",
    "'''\n",
    "equal_w_model_valid_rmse_list = []\n",
    "equal_w_model_test_results = []\n",
    "equal_w_model_test_plot = [] # storing the 1/n model test data return for plotting later on\n",
    "\n",
    "for i in range(int(24/rbp)):\n",
    "    print(f'\\nEqual Weights Model Results for model {i+1}:')\n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i*rbp))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i*rbp))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i*rbp))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i*rbp))\n",
    "    x_test = data_process(date_slicer(df, '2018-01-01', 1, i*rbp))\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i*rbp))\n",
    "    \n",
    "    equal_w_model_valid_rmse_list.append(valid_fun(x_valid, i*rbp, equal_w_model))\n",
    "    equal_w_model_test_results.append(test_fun(x_test, i*rbp, equal_w_model))\n",
    "    portfolio_return(df, x_test, equal_w_model, i, equal_w_model_test_plot)\n",
    "    \n",
    "print('Selected Model Test Results for model i =', (deep_best_result_index)+1, 'are: ')\n",
    "print('RMSE =', equal_w_model_test_results[(deep_best_result_index)]['RMSE'])\n",
    "print('MEAN =', equal_w_model_test_results[(deep_best_result_index)]['MEAN'])\n",
    "print('VOL =', equal_w_model_test_results[(deep_best_result_index)]['VOL'])\n",
    "\n",
    "equal_w_model_test_plot = np.array(equal_w_model_test_plot).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models test results with rebalancing period of 1 month(s) are: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep NNF</th>\n",
       "      <th>Shallow NNF</th>\n",
       "      <th>1/N Model</th>\n",
       "      <th>S&amp;P 500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN</th>\n",
       "      <td>1.001953</td>\n",
       "      <td>1.001002</td>\n",
       "      <td>1.001949</td>\n",
       "      <td>1.002337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOL</th>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.005601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Deep NNF  Shallow NNF  1/N Model   S&P 500\n",
       "RMSE  0.001412     0.003911   0.001413         -\n",
       "MEAN  1.001953     1.001002   1.001949  1.002337\n",
       "VOL   0.005354     0.004704   0.005348  0.005601"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print test results\n",
    "'''\n",
    "here we compare the results in a dataframe featuring RMSE, MEAN and, volatility of each model in the test dataset\n",
    "that has the best results for deep nnf model. this dataframe can cope with the understanding of why we bother \n",
    "implementing a complex neural network\n",
    "'''\n",
    "print(f'Models test results with rebalancing period of {rbp} month(s) are: ')\n",
    "deep_temp = pd.DataFrame(deep_nnf_test_results)\n",
    "deep_temp = deep_temp.iloc[deep_best_result_index]\n",
    "shallow_temp = pd.DataFrame(shallow_nnf_test_results)\n",
    "shallow_temp = shallow_temp.iloc[deep_best_result_index]\n",
    "equal_w_temp = pd.DataFrame(equal_w_model_test_results)\n",
    "equal_w_temp = equal_w_temp.iloc[deep_best_result_index]\n",
    "\n",
    "# extract the mean and volatility of the s&p index on the test dataset\n",
    "sp_temp_rmse = '-'\n",
    "sp_temp_mean = daily_return(date_slicer(df_sp, '2018-01-01', 1, deep_best_result_index)).mean()[0]\n",
    "sp_temp_std = daily_return(date_slicer(df_sp, '2018-01-01', 1, deep_best_result_index)).std()[0]\n",
    "sp_temp = pd.DataFrame([sp_temp_rmse, sp_temp_mean, sp_temp_std], index=deep_temp.index)\n",
    "\n",
    "# concatinating the result in a unified dataframe\n",
    "final_result = pd.concat([deep_temp, shallow_temp, equal_w_temp, sp_temp], axis=1, join='inner')\n",
    "final_result.columns = ['Deep NNF', 'Shallow NNF', '1/N Model', 'S&P 500']\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of test RMSE for each model: \n",
      "Deep NNF: 0.0018112010160534961\n",
      "Shallow NNF: 0.006406013945540833\n",
      "Equal weight model: 0.001811103162995504\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "to further showcase the results, here we compute the average RMSE of each model in test dataset\n",
    "'''\n",
    "print(f'Average of test RMSE for each model: ')\n",
    "\n",
    "deep_nnf_test_rmse_mean = 0 # temp variable for storing each tmse for deep nnf model\n",
    "for i in range(int(24/rbp)):\n",
    "    deep_nnf_test_rmse_mean += deep_nnf_test_results[i]['RMSE']\n",
    "print(f'Deep NNF: {deep_nnf_test_rmse_mean/int(24/rbp)}')\n",
    "\n",
    "shallow_nnf_test_rmse_mean = 0 # temp variable for storing each tmse for shallow nnf model\n",
    "for i in range(int(24/rbp)):\n",
    "    shallow_nnf_test_rmse_mean += shallow_nnf_test_results[i]['RMSE']\n",
    "print(f'Shallow NNF: {shallow_nnf_test_rmse_mean/int(24/rbp)}')\n",
    "\n",
    "equal_w_model_test_rmse_mean = 0 # temp variable for storing each tmse for 1/n model model\n",
    "for i in range(int(24/rbp)):\n",
    "    equal_w_model_test_rmse_mean += equal_w_model_test_results[i]['RMSE']\n",
    "print(f'Equal weight model: {equal_w_model_test_rmse_mean/int(24/rbp)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinating the test dataset return results of each model + index return for plot\n",
    "plot_test = pd.concat([pd.DataFrame(equal_w_model_test_plot), pd.DataFrame(shallow_nnf_test_plot),\n",
    "                       pd.DataFrame(deep_nnf_test_plot), pd.DataFrame(index_test_plot)], axis=1, join='inner')\n",
    "\n",
    "plot_test.columns = ['1/N Model', 'Shallow NNF', 'Deep NNF', 'S&P 500']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "1/N Model",
         "text": "",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477
         ],
         "y": [
          1.005443342664013,
          1.008572994842972,
          1.014449464317343,
          1.0182419050805815,
          1.0185056900797973,
          1.0156959100764915,
          1.024812748553089,
          1.0309717887089722,
          1.0246954300306539,
          1.033650034225885,
          1.0312830197699063,
          1.0381040743734162,
          1.0443933846164353,
          1.047401484570692,
          1.0472057042226137,
          1.0469113994063004,
          1.0570299319192908,
          1.0496729636655506,
          1.0392336873748804,
          1.0394948393540526,
          0.9799002432619366,
          0.9442233563075461,
          0.9563128311974386,
          0.9538936707193497,
          0.9213029108110568,
          0.9336559864593101,
          0.944993631808935,
          0.9482296317511052,
          0.9620262346937991,
          0.9724224459133792,
          0.9726636698055255,
          0.9666233403404936,
          0.9612472701000855,
          0.9618554811462964,
          0.9766986401078889,
          0.9838713997955385,
          0.9709029137407595,
          0.960967103349419,
          1.006637391318661,
          1.0182918740912303,
          1.0233566074903748,
          1.0230489824093478,
          1.0266332853020017,
          1.0430616777644697,
          1.041904152761347,
          1.0377558722405456,
          1.0322213478591742,
          1.0299008297352743,
          1.0346559767326187,
          1.023049609813605,
          1.0242071506436974,
          1.0240319892338574,
          1.000661288083951,
          0.9812608980841633,
          1.004147585646594,
          0.9915547020001465,
          0.9902604723839443,
          1.0031956391844399,
          1.0120855571192562,
          1.0237142253482234,
          1.030206273864736,
          1.0082529142879362,
          1.0097221411078974,
          1.0248020659480968,
          1.0199819822643068,
          1.0255497429835476,
          1.0228367293687626,
          1.0329481517202699,
          1.0422999720724024,
          1.0450880028621745,
          1.0381663131205339,
          1.030850620716514,
          1.0321077802688658,
          1.0215061894192192,
          1.0242093051479066,
          1.031826827764115,
          1.0345327923640886,
          1.0255201508922966,
          0.9915081423965098,
          0.9893456720051855,
          1.0015518731092998,
          1.0031625245204687,
          1.002745545855196,
          1.0105739380670804,
          1.019207918181998,
          1.0201642360730336,
          1.020254158032857,
          1.015104967630127,
          1.0204150165834929,
          1.0215050070187917,
          1.0200053287735218,
          1.0269378286644042,
          1.0225753929322008,
          1.0250539506109553,
          1.0247416479065519,
          1.0229103578466423,
          1.012397414182743,
          1.0252901479231717,
          1.0159122350862542,
          1.0049707293291201,
          1.0067162930964415,
          1.0146520394856335,
          1.0148123194974803,
          1.0197855207330582,
          1.0220715852394695,
          1.025252026199786,
          1.0194412925483314,
          1.0224356439857285,
          1.0231684267722703,
          1.0214622661620296,
          1.0170888879712843,
          1.0194812164897868,
          1.0138124426665334,
          1.0164836211060189,
          1.0052648449439585,
          1.0060772778011176,
          0.9973863134626133,
          1.0015625918050255,
          1.0025701151438495,
          0.9982900353087949,
          1.0064154550811855,
          1.0141002127462522,
          1.0220657755366178,
          1.0251172080882731,
          1.0171563659789877,
          1.023029778866516,
          1.024056586060722,
          1.020991849637657,
          1.0252014612395055,
          1.0277807822498775,
          1.0273917820305858,
          1.0239961043450088,
          1.0242534919054636,
          1.0233192454314328,
          1.0317973943658245,
          1.0356221043654523,
          1.0291183453508002,
          1.0235975562790818,
          1.0313620709825542,
          1.0052388779847212,
          1.0102684338695789,
          1.0129083644459322,
          1.0156618363361558,
          1.013681128727133,
          1.0123523932420353,
          1.0049170911083092,
          1.0002877965784476,
          1.008574022523303,
          1.0016073674123194,
          1.009623867504817,
          1.0149053151148397,
          1.0194891832432407,
          1.0227594401259996,
          1.0206623423086392,
          1.01800610514766,
          1.0238791046646516,
          1.029895813977138,
          1.0302380224622194,
          1.0342582005818266,
          1.027697307843729,
          1.028602829164031,
          1.000072716663728,
          0.9981090620476213,
          0.9948700718092104,
          0.9989255346686817,
          0.9999562768732599,
          1.0018175885682377,
          1.0063573217405315,
          1.0076126076335372,
          1.0038142017004836,
          1.0083064563406972,
          1.0082097981021694,
          1.014821971077671,
          1.0158551660959105,
          1.0083411158500215,
          1.0055043859794313,
          1.0010459519965522,
          1.0012659063617126,
          1.0029669710973295,
          0.9982820629657406,
          0.998130361492734,
          0.9910422748441834,
          0.9861629356813625,
          0.9870935366751656,
          0.9820778777729959,
          0.9542963116748875,
          0.9338997950355324,
          0.9424956363454339,
          0.9417732507613,
          0.9605637795052012,
          0.958299443023155,
          0.9458454581073856,
          0.943812124039161,
          0.9384269211576811,
          0.9329431296673716,
          0.9089103702148211,
          0.9208861534367766,
          0.9068471292603368,
          0.9064343688431429,
          0.9248943003964439,
          0.9306163391612574,
          0.9968136676413681,
          1.0034241116703817,
          1.0108538588177591,
          1.0270077392364376,
          1.0251075122154008,
          1.016976085275572,
          1.0010168196476705,
          1.0009627313350096,
          0.9950631290882429,
          1.0042223729636834,
          1.0073820053570375,
          0.9937351026403017,
          0.9774116425691708,
          0.982765508998034,
          0.9797371074358034,
          0.9932464476726408,
          0.9934103674713658,
          1.0122120144927764,
          1.0090327367402445,
          1.0152598215329245,
          0.9684241112549253,
          0.9665977466689051,
          0.9455534751437957,
          0.9442768673179054,
          0.9428311319580917,
          0.9479558639419493,
          0.9436930928246507,
          0.9300744441972718,
          0.9100602645644033,
          0.9094673912330824,
          0.8960326585683293,
          0.8818218546658511,
          0.8657919306444628,
          0.8425123473785396,
          0.8802645541358531,
          0.8880187823194293,
          0.8865810053232152,
          0.8938660890485721,
          0.9805450126719798,
          1.01237314956618,
          1.0229162416580715,
          1.0340003635559638,
          1.0408615872322298,
          1.0476040698272857,
          1.0487511009973736,
          1.0434327240887262,
          1.0510882967570403,
          1.0535284494758133,
          1.063043081242437,
          1.0788287556950427,
          1.0647208238870658,
          1.0644314743958507,
          1.0693335674309268,
          1.0801500998657867,
          1.0756644971693083,
          1.0775101385605288,
          1.0895527054572538,
          1.0981041743473015,
          1.005462348515306,
          1.0097743034981717,
          1.0086895452471127,
          1.0032095415882458,
          1.0049132792405115,
          1.007324547883383,
          1.019545440167558,
          1.0237384337235433,
          1.0217227747235904,
          1.0331986965019213,
          1.035162276931138,
          1.0384265782034852,
          1.0351313385584764,
          1.0410225585377952,
          1.0408459775737358,
          1.0382025924357072,
          1.0384997869242865,
          1.0365150386358755,
          0.9949240275479585,
          0.9919403672720388,
          0.9839148218534932,
          0.9766845003425241,
          0.9740782268574915,
          0.9869922564969158,
          0.9899149573065528,
          0.995978094687409,
          0.9947090117673436,
          0.9981155462206186,
          1.002512158511703,
          1.0007164145966823,
          0.9946177584254281,
          1.007754438579759,
          0.9880675836504316,
          0.9884087033827774,
          0.9964729163234572,
          0.9932479810878121,
          0.9985286854512843,
          1.0046588990506224,
          0.9992204969722017,
          1.0020236629464987,
          1.0051378083692273,
          1.011692578057859,
          1.0123058963155103,
          1.0042062504684555,
          1.0096629850214445,
          1.0111747840219765,
          1.0182635050485496,
          1.016142302424912,
          1.015956003952552,
          1.010407006429896,
          1.0127254622699744,
          1.0103416510975394,
          1.0196017462718763,
          1.0193225411006401,
          1.0141294565210652,
          1.0206066430531708,
          1.0205750586335423,
          1.023935313688307,
          1.0009367100509614,
          1.010079988127478,
          1.0055868996577517,
          0.9893482419632176,
          0.9874125287269507,
          0.9862168131668447,
          0.9903796014697095,
          0.9668323746499007,
          0.9758714671237488,
          0.9789857902310706,
          0.986051702902669,
          0.9796630262605792,
          0.9736525703131335,
          0.9837872644070002,
          0.9792849989119821,
          0.9676698724818218,
          0.9696548610511231,
          0.9596268217017132,
          0.952712617917459,
          0.9540795039396539,
          0.9441386802366818,
          1.022423667171756,
          1.0301187461748647,
          1.034938668567928,
          1.0425112845197415,
          1.0467121065730371,
          1.0458482569679406,
          1.0439971895821865,
          1.0506764495964311,
          1.0478105421958888,
          1.046887678857214,
          1.0573726409979483,
          1.0614464762668727,
          1.0711774504498746,
          1.0685033785621145,
          1.064291935439254,
          1.056880155684432,
          1.0545504431353594,
          1.061264226008105,
          1.0708290944221477,
          1.0003469677598489,
          1.0097489754652786,
          1.0082754806143486,
          1.0029662161579784,
          1.0027255421103332,
          1.0039314114784175,
          1.0057589549113686,
          1.0129756448833842,
          1.011942460936397,
          1.0106149256231074,
          1.0022850210003191,
          1.0058531886297322,
          1.000794517022307,
          1.0010378726703573,
          1.0099166601943672,
          1.0164600758926907,
          1.0102090821384249,
          1.0159881747385613,
          1.0137768761793824,
          1.0140742509528244,
          1.0046368515543038,
          0.9921821962186009,
          0.9639471208637771,
          0.974900254085206,
          0.9764612300409367,
          0.994441177863714,
          0.9864482807697572,
          0.9740849617605101,
          0.9864440866441988,
          0.956485090422442,
          0.9572229169744378,
          0.9722258546497455,
          0.9839545692720564,
          0.9757594906954808,
          0.9839053536219673,
          0.9844562336275365,
          0.9584856616109824,
          0.9670462298142577,
          0.9622078011011312,
          0.9697398026616689,
          0.9826812985229402,
          0.9844037369284769,
          1.011692419811061,
          1.026928319470596,
          1.0293950186672747,
          1.035119409754866,
          1.0408297897989018,
          1.0491452692152132,
          1.04969576230964,
          1.0504971856263567,
          1.0509933307636476,
          1.0507850777040468,
          1.0495488036818401,
          1.0468264144984143,
          1.0428303457046617,
          1.043325260541347,
          1.0351635867662856,
          1.041310235557371,
          1.0392017043846284,
          1.035209853711937,
          1.0403179839497725,
          0.981395113932634,
          0.9882544437148923,
          1.000007762710438,
          0.9951065474000065,
          0.9775799096047503,
          0.985985753868158,
          0.993100279306108,
          1.0072753432469257,
          1.004822852186623,
          1.013674030476082,
          1.0117738590409537,
          1.0155822240700514,
          1.0144326956726346,
          1.0217892399219795,
          1.0217267689708056,
          1.024843465264599,
          1.0254867710945779,
          1.0292494594090904,
          1.031757201886155,
          1.0343489068403935,
          1.0346404818200796,
          1.0291176957393835,
          1.0051818384430729,
          1.005019907861984,
          1.0044199810328494,
          1.006932606789332,
          1.0087693595630758,
          1.0062295273290982,
          1.007016080224759,
          1.006272074760273,
          1.0084543859873978,
          1.0159690373838683,
          1.0149793776971234,
          1.0142057872778334,
          1.010598332627208,
          1.0078916160338123,
          1.0115022078076934,
          1.0198950201812902,
          1.021827479397883,
          1.026159116029552,
          1.0212031931862264,
          0.9919897289748665,
          0.9994713791624729,
          1.001321433020612,
          1.0102513318815265,
          1.0076599842521878,
          1.0065037973301556,
          1.009102725435664,
          1.019507518852647,
          1.0167783504260837,
          1.023021562283747,
          1.0236297269276766,
          1.0250692198185642,
          1.0286186133052613,
          1.0346978669924138,
          1.034931247447906,
          1.0351898582574872,
          1.0376339130988324,
          1.036738145716607,
          1.032728182705108
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "Shallow NNF",
         "text": "",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477
         ],
         "y": [
          1.003003539597625,
          1.009776998480948,
          1.0129132197058375,
          1.0134881548340995,
          1.0121531144869136,
          1.005906072907689,
          1.017446084444817,
          1.022355433928138,
          1.0186771588444543,
          1.0239029777069735,
          1.0223275170728123,
          1.0290127824963278,
          1.031889021813358,
          1.0282449970300591,
          1.026265784965382,
          1.0290891299350169,
          1.0324519964897396,
          1.0241650649270744,
          1.0199583344705918,
          1.0197856169971768,
          0.9787410690833702,
          0.9443814516984292,
          0.9553830028281245,
          0.9530939571356362,
          0.9237463102181068,
          0.9348183778359295,
          0.944984721772775,
          0.9482533464286428,
          0.9605534146889849,
          0.9703654659656731,
          0.9704826052360646,
          0.9624424488644912,
          0.9551433745153027,
          0.957679816215425,
          0.9714301284958988,
          0.9774939441946726,
          0.9618146282498018,
          0.9518529552333659,
          1.0061255247067145,
          1.0175613694440042,
          1.0234005113749214,
          1.02046923932262,
          1.0263103601449777,
          1.0428024450540538,
          1.041000659454196,
          1.0375987265272046,
          1.0300629758408575,
          1.0268764569778255,
          1.0318889011717467,
          1.0213978210305015,
          1.0209443636985898,
          1.01825263733533,
          0.9942572428293238,
          0.9734932147004736,
          0.9967239087008171,
          0.9885428140564487,
          0.9900036580071563,
          1.0019952780267625,
          1.0133511737747543,
          1.021607296222455,
          1.0185392010739147,
          1.0062309309946498,
          1.006457263616227,
          1.0141099521584471,
          1.0057108168357536,
          1.0111092330887967,
          1.005261992770628,
          1.0186906025844027,
          1.02289721261607,
          1.0240945870274618,
          1.0324047045952915,
          1.032845732268583,
          1.0374224225138768,
          1.0210046021727583,
          1.0297037184908262,
          1.0232647529909964,
          1.0300912022735043,
          1.017787754445363,
          1.0094072930601625,
          1.0037118184545408,
          1.0257493268950209,
          1.0289710185629053,
          1.0309479783887652,
          1.0302083865966218,
          1.0363996429480737,
          1.0368951408847757,
          1.0339232354456374,
          1.0304530655258537,
          1.0341687913565112,
          1.0371385151799326,
          1.0430796769752877,
          1.0544698266633639,
          1.0381296611280473,
          1.031445484609521,
          1.0309506115123537,
          1.0309515084325422,
          1.027484120979925,
          1.0406111934371616,
          1.02278256231997,
          1.005132583312862,
          1.0038177032672766,
          1.0112391686950963,
          1.0124764546386602,
          1.0192220756503267,
          1.0221953288759775,
          1.0244415866990586,
          1.0180632055290095,
          1.0229593300946498,
          1.0255736576716368,
          1.0211403108579133,
          1.0192054612230972,
          1.0215664546499958,
          1.016572458318263,
          1.0218015166031285,
          1.0150802274720234,
          1.0134984122263797,
          1.0048978929353904,
          1.0116046254867377,
          1.0155548956832903,
          1.000478801109067,
          1.0081921139119856,
          1.0193301480217112,
          0.983010565471299,
          0.9906918508900823,
          1.0026146509499108,
          1.0067631424577657,
          1.0009287992586948,
          0.9986344760616562,
          0.9968557743082122,
          0.993800389085012,
          1.001787102641951,
          0.9956514141561063,
          0.9874591083069141,
          0.9894650208894573,
          0.9897736864980015,
          1.005427152878978,
          1.0087664969540298,
          1.0012331099432503,
          1.0190687156571636,
          0.9834388063044437,
          0.9983861274751775,
          1.0068812569421735,
          1.007972862234563,
          1.0060216395873034,
          1.0056136915581333,
          0.9989641968244818,
          1.0003566815706517,
          0.9995129635223401,
          1.004011584566698,
          1.0165172057429963,
          1.0254743369105832,
          1.0232438589540787,
          1.010522919747624,
          0.994731306208861,
          0.9938237800741972,
          1.005280883064884,
          0.9982267763142842,
          1.0064182573135285,
          1.0026339347193172,
          0.9994810121629208,
          1.002783958214839,
          1.002996215059643,
          1.0030725169006862,
          0.9987409383192666,
          1.0032202340698404,
          1.003170986934864,
          1.0054514365382958,
          1.0110054959277381,
          1.0131101722938578,
          1.0099997828045453,
          1.0153476752226571,
          1.0134620813558908,
          1.0200201460780478,
          1.0219456269873513,
          1.0127775370254577,
          1.009025012386858,
          1.0045668136914507,
          1.0044674934883384,
          1.0061272255648472,
          1.0024045338826386,
          0.9926489046693505,
          0.9917468362951178,
          0.991704518907841,
          0.9948122799500725,
          0.9924733299351184,
          0.9596703174620623,
          0.9295540223264207,
          0.932383362857614,
          0.9273536943713503,
          0.9361425155013253,
          0.936474717755244,
          0.926469116540505,
          0.9247688390541572,
          0.9143021966639893,
          0.9109267396150711,
          0.887029266710428,
          0.9002761045951332,
          0.8597204037094047,
          0.8555534017451039,
          0.8719509816979599,
          0.8821851489562286,
          1.008225940636272,
          1.0134716212641277,
          1.019372936392093,
          1.0270630031290744,
          1.0344224083126967,
          1.0226098633748095,
          1.0133483571215425,
          1.0165199853197784,
          0.9964998703246221,
          1.0119376857859326,
          1.021163275314528,
          1.0229496858043432,
          1.0148700856592072,
          1.0267980903551341,
          1.0189157486661136,
          1.0265101678370554,
          1.0319415007797705,
          1.0542122788484296,
          1.0490944024928068,
          1.0473382880341089,
          0.9608745502071291,
          0.9585252050008131,
          0.9324532482541318,
          0.9221312757202803,
          0.9171538432826318,
          0.9244839666339433,
          0.9334267576556394,
          0.9150760132385796,
          0.9006088425963406,
          0.9047266053712913,
          0.8790387570359994,
          0.864132682596012,
          0.8558366193793601,
          0.8384841962405357,
          0.8713242387640602,
          0.8850689899216572,
          0.885548099728775,
          0.8910992235945604,
          0.9748468053177056,
          1.000218715981531,
          0.9991249585479024,
          0.9971563386374775,
          0.9967191761066676,
          1.003827568977073,
          0.9945319300684441,
          0.9842521155614171,
          0.9885171154115547,
          0.9823928982694219,
          0.9919072528007464,
          1.0100611887595887,
          1.0066709618905096,
          1.0146543068495604,
          1.016076003414724,
          1.0138887573770954,
          1.012576553030272,
          1.0134514156263175,
          1.0219815945556268,
          1.0277776934684304,
          0.9932194497115626,
          0.9932202195266219,
          0.9773973055029438,
          0.9699019356599621,
          0.9639546450687628,
          0.9683569940893711,
          0.9844180803655977,
          0.9825144255187649,
          0.973592187568363,
          0.9917942070703618,
          0.9951259364758569,
          0.9995279643029027,
          0.9898922908142422,
          0.9868006785403229,
          0.9829939510150382,
          0.98287496179313,
          0.9844219371326492,
          0.9822807154347308,
          0.9919861732701989,
          1.002112006449558,
          1.0016686938985957,
          1.0007502040253127,
          0.990696859365637,
          0.9902429356529548,
          0.9780866133849865,
          0.9857725558925676,
          0.9839533466250655,
          0.9815539814132375,
          0.9816494102746135,
          0.981149977174542,
          0.9761083441075249,
          0.9948813992835581,
          1.0040260910246253,
          1.0152705721062822,
          1.0223532522828458,
          1.0128749839190143,
          1.0234140441403783,
          1.0318948567600668,
          1.0014278810646537,
          0.9961142011716827,
          0.9904311527794382,
          1.0028538699480267,
          0.993995542332194,
          0.9922213703907757,
          0.9890395086941262,
          0.9950695967241645,
          0.9961385113845895,
          0.9929416940655177,
          0.9794478381769479,
          0.979084019939792,
          0.9780258785842413,
          0.9691715850932203,
          0.9688207683723041,
          0.9762694031503899,
          0.9879582755831354,
          0.9893851120918067,
          0.9815235904610461,
          0.9929711415507011,
          0.9926099597591066,
          1.003831110708539,
          0.9923562211467917,
          0.9684316020381004,
          0.9663592248031074,
          0.9695731353985909,
          0.9722881241772333,
          0.9383713559808852,
          0.9445160711747729,
          0.9415913916430962,
          0.9488553324066438,
          0.9342551369275803,
          0.9332823454890745,
          0.9430849156370296,
          0.9368548339903311,
          0.9192159598977822,
          0.922659741610764,
          0.9129855323564298,
          0.9085042525374387,
          0.9063372770842985,
          0.8899223516848894,
          1.0448577545635949,
          1.048104480587059,
          1.044681975614061,
          1.0604190211759943,
          1.0703378514145496,
          1.0507278248940373,
          1.0526756643613164,
          1.0742515902992258,
          1.0682212127599147,
          1.0643468867818335,
          1.1009656804260028,
          1.1018427525180976,
          1.1332834419566615,
          1.1212279630992386,
          1.119064428725413,
          1.1147527430690813,
          1.109994169488658,
          1.1203557221014877,
          1.1455946409256315,
          0.9998598076603112,
          1.0091736671045421,
          1.0080014736841616,
          1.0030733616672265,
          1.002542046734297,
          1.0032883930787175,
          1.005165309268338,
          1.0124489921825335,
          1.0105746268407174,
          1.0101991004679873,
          1.0008286855089326,
          1.0045048238448218,
          0.9996016399887196,
          0.9992634581417301,
          1.010462671968819,
          1.0181046775389055,
          1.0118103618965626,
          1.017464429199295,
          1.0151578032475201,
          1.0165298502244509,
          1.0070426764029465,
          0.9958341670724481,
          0.9681521716003899,
          0.9774518421762713,
          0.9804210328501837,
          1.0012686895461653,
          0.9959313333507709,
          0.9864839180770081,
          0.9973265669380644,
          0.9727914513873352,
          0.9727184532581749,
          0.9865375686460657,
          0.9969797617052947,
          0.9890544144223818,
          0.9979379024933596,
          0.9986672770638462,
          0.9737425251378476,
          0.9842871916524005,
          0.9789748303029392,
          0.9851987057326808,
          0.9979143058146723,
          1.000395143175626,
          1.0198083299893201,
          1.0442107870842214,
          1.0474169848948085,
          1.0472193461997958,
          1.0255833949207294,
          1.024646572859732,
          1.0354712954360819,
          1.0313688709580457,
          1.0307913065379135,
          1.0345177312797496,
          1.040289086065903,
          1.0358041729250709,
          1.0237898051129974,
          1.035708905757016,
          1.0296840258115951,
          1.072483424886947,
          1.0884910844794815,
          1.0901225799950665,
          1.1090622719120278,
          0.9808176925722477,
          0.9903183359712879,
          1.000983851124487,
          0.9852296353033652,
          0.9762239688786788,
          0.980135589803066,
          0.9901246264500292,
          0.998928441015406,
          1.00428472537103,
          1.0184589348444644,
          1.0239834993889065,
          1.0247037427784615,
          1.0176998029498099,
          1.0226032748389542,
          1.0231997501527843,
          1.0269536048171595,
          1.0324735480562441,
          1.0382972952493854,
          1.039365629721711,
          1.032719211952204,
          1.0319009246565034,
          1.030822308223161,
          1.016687106634275,
          1.0167633876130933,
          1.020736931583302,
          1.0220150319461914,
          1.03563748423017,
          1.0352742925483909,
          1.0375568919692633,
          1.0315188579415664,
          1.0346169400217373,
          1.0431006898722999,
          1.0399208033290983,
          1.0432875113207445,
          1.0308776940137518,
          1.0276100389266258,
          1.0316833477392873,
          1.0435534472964036,
          1.0390236142694975,
          1.0473402648330625,
          1.0435142986619494,
          0.9916432887466795,
          0.9992147640593522,
          1.001550871234943,
          1.0104746052180764,
          1.00823753303733,
          1.0069074182320361,
          1.0083192553641542,
          1.0199239470660932,
          1.0154798528819897,
          1.0216644026372899,
          1.022356978440213,
          1.0236923250775185,
          1.0261744504093777,
          1.0310175909219124,
          1.0303260800460037,
          1.0306281850085037,
          1.0332079700185557,
          1.0321642751777338,
          1.0285792139763619
         ]
        },
        {
         "line": {
          "color": "rgba(50, 171, 96, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "Deep NNF",
         "text": "",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477
         ],
         "y": [
          1.0054743370028698,
          1.008621653588767,
          1.0144859072718861,
          1.0182743941704242,
          1.0185447054410364,
          1.0157452241095148,
          1.0249055696909428,
          1.0310905307497624,
          1.024788946759263,
          1.033749610180838,
          1.0313785038635457,
          1.0381798314930888,
          1.0444762080982737,
          1.0474846381832918,
          1.0472872431631775,
          1.046998265465785,
          1.0571120073544205,
          1.0497459227046408,
          1.0393022824988407,
          1.0395557742626447,
          0.979924499120728,
          0.9442789716138619,
          0.956341663640257,
          0.9539277102482087,
          0.9213281972687789,
          0.9336592253361639,
          0.9450242998951394,
          0.9482456707306786,
          0.9620516219662522,
          0.9724372299687755,
          0.9727090001098114,
          0.9666412519231399,
          0.9612697794622135,
          0.9618721501527113,
          0.9767191742308259,
          0.983907925785366,
          0.9709442036746203,
          0.9609788958960392,
          1.006674204544816,
          1.0183419579508708,
          1.023388514074228,
          1.0231093530818143,
          1.0267016901525952,
          1.0431367930942335,
          1.0419410734802121,
          1.0377607684996255,
          1.032205658186458,
          1.0298943016891493,
          1.0346300498098782,
          1.0230385518805747,
          1.0241572898576368,
          1.0239849867155442,
          1.0006033145978142,
          0.9811901861075717,
          1.0040988950550518,
          0.9914945734720779,
          0.9902052896094613,
          1.0031213994377222,
          1.0121158649636703,
          1.0237503010773632,
          1.0302542243046842,
          1.008316552949884,
          1.0097940652259527,
          1.024897551560079,
          1.0200790212533253,
          1.0256241505920096,
          1.0229127781894443,
          1.0330112561734761,
          1.0423683363384932,
          1.0451774708631658,
          1.038223654058138,
          1.0309046871407836,
          1.0321671341772174,
          1.021584646753248,
          1.0242764630619159,
          1.0319434420489788,
          1.0346372239741148,
          1.0255971292010395,
          0.9914952834162948,
          0.9893075967168872,
          1.0015007710073975,
          1.0031015443313802,
          1.0026704054482922,
          1.0105215284593154,
          1.0191622634273088,
          1.0200738558852172,
          1.0201524493111738,
          1.0150269276516548,
          1.0203183264351119,
          1.0214389849888323,
          1.0199535580528811,
          1.026874183701969,
          1.0225155761430322,
          1.0249624690148578,
          1.0246396962771585,
          1.0227677181472972,
          1.0122298603558124,
          1.0251274261463883,
          1.0157435082908743,
          1.0049877550299584,
          1.0067325458967253,
          1.0146871527344943,
          1.0148688294838344,
          1.0198377664029052,
          1.0221294580730211,
          1.025304860431455,
          1.019506342658693,
          1.0225133534329216,
          1.0232418680977533,
          1.0215156833619852,
          1.0171497820421052,
          1.019542041289642,
          1.013880293144539,
          1.0165754109959575,
          1.005362232529558,
          1.0061893010380873,
          0.997552395055565,
          1.001703960145958,
          1.0027124428313374,
          0.9982721483152696,
          1.0063973878099663,
          1.0140610963624819,
          1.0220504505871622,
          1.0250923713599847,
          1.0171424701485572,
          1.0230146544910033,
          1.0240568302292052,
          1.0209832924155877,
          1.0251988459399757,
          1.0277761542939539,
          1.0273907305422203,
          1.0240024502501313,
          1.0242519091525493,
          1.023335977905538,
          1.0318146400479213,
          1.035608516757178,
          1.0291068647057544,
          1.0236045999716608,
          1.0313884827278372,
          1.0052267593545559,
          1.0102582043550856,
          1.0128748391173914,
          1.015620196327335,
          1.0136210857993824,
          1.0122947229771806,
          1.0048594420984738,
          1.0002467412628369,
          1.0085580698659462,
          1.0015746436263147,
          1.0096081072505096,
          1.0149130486604985,
          1.019486718784175,
          1.0227269288943819,
          1.0206167779862216,
          1.0179604898897654,
          1.0238400445781517,
          1.0298676494609895,
          1.0302115095490028,
          1.0342407940127765,
          1.0277053681640078,
          1.0285981038331715,
          1.0000641304941809,
          0.998080152370471,
          0.9948308170603181,
          0.9988827212116995,
          0.9999339241668024,
          1.0018090558100767,
          1.006335606718181,
          1.0075524493024244,
          1.0037497809177292,
          1.0082163722202373,
          1.0081109334891034,
          1.0147179371426467,
          1.0157323050176248,
          1.008246785494094,
          1.005411000720849,
          1.0009377224720977,
          1.0011392646605326,
          1.0028377906626944,
          0.9982689719333401,
          0.9981241018165932,
          0.9910165134550376,
          0.9861382334242559,
          0.9870184633422652,
          0.9819994289684232,
          0.9542056371959368,
          0.9338148610351922,
          0.9424152913869627,
          0.9416722597934437,
          0.9604644005528299,
          0.9582014191554433,
          0.9457141464153828,
          0.9436332300872359,
          0.9382653901114757,
          0.932792092270397,
          0.9087692767131341,
          0.9207202565211371,
          0.9067266270619604,
          0.9063173087195768,
          0.9247399729664841,
          0.9305008538694935,
          0.9967284176335686,
          1.0033225568595492,
          1.0107535844156226,
          1.026931441745048,
          1.0250118030344841,
          1.0169015643226291,
          1.0009170882633842,
          1.0008859823224419,
          0.9950233767234633,
          1.0042101464630782,
          1.0073705221988785,
          0.9937114637980354,
          0.9774001794550805,
          0.9827781212746501,
          0.9797289072760359,
          0.9932200886150467,
          0.9933714487616395,
          1.0121572555180869,
          1.0089809254587472,
          1.0152251669953587,
          0.9684545579771351,
          0.9666307668164001,
          0.9456133459343661,
          0.944326021008207,
          0.942899001195013,
          0.9480051728004442,
          0.9437637493235984,
          0.9301514037002588,
          0.9101098873675157,
          0.9094921509767487,
          0.8960815976891642,
          0.8818698591497356,
          0.8659044806166741,
          0.8425839233894398,
          0.8803361839106032,
          0.8880839912060001,
          0.8866304167820916,
          0.8939146110876248,
          0.9805359527811992,
          1.012364029373076,
          1.022921485688638,
          1.033993682069357,
          1.040821842546517,
          1.047560214025029,
          1.0486938194583049,
          1.0433369594303992,
          1.051028660477483,
          1.0534906064842298,
          1.0629727591937517,
          1.0787333159229426,
          1.0646433220758562,
          1.0643701203688254,
          1.069274844929925,
          1.0800560755073052,
          1.0755746447015122,
          1.0774224838267594,
          1.0894808960119537,
          1.0979848524535427,
          1.005490754553035,
          1.009802848124478,
          1.008676406264135,
          1.0031977658088427,
          1.0049082393576603,
          1.007299180712481,
          1.0195216489526164,
          1.02369340634728,
          1.021714847751723,
          1.0331732709764265,
          1.0351194878768726,
          1.0383573627737697,
          1.0350632318757518,
          1.0410257874659494,
          1.0408409674637602,
          1.038194448743934,
          1.0385405933824825,
          1.0365784367294535,
          0.9949172301766638,
          0.9919349102023832,
          0.9839142874785363,
          0.9767047005601275,
          0.9740932334736229,
          0.9870093800383594,
          0.9899412238278638,
          0.9960091283227536,
          0.9947364059129454,
          0.9981313155628003,
          1.0025420293519327,
          1.00075817209168,
          0.9946706277455009,
          1.0078320654240351,
          0.9881644169620047,
          0.9885368632548985,
          0.9965957845511959,
          0.9933915360451119,
          0.9986610981709939,
          1.0047892339980458,
          0.9992254431460029,
          1.002043175480279,
          1.0051632075128105,
          1.011745061039074,
          1.0123514051528648,
          1.004223294978094,
          1.0096828556857353,
          1.0111945381341585,
          1.0183282279129222,
          1.016181829670475,
          1.0160152654205072,
          1.0105033312979317,
          1.0128077397305515,
          1.01041920324458,
          1.0196364744588564,
          1.019387328608551,
          1.0141679608455472,
          1.0206124728814354,
          1.0205621219347945,
          1.0239176130020002,
          1.0009288226057442,
          1.0100507133090872,
          1.005562739297292,
          0.9892728718825693,
          0.9873430700165535,
          0.9861253267265054,
          0.9902737625173351,
          0.9667010001288397,
          0.9757483424875001,
          0.9788683708699001,
          0.9859275009869344,
          0.9795266061199586,
          0.973516320136963,
          0.9836616305738493,
          0.979136712561193,
          0.9675355896248684,
          0.969533622449441,
          0.9595214690028673,
          0.9525849827187761,
          0.9539236075718169,
          0.9439826018728816,
          1.022445933851089,
          1.0300733488331262,
          1.034903896881441,
          1.042475969435519,
          1.0466959405858256,
          1.0458708764087792,
          1.0439830822139842,
          1.0506857351310248,
          1.0478006246639817,
          1.0468793786556694,
          1.0573844726341715,
          1.061452807304432,
          1.0711877401063576,
          1.068527086451875,
          1.0642964466370501,
          1.0568577439727203,
          1.0545902923974726,
          1.0613152040488805,
          1.0708716647873477,
          1.0003345245617332,
          1.0097546621849802,
          1.0082848347493525,
          1.0029680637769298,
          1.0027354800061101,
          1.003942274900218,
          1.0058021535277433,
          1.0129806351295008,
          1.0119363695578212,
          1.0106102548825893,
          1.0022532674618498,
          1.0057876514677113,
          1.0007267097356203,
          1.0009514301655522,
          1.0098213646508911,
          1.0163594470048496,
          1.0100734483288885,
          1.0158709017912912,
          1.01364241757711,
          1.0139250553851533,
          1.004561471406313,
          0.9921874064660572,
          0.9639624952893023,
          0.9749075135793659,
          0.9764722369298312,
          0.9944801829257225,
          0.9864820881032053,
          0.9741293454877777,
          0.9864825587801884,
          0.9565185053954098,
          0.9572213898189932,
          0.9722647454596421,
          0.9840194585751553,
          0.9758038650309715,
          0.9839436779387198,
          0.9844977511690837,
          0.9585053541940275,
          0.9670683809238706,
          0.9622336787813189,
          0.9697632627417275,
          0.9827038016048697,
          0.98445569722937,
          1.0117049940740253,
          1.0269843725073429,
          1.0294725536641327,
          1.0352298486529066,
          1.0409338045763539,
          1.0492299616714351,
          1.0497304315049272,
          1.0505249588836414,
          1.0510332480235607,
          1.0508133212927258,
          1.0495910665014077,
          1.0468939812776192,
          1.0428931855385253,
          1.0433763539235044,
          1.035219681297827,
          1.0413618611126783,
          1.0392651792682521,
          1.0352697624793439,
          1.0403738863582108,
          0.9813632472779468,
          0.9882294122956515,
          0.9999724803082515,
          0.9950626289403751,
          0.9775512483174938,
          0.9859569050456268,
          0.9930681776565261,
          1.0072614342396458,
          1.0048115396751562,
          1.013671136834663,
          1.011769426176844,
          1.0155683373864848,
          1.0144137083706728,
          1.0217818034996835,
          1.0217471383666217,
          1.0248759031616976,
          1.0255014415603714,
          1.02923818782058,
          1.031722619869961,
          1.0343027118921702,
          1.0345944710508872,
          1.0291230403176417,
          1.005214664121771,
          1.0050388542615354,
          1.0044159995525872,
          1.0068692779472304,
          1.0086968267945726,
          1.0061556695770233,
          1.0069545124032395,
          1.0062131821519336,
          1.008383381894603,
          1.0158741226579193,
          1.0148807148848789,
          1.0141329564883086,
          1.0105396443046728,
          1.0078199549611513,
          1.0114246904544004,
          1.019829445396381,
          1.0217881013586936,
          1.0261121306493608,
          1.0211474236244988,
          0.9920018609315416,
          0.9994872220221521,
          1.0013366469310103,
          1.010263131531115,
          1.0076825884932004,
          1.0065140978411837,
          1.0090956221133904,
          1.0194964557272634,
          1.0168004587596566,
          1.0230477580638964,
          1.0236393449505838,
          1.0250680982738785,
          1.028609112398069,
          1.0347036745213603,
          1.0349651567173714,
          1.0352234279620744,
          1.0376615055235487,
          1.0367768952505259,
          1.0327466368661586
         ]
        },
        {
         "line": {
          "color": "rgba(128, 0, 128, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "S&P 500",
         "text": "",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477
         ],
         "y": [
          1.0063988187678174,
          1.0104532331222378,
          1.01756052613646,
          1.0192520618530718,
          1.0205800775224427,
          1.0194449608291194,
          1.0266153766139654,
          1.0335446225887093,
          1.0299019074919185,
          1.0395984871573627,
          1.0379180905786511,
          1.0424696056080711,
          1.0508789228462483,
          1.053163917658637,
          1.0525741713615295,
          1.0532084745811838,
          1.0656797230238397,
          1.0585055944403243,
          1.0469691373757133,
          1.0474810899872826,
          0.9787914523050585,
          0.9386813371369133,
          0.9550528040953712,
          0.9502760228653357,
          0.9146060632223194,
          0.9282667019487502,
          0.9411831475856182,
          0.943642392884729,
          0.9562895208774654,
          0.9678310868101905,
          0.9681925422447539,
          0.9625369525123278,
          0.9572463650149637,
          0.9581782933130517,
          0.9735363356475689,
          0.9849822173437246,
          0.9724661579633176,
          0.9616758790755133,
          1.005071602697713,
          1.016159579134265,
          1.0188410806669994,
          1.0183480893579684,
          1.02289305656995,
          1.0406697424149502,
          1.0393439449479687,
          1.0327300001691544,
          1.0268181142903392,
          1.0260152139842424,
          1.0277629768289267,
          1.0131644306530774,
          1.014665743031788,
          1.0127947099523045,
          0.9873098694051805,
          0.9666090613837801,
          0.9928595108594567,
          0.9757065632079799,
          0.9728607617380555,
          0.9862567806817226,
          1.0126148657086849,
          1.0243272579849914,
          1.0313570764980473,
          1.0087494728739093,
          1.0121152146565606,
          1.029044819045906,
          1.0233589712662865,
          1.031802450431812,
          1.0288240233366426,
          1.037166796810276,
          1.0482245556115208,
          1.0490960136583551,
          1.0430887589823636,
          1.0341843981903012,
          1.0342425519413678,
          1.0204038059039324,
          1.022278348182939,
          1.0329450097814639,
          1.0340953231711592,
          1.0256286771649166,
          0.9927941364144521,
          0.990556701620733,
          1.0032469010248992,
          1.0067160741565893,
          1.0064486487434146,
          1.016193306164882,
          1.0257156914795584,
          1.0274671992820958,
          1.0283749557818398,
          1.0213386699391316,
          1.0254858786918764,
          1.0246081937600573,
          1.0219112252999667,
          1.0294598310819911,
          1.0262316900386654,
          1.029565311342211,
          1.0274822810205553,
          1.0250602786545306,
          1.0132062894955904,
          1.0260697452623868,
          1.0190108370003281,
          1.0044795984363044,
          1.0051853388746206,
          1.013797156235869,
          1.0130731138039089,
          1.016239883457275,
          1.0173259469223745,
          1.0190995380584336,
          1.01499651295076,
          1.0175051272030116,
          1.0164702200206917,
          1.0143090745060876,
          1.0102281010902103,
          1.0119577672952513,
          1.005536378857846,
          1.0074086217219176,
          0.9935822716687778,
          0.9957727005926209,
          0.9872047185704218,
          0.9933043504338407,
          0.9940576755436773,
          0.995052649459258,
          1.003630802740886,
          1.0121428782208493,
          1.0210730007304945,
          1.0246194600673186,
          1.01735060188897,
          1.0262514455236553,
          1.0273590147346074,
          1.0263027502102562,
          1.0303809679741733,
          1.0326071189351556,
          1.0285252300803842,
          1.0275497277211143,
          1.0294384148472329,
          1.03436006848548,
          1.0437744053116034,
          1.040609372314535,
          1.0337806764626405,
          1.0278321266601336,
          1.032852807699117,
          1.0049264450595978,
          1.0095935073980913,
          1.0131656786160577,
          1.016027043209936,
          1.0157604580692234,
          1.0142960621713257,
          1.0070804736124737,
          1.0030461173380103,
          1.0094548344287018,
          1.001780792294429,
          1.0097143035233918,
          1.013069701211911,
          1.015529452447731,
          1.0176301120772238,
          1.017224940696154,
          1.0155045466420984,
          1.021799496569033,
          1.0296371171228813,
          1.0299143763326282,
          1.0357863651188828,
          1.031197490780373,
          1.0313361637497624,
          0.9971968733321512,
          0.9935548060610239,
          0.9913557267355201,
          0.9932371481551123,
          0.9969516977518016,
          0.99730728234759,
          1.0025753131385442,
          1.0028515041435464,
          0.9972659000251012,
          1.0026202353268479,
          1.0038767917204379,
          1.0117477800203973,
          1.0113749176067663,
          1.0078192390796339,
          1.0065039383125098,
          1.003193266899322,
          1.0059653777973,
          1.0059584665320758,
          0.9996033098775927,
          1.0003145473287949,
          0.9921424950818614,
          0.9866579524562761,
          0.9862681077376338,
          0.9848696744950467,
          0.9525026920627381,
          0.9329068467389267,
          0.9461599060852729,
          0.9405728516576987,
          0.96079102966583,
          0.9605482739364328,
          0.9467241376357972,
          0.9463822093757982,
          0.9423132131602848,
          0.9371193427227399,
          0.908195684892166,
          0.925110865656466,
          0.9090812254028265,
          0.9031180167222123,
          0.9172669681153622,
          0.9272205363502554,
          0.9936833138368367,
          0.9992482555596338,
          1.005502845731112,
          1.026828411076269,
          1.0242521842534016,
          1.0148300745026697,
          0.994836410632192,
          0.9933621429867606,
          0.9858449635108176,
          0.996288761895005,
          0.9985038163368646,
          0.981885608556284,
          0.9640631667273433,
          0.9669970912180984,
          0.9606585777113843,
          0.9755798804019727,
          0.9787619217422666,
          1.0012479781394434,
          0.9990621456627131,
          1.007225230226082,
          0.9676350970612119,
          0.966162135472726,
          0.9436311197422418,
          0.9452939432407204,
          0.9449570911527936,
          0.950078289560467,
          0.9498883402068774,
          0.9317580973076341,
          0.9124022385020405,
          0.9124810706966155,
          0.8984327726729308,
          0.884262595477043,
          0.8660571951645509,
          0.8425764323077432,
          0.8843629509812443,
          0.8919354686452154,
          0.8908280571297416,
          0.8983934004766292,
          0.9752432698883858,
          1.0087289441747151,
          1.0158005727189647,
          1.025649048918211,
          1.029852205405627,
          1.034505509097238,
          1.034354163099138,
          1.028916019793164,
          1.0399477372149,
          1.0422584860637139,
          1.0501706874200907,
          1.0640151433024947,
          1.048951554993528,
          1.0512623038423419,
          1.052708552276846,
          1.0616446732558196,
          1.0533141306892309,
          1.0517802454545853,
          1.0681346509898666,
          1.0773178275788666,
          1.0067762366585589,
          1.0115165624123952,
          1.0092665064607713,
          0.9998226585351513,
          1.0004987397093463,
          1.001208196460029,
          1.0141139948903926,
          1.0171806702684842,
          1.0144834716703601,
          1.0255197866862462,
          1.0270567775769541,
          1.028881971070863,
          1.025253683967162,
          1.0318266902923765,
          1.0330977587686687,
          1.032281139342201,
          1.0317195276165916,
          1.0288043953566641,
          0.9961194417967204,
          0.9949922996852526,
          0.9885008718230445,
          0.9804685931210823,
          0.9783785388984994,
          0.9927274797038621,
          0.9956593199476047,
          1.0025787377178452,
          1.0017084767220341,
          1.0067018962137082,
          1.0104326800093903,
          1.01030075636313,
          1.0073260736501675,
          1.0182580610114618,
          0.9989371221273714,
          0.9980989930726437,
          1.0052680646971726,
          1.0005992731134172,
          1.0041909056447977,
          1.0109534084175678,
          1.0000174557671553,
          1.0021658701124747,
          1.004255020508249,
          1.0089111811654476,
          1.009967975470098,
          1.0038400002185275,
          1.0073312268920238,
          1.0073696293007466,
          1.0140276618667168,
          1.0133894641757184,
          1.013905642395667,
          1.0116002115954688,
          1.0131976216360477,
          1.0142229956295734,
          1.023189949870154,
          1.0209473596922052,
          1.0205706570592352,
          1.025352328759443,
          1.0264510163472285,
          1.0274275993632191,
          0.9978760145285372,
          1.0074938223262329,
          1.0029893290624603,
          0.9864283188695834,
          0.984844681860806,
          0.9818690476334619,
          0.9855218921413533,
          0.9617406998029281,
          0.9694499599446598,
          0.9751105541558941,
          0.9837844423649551,
          0.9780417646502367,
          0.9714405911041079,
          0.979693790669411,
          0.9769267475240655,
          0.9652874955299399,
          0.9665940693333113,
          0.9584981896994471,
          0.9518731343309619,
          0.953870612565939,
          0.9412839345034183,
          1.021432370802961,
          1.029769153185042,
          1.036087391196153,
          1.0469639233001995,
          1.0518428215271907,
          1.051474802791913,
          1.0493323396007523,
          1.0536318550631134,
          1.0519339144618276,
          1.052914053304957,
          1.063145640144341,
          1.0663193037765843,
          1.0764196778023158,
          1.0750642255017029,
          1.0732023358366578,
          1.0630107799695856,
          1.0616990949090916,
          1.065758157088725,
          1.0718942092305626,
          1.0029281260087797,
          1.010622970172487,
          1.0087978846193795,
          1.0039198984911424,
          1.00516130275557,
          1.0096952732130933,
          1.0120026559336488,
          1.0166782850421827,
          1.0168570873300702,
          1.0133959309372158,
          1.0067771953430888,
          1.0103834688412185,
          1.0041425983871153,
          1.0069830114917453,
          1.013878310416685,
          1.0186315219785724,
          1.0132710740588453,
          1.0207568075689852,
          1.0191071478241773,
          1.016479222190047,
          1.0054143110172231,
          0.9927172599946105,
          0.9631563039768206,
          0.9756937263621089,
          0.976441962374194,
          0.994762262933215,
          0.9881803124694816,
          0.9760085772476247,
          0.9907772347757092,
          0.9617546422813407,
          0.9641246634964737,
          0.9780332460813522,
          0.9898731847660052,
          0.982038608343735,
          0.9901372830014966,
          0.9896361992346404,
          0.9639587650585846,
          0.974545912560365,
          0.9714242658642347,
          0.977782704028637,
          0.9901881186022634,
          0.9908245989725447,
          1.0108420789476402,
          1.0239929461199893,
          1.0249253993956144,
          1.0248290459948386,
          1.0251593528807763,
          1.0325709281479636,
          1.0355438576901401,
          1.0347936951157761,
          1.0315490096821769,
          1.0342122137020153,
          1.0345666298412286,
          1.0345872951612392,
          1.0295223937932652,
          1.0294225961151402,
          1.0207585935184373,
          1.027045008364364,
          1.0245504018928016,
          1.0191035308549894,
          1.024247564581078,
          0.9820967968710144,
          0.9899259869058753,
          1.0039996632939374,
          0.9995034568489072,
          0.9839503644247936,
          0.992908732930873,
          0.9992789330839211,
          1.010210022957231,
          1.0088087414335511,
          1.018852115296318,
          1.016814876626137,
          1.0196241649519595,
          1.0156279061304307,
          1.0226069113170644,
          1.0189575682339933,
          1.0218586922880701,
          1.0238211169118265,
          1.0279908337726376,
          1.0337283979253455,
          1.0328679170138584,
          1.0362282186888858,
          1.033095845251253,
          1.0037040892383409,
          1.0025139978744835,
          1.0032182611433682,
          1.0059571427020124,
          1.0085330729466828,
          1.0065538599361377,
          1.0081287604511808,
          1.0088460788801936,
          1.009690526247189,
          1.0174605875413794,
          1.0179725256305474,
          1.0173692809793886,
          1.0135478544177075,
          1.0119436592697673,
          1.0141445716518327,
          1.0217580505833912,
          1.0240013923173887,
          1.0282760085846303,
          1.024151367378019,
          0.9933619048889829,
          0.999643496048875,
          1.001143212422562,
          1.0102893806729702,
          1.0070940158612913,
          1.0059893002274503,
          1.0089148760086188,
          1.017566548682094,
          1.0176404056482997,
          1.024914280649169,
          1.0252579266458848,
          1.0248147074530016,
          1.0293846552881123,
          1.0344747372133245,
          1.035370740866389,
          1.035168379503736,
          1.0404768953951842,
          1.040512255893812,
          1.0344972391152558
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": "Days"
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": "Comulative Return"
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"1bfb43f9-e0f8-44be-96fc-064bae6eb6dc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';                                    if (document.getElementById(\"1bfb43f9-e0f8-44be-96fc-064bae6eb6dc\")) {                    Plotly.newPlot(                        \"1bfb43f9-e0f8-44be-96fc-064bae6eb6dc\",                        [{\"line\":{\"color\":\"rgba(255, 153, 51, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"1/N Model\",\"text\":\"\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477],\"y\":[1.005443342664013,1.008572994842972,1.014449464317343,1.0182419050805815,1.0185056900797973,1.0156959100764915,1.024812748553089,1.0309717887089722,1.0246954300306539,1.033650034225885,1.0312830197699063,1.0381040743734162,1.0443933846164353,1.047401484570692,1.0472057042226137,1.0469113994063004,1.0570299319192908,1.0496729636655506,1.0392336873748804,1.0394948393540526,0.9799002432619366,0.9442233563075461,0.9563128311974386,0.9538936707193497,0.9213029108110568,0.9336559864593101,0.944993631808935,0.9482296317511052,0.9620262346937991,0.9724224459133792,0.9726636698055255,0.9666233403404936,0.9612472701000855,0.9618554811462964,0.9766986401078889,0.9838713997955385,0.9709029137407595,0.960967103349419,1.006637391318661,1.0182918740912303,1.0233566074903748,1.0230489824093478,1.0266332853020017,1.0430616777644697,1.041904152761347,1.0377558722405456,1.0322213478591742,1.0299008297352743,1.0346559767326187,1.023049609813605,1.0242071506436974,1.0240319892338574,1.000661288083951,0.9812608980841633,1.004147585646594,0.9915547020001465,0.9902604723839443,1.0031956391844399,1.0120855571192562,1.0237142253482234,1.030206273864736,1.0082529142879362,1.0097221411078974,1.0248020659480968,1.0199819822643068,1.0255497429835476,1.0228367293687626,1.0329481517202699,1.0422999720724024,1.0450880028621745,1.0381663131205339,1.030850620716514,1.0321077802688658,1.0215061894192192,1.0242093051479066,1.031826827764115,1.0345327923640886,1.0255201508922966,0.9915081423965098,0.9893456720051855,1.0015518731092998,1.0031625245204687,1.002745545855196,1.0105739380670804,1.019207918181998,1.0201642360730336,1.020254158032857,1.015104967630127,1.0204150165834929,1.0215050070187917,1.0200053287735218,1.0269378286644042,1.0225753929322008,1.0250539506109553,1.0247416479065519,1.0229103578466423,1.012397414182743,1.0252901479231717,1.0159122350862542,1.0049707293291201,1.0067162930964415,1.0146520394856335,1.0148123194974803,1.0197855207330582,1.0220715852394695,1.025252026199786,1.0194412925483314,1.0224356439857285,1.0231684267722703,1.0214622661620296,1.0170888879712843,1.0194812164897868,1.0138124426665334,1.0164836211060189,1.0052648449439585,1.0060772778011176,0.9973863134626133,1.0015625918050255,1.0025701151438495,0.9982900353087949,1.0064154550811855,1.0141002127462522,1.0220657755366178,1.0251172080882731,1.0171563659789877,1.023029778866516,1.024056586060722,1.020991849637657,1.0252014612395055,1.0277807822498775,1.0273917820305858,1.0239961043450088,1.0242534919054636,1.0233192454314328,1.0317973943658245,1.0356221043654523,1.0291183453508002,1.0235975562790818,1.0313620709825542,1.0052388779847212,1.0102684338695789,1.0129083644459322,1.0156618363361558,1.013681128727133,1.0123523932420353,1.0049170911083092,1.0002877965784476,1.008574022523303,1.0016073674123194,1.009623867504817,1.0149053151148397,1.0194891832432407,1.0227594401259996,1.0206623423086392,1.01800610514766,1.0238791046646516,1.029895813977138,1.0302380224622194,1.0342582005818266,1.027697307843729,1.028602829164031,1.000072716663728,0.9981090620476213,0.9948700718092104,0.9989255346686817,0.9999562768732599,1.0018175885682377,1.0063573217405315,1.0076126076335372,1.0038142017004836,1.0083064563406972,1.0082097981021694,1.014821971077671,1.0158551660959105,1.0083411158500215,1.0055043859794313,1.0010459519965522,1.0012659063617126,1.0029669710973295,0.9982820629657406,0.998130361492734,0.9910422748441834,0.9861629356813625,0.9870935366751656,0.9820778777729959,0.9542963116748875,0.9338997950355324,0.9424956363454339,0.9417732507613,0.9605637795052012,0.958299443023155,0.9458454581073856,0.943812124039161,0.9384269211576811,0.9329431296673716,0.9089103702148211,0.9208861534367766,0.9068471292603368,0.9064343688431429,0.9248943003964439,0.9306163391612574,0.9968136676413681,1.0034241116703817,1.0108538588177591,1.0270077392364376,1.0251075122154008,1.016976085275572,1.0010168196476705,1.0009627313350096,0.9950631290882429,1.0042223729636834,1.0073820053570375,0.9937351026403017,0.9774116425691708,0.982765508998034,0.9797371074358034,0.9932464476726408,0.9934103674713658,1.0122120144927764,1.0090327367402445,1.0152598215329245,0.9684241112549253,0.9665977466689051,0.9455534751437957,0.9442768673179054,0.9428311319580917,0.9479558639419493,0.9436930928246507,0.9300744441972718,0.9100602645644033,0.9094673912330824,0.8960326585683293,0.8818218546658511,0.8657919306444628,0.8425123473785396,0.8802645541358531,0.8880187823194293,0.8865810053232152,0.8938660890485721,0.9805450126719798,1.01237314956618,1.0229162416580715,1.0340003635559638,1.0408615872322298,1.0476040698272857,1.0487511009973736,1.0434327240887262,1.0510882967570403,1.0535284494758133,1.063043081242437,1.0788287556950427,1.0647208238870658,1.0644314743958507,1.0693335674309268,1.0801500998657867,1.0756644971693083,1.0775101385605288,1.0895527054572538,1.0981041743473015,1.005462348515306,1.0097743034981717,1.0086895452471127,1.0032095415882458,1.0049132792405115,1.007324547883383,1.019545440167558,1.0237384337235433,1.0217227747235904,1.0331986965019213,1.035162276931138,1.0384265782034852,1.0351313385584764,1.0410225585377952,1.0408459775737358,1.0382025924357072,1.0384997869242865,1.0365150386358755,0.9949240275479585,0.9919403672720388,0.9839148218534932,0.9766845003425241,0.9740782268574915,0.9869922564969158,0.9899149573065528,0.995978094687409,0.9947090117673436,0.9981155462206186,1.002512158511703,1.0007164145966823,0.9946177584254281,1.007754438579759,0.9880675836504316,0.9884087033827774,0.9964729163234572,0.9932479810878121,0.9985286854512843,1.0046588990506224,0.9992204969722017,1.0020236629464987,1.0051378083692273,1.011692578057859,1.0123058963155103,1.0042062504684555,1.0096629850214445,1.0111747840219765,1.0182635050485496,1.016142302424912,1.015956003952552,1.010407006429896,1.0127254622699744,1.0103416510975394,1.0196017462718763,1.0193225411006401,1.0141294565210652,1.0206066430531708,1.0205750586335423,1.023935313688307,1.0009367100509614,1.010079988127478,1.0055868996577517,0.9893482419632176,0.9874125287269507,0.9862168131668447,0.9903796014697095,0.9668323746499007,0.9758714671237488,0.9789857902310706,0.986051702902669,0.9796630262605792,0.9736525703131335,0.9837872644070002,0.9792849989119821,0.9676698724818218,0.9696548610511231,0.9596268217017132,0.952712617917459,0.9540795039396539,0.9441386802366818,1.022423667171756,1.0301187461748647,1.034938668567928,1.0425112845197415,1.0467121065730371,1.0458482569679406,1.0439971895821865,1.0506764495964311,1.0478105421958888,1.046887678857214,1.0573726409979483,1.0614464762668727,1.0711774504498746,1.0685033785621145,1.064291935439254,1.056880155684432,1.0545504431353594,1.061264226008105,1.0708290944221477,1.0003469677598489,1.0097489754652786,1.0082754806143486,1.0029662161579784,1.0027255421103332,1.0039314114784175,1.0057589549113686,1.0129756448833842,1.011942460936397,1.0106149256231074,1.0022850210003191,1.0058531886297322,1.000794517022307,1.0010378726703573,1.0099166601943672,1.0164600758926907,1.0102090821384249,1.0159881747385613,1.0137768761793824,1.0140742509528244,1.0046368515543038,0.9921821962186009,0.9639471208637771,0.974900254085206,0.9764612300409367,0.994441177863714,0.9864482807697572,0.9740849617605101,0.9864440866441988,0.956485090422442,0.9572229169744378,0.9722258546497455,0.9839545692720564,0.9757594906954808,0.9839053536219673,0.9844562336275365,0.9584856616109824,0.9670462298142577,0.9622078011011312,0.9697398026616689,0.9826812985229402,0.9844037369284769,1.011692419811061,1.026928319470596,1.0293950186672747,1.035119409754866,1.0408297897989018,1.0491452692152132,1.04969576230964,1.0504971856263567,1.0509933307636476,1.0507850777040468,1.0495488036818401,1.0468264144984143,1.0428303457046617,1.043325260541347,1.0351635867662856,1.041310235557371,1.0392017043846284,1.035209853711937,1.0403179839497725,0.981395113932634,0.9882544437148923,1.000007762710438,0.9951065474000065,0.9775799096047503,0.985985753868158,0.993100279306108,1.0072753432469257,1.004822852186623,1.013674030476082,1.0117738590409537,1.0155822240700514,1.0144326956726346,1.0217892399219795,1.0217267689708056,1.024843465264599,1.0254867710945779,1.0292494594090904,1.031757201886155,1.0343489068403935,1.0346404818200796,1.0291176957393835,1.0051818384430729,1.005019907861984,1.0044199810328494,1.006932606789332,1.0087693595630758,1.0062295273290982,1.007016080224759,1.006272074760273,1.0084543859873978,1.0159690373838683,1.0149793776971234,1.0142057872778334,1.010598332627208,1.0078916160338123,1.0115022078076934,1.0198950201812902,1.021827479397883,1.026159116029552,1.0212031931862264,0.9919897289748665,0.9994713791624729,1.001321433020612,1.0102513318815265,1.0076599842521878,1.0065037973301556,1.009102725435664,1.019507518852647,1.0167783504260837,1.023021562283747,1.0236297269276766,1.0250692198185642,1.0286186133052613,1.0346978669924138,1.034931247447906,1.0351898582574872,1.0376339130988324,1.036738145716607,1.032728182705108],\"type\":\"scatter\"},{\"line\":{\"color\":\"rgba(55, 128, 191, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"Shallow NNF\",\"text\":\"\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477],\"y\":[1.003003539597625,1.009776998480948,1.0129132197058375,1.0134881548340995,1.0121531144869136,1.005906072907689,1.017446084444817,1.022355433928138,1.0186771588444543,1.0239029777069735,1.0223275170728123,1.0290127824963278,1.031889021813358,1.0282449970300591,1.026265784965382,1.0290891299350169,1.0324519964897396,1.0241650649270744,1.0199583344705918,1.0197856169971768,0.9787410690833702,0.9443814516984292,0.9553830028281245,0.9530939571356362,0.9237463102181068,0.9348183778359295,0.944984721772775,0.9482533464286428,0.9605534146889849,0.9703654659656731,0.9704826052360646,0.9624424488644912,0.9551433745153027,0.957679816215425,0.9714301284958988,0.9774939441946726,0.9618146282498018,0.9518529552333659,1.0061255247067145,1.0175613694440042,1.0234005113749214,1.02046923932262,1.0263103601449777,1.0428024450540538,1.041000659454196,1.0375987265272046,1.0300629758408575,1.0268764569778255,1.0318889011717467,1.0213978210305015,1.0209443636985898,1.01825263733533,0.9942572428293238,0.9734932147004736,0.9967239087008171,0.9885428140564487,0.9900036580071563,1.0019952780267625,1.0133511737747543,1.021607296222455,1.0185392010739147,1.0062309309946498,1.006457263616227,1.0141099521584471,1.0057108168357536,1.0111092330887967,1.005261992770628,1.0186906025844027,1.02289721261607,1.0240945870274618,1.0324047045952915,1.032845732268583,1.0374224225138768,1.0210046021727583,1.0297037184908262,1.0232647529909964,1.0300912022735043,1.017787754445363,1.0094072930601625,1.0037118184545408,1.0257493268950209,1.0289710185629053,1.0309479783887652,1.0302083865966218,1.0363996429480737,1.0368951408847757,1.0339232354456374,1.0304530655258537,1.0341687913565112,1.0371385151799326,1.0430796769752877,1.0544698266633639,1.0381296611280473,1.031445484609521,1.0309506115123537,1.0309515084325422,1.027484120979925,1.0406111934371616,1.02278256231997,1.005132583312862,1.0038177032672766,1.0112391686950963,1.0124764546386602,1.0192220756503267,1.0221953288759775,1.0244415866990586,1.0180632055290095,1.0229593300946498,1.0255736576716368,1.0211403108579133,1.0192054612230972,1.0215664546499958,1.016572458318263,1.0218015166031285,1.0150802274720234,1.0134984122263797,1.0048978929353904,1.0116046254867377,1.0155548956832903,1.000478801109067,1.0081921139119856,1.0193301480217112,0.983010565471299,0.9906918508900823,1.0026146509499108,1.0067631424577657,1.0009287992586948,0.9986344760616562,0.9968557743082122,0.993800389085012,1.001787102641951,0.9956514141561063,0.9874591083069141,0.9894650208894573,0.9897736864980015,1.005427152878978,1.0087664969540298,1.0012331099432503,1.0190687156571636,0.9834388063044437,0.9983861274751775,1.0068812569421735,1.007972862234563,1.0060216395873034,1.0056136915581333,0.9989641968244818,1.0003566815706517,0.9995129635223401,1.004011584566698,1.0165172057429963,1.0254743369105832,1.0232438589540787,1.010522919747624,0.994731306208861,0.9938237800741972,1.005280883064884,0.9982267763142842,1.0064182573135285,1.0026339347193172,0.9994810121629208,1.002783958214839,1.002996215059643,1.0030725169006862,0.9987409383192666,1.0032202340698404,1.003170986934864,1.0054514365382958,1.0110054959277381,1.0131101722938578,1.0099997828045453,1.0153476752226571,1.0134620813558908,1.0200201460780478,1.0219456269873513,1.0127775370254577,1.009025012386858,1.0045668136914507,1.0044674934883384,1.0061272255648472,1.0024045338826386,0.9926489046693505,0.9917468362951178,0.991704518907841,0.9948122799500725,0.9924733299351184,0.9596703174620623,0.9295540223264207,0.932383362857614,0.9273536943713503,0.9361425155013253,0.936474717755244,0.926469116540505,0.9247688390541572,0.9143021966639893,0.9109267396150711,0.887029266710428,0.9002761045951332,0.8597204037094047,0.8555534017451039,0.8719509816979599,0.8821851489562286,1.008225940636272,1.0134716212641277,1.019372936392093,1.0270630031290744,1.0344224083126967,1.0226098633748095,1.0133483571215425,1.0165199853197784,0.9964998703246221,1.0119376857859326,1.021163275314528,1.0229496858043432,1.0148700856592072,1.0267980903551341,1.0189157486661136,1.0265101678370554,1.0319415007797705,1.0542122788484296,1.0490944024928068,1.0473382880341089,0.9608745502071291,0.9585252050008131,0.9324532482541318,0.9221312757202803,0.9171538432826318,0.9244839666339433,0.9334267576556394,0.9150760132385796,0.9006088425963406,0.9047266053712913,0.8790387570359994,0.864132682596012,0.8558366193793601,0.8384841962405357,0.8713242387640602,0.8850689899216572,0.885548099728775,0.8910992235945604,0.9748468053177056,1.000218715981531,0.9991249585479024,0.9971563386374775,0.9967191761066676,1.003827568977073,0.9945319300684441,0.9842521155614171,0.9885171154115547,0.9823928982694219,0.9919072528007464,1.0100611887595887,1.0066709618905096,1.0146543068495604,1.016076003414724,1.0138887573770954,1.012576553030272,1.0134514156263175,1.0219815945556268,1.0277776934684304,0.9932194497115626,0.9932202195266219,0.9773973055029438,0.9699019356599621,0.9639546450687628,0.9683569940893711,0.9844180803655977,0.9825144255187649,0.973592187568363,0.9917942070703618,0.9951259364758569,0.9995279643029027,0.9898922908142422,0.9868006785403229,0.9829939510150382,0.98287496179313,0.9844219371326492,0.9822807154347308,0.9919861732701989,1.002112006449558,1.0016686938985957,1.0007502040253127,0.990696859365637,0.9902429356529548,0.9780866133849865,0.9857725558925676,0.9839533466250655,0.9815539814132375,0.9816494102746135,0.981149977174542,0.9761083441075249,0.9948813992835581,1.0040260910246253,1.0152705721062822,1.0223532522828458,1.0128749839190143,1.0234140441403783,1.0318948567600668,1.0014278810646537,0.9961142011716827,0.9904311527794382,1.0028538699480267,0.993995542332194,0.9922213703907757,0.9890395086941262,0.9950695967241645,0.9961385113845895,0.9929416940655177,0.9794478381769479,0.979084019939792,0.9780258785842413,0.9691715850932203,0.9688207683723041,0.9762694031503899,0.9879582755831354,0.9893851120918067,0.9815235904610461,0.9929711415507011,0.9926099597591066,1.003831110708539,0.9923562211467917,0.9684316020381004,0.9663592248031074,0.9695731353985909,0.9722881241772333,0.9383713559808852,0.9445160711747729,0.9415913916430962,0.9488553324066438,0.9342551369275803,0.9332823454890745,0.9430849156370296,0.9368548339903311,0.9192159598977822,0.922659741610764,0.9129855323564298,0.9085042525374387,0.9063372770842985,0.8899223516848894,1.0448577545635949,1.048104480587059,1.044681975614061,1.0604190211759943,1.0703378514145496,1.0507278248940373,1.0526756643613164,1.0742515902992258,1.0682212127599147,1.0643468867818335,1.1009656804260028,1.1018427525180976,1.1332834419566615,1.1212279630992386,1.119064428725413,1.1147527430690813,1.109994169488658,1.1203557221014877,1.1455946409256315,0.9998598076603112,1.0091736671045421,1.0080014736841616,1.0030733616672265,1.002542046734297,1.0032883930787175,1.005165309268338,1.0124489921825335,1.0105746268407174,1.0101991004679873,1.0008286855089326,1.0045048238448218,0.9996016399887196,0.9992634581417301,1.010462671968819,1.0181046775389055,1.0118103618965626,1.017464429199295,1.0151578032475201,1.0165298502244509,1.0070426764029465,0.9958341670724481,0.9681521716003899,0.9774518421762713,0.9804210328501837,1.0012686895461653,0.9959313333507709,0.9864839180770081,0.9973265669380644,0.9727914513873352,0.9727184532581749,0.9865375686460657,0.9969797617052947,0.9890544144223818,0.9979379024933596,0.9986672770638462,0.9737425251378476,0.9842871916524005,0.9789748303029392,0.9851987057326808,0.9979143058146723,1.000395143175626,1.0198083299893201,1.0442107870842214,1.0474169848948085,1.0472193461997958,1.0255833949207294,1.024646572859732,1.0354712954360819,1.0313688709580457,1.0307913065379135,1.0345177312797496,1.040289086065903,1.0358041729250709,1.0237898051129974,1.035708905757016,1.0296840258115951,1.072483424886947,1.0884910844794815,1.0901225799950665,1.1090622719120278,0.9808176925722477,0.9903183359712879,1.000983851124487,0.9852296353033652,0.9762239688786788,0.980135589803066,0.9901246264500292,0.998928441015406,1.00428472537103,1.0184589348444644,1.0239834993889065,1.0247037427784615,1.0176998029498099,1.0226032748389542,1.0231997501527843,1.0269536048171595,1.0324735480562441,1.0382972952493854,1.039365629721711,1.032719211952204,1.0319009246565034,1.030822308223161,1.016687106634275,1.0167633876130933,1.020736931583302,1.0220150319461914,1.03563748423017,1.0352742925483909,1.0375568919692633,1.0315188579415664,1.0346169400217373,1.0431006898722999,1.0399208033290983,1.0432875113207445,1.0308776940137518,1.0276100389266258,1.0316833477392873,1.0435534472964036,1.0390236142694975,1.0473402648330625,1.0435142986619494,0.9916432887466795,0.9992147640593522,1.001550871234943,1.0104746052180764,1.00823753303733,1.0069074182320361,1.0083192553641542,1.0199239470660932,1.0154798528819897,1.0216644026372899,1.022356978440213,1.0236923250775185,1.0261744504093777,1.0310175909219124,1.0303260800460037,1.0306281850085037,1.0332079700185557,1.0321642751777338,1.0285792139763619],\"type\":\"scatter\"},{\"line\":{\"color\":\"rgba(50, 171, 96, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"Deep NNF\",\"text\":\"\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477],\"y\":[1.0054743370028698,1.008621653588767,1.0144859072718861,1.0182743941704242,1.0185447054410364,1.0157452241095148,1.0249055696909428,1.0310905307497624,1.024788946759263,1.033749610180838,1.0313785038635457,1.0381798314930888,1.0444762080982737,1.0474846381832918,1.0472872431631775,1.046998265465785,1.0571120073544205,1.0497459227046408,1.0393022824988407,1.0395557742626447,0.979924499120728,0.9442789716138619,0.956341663640257,0.9539277102482087,0.9213281972687789,0.9336592253361639,0.9450242998951394,0.9482456707306786,0.9620516219662522,0.9724372299687755,0.9727090001098114,0.9666412519231399,0.9612697794622135,0.9618721501527113,0.9767191742308259,0.983907925785366,0.9709442036746203,0.9609788958960392,1.006674204544816,1.0183419579508708,1.023388514074228,1.0231093530818143,1.0267016901525952,1.0431367930942335,1.0419410734802121,1.0377607684996255,1.032205658186458,1.0298943016891493,1.0346300498098782,1.0230385518805747,1.0241572898576368,1.0239849867155442,1.0006033145978142,0.9811901861075717,1.0040988950550518,0.9914945734720779,0.9902052896094613,1.0031213994377222,1.0121158649636703,1.0237503010773632,1.0302542243046842,1.008316552949884,1.0097940652259527,1.024897551560079,1.0200790212533253,1.0256241505920096,1.0229127781894443,1.0330112561734761,1.0423683363384932,1.0451774708631658,1.038223654058138,1.0309046871407836,1.0321671341772174,1.021584646753248,1.0242764630619159,1.0319434420489788,1.0346372239741148,1.0255971292010395,0.9914952834162948,0.9893075967168872,1.0015007710073975,1.0031015443313802,1.0026704054482922,1.0105215284593154,1.0191622634273088,1.0200738558852172,1.0201524493111738,1.0150269276516548,1.0203183264351119,1.0214389849888323,1.0199535580528811,1.026874183701969,1.0225155761430322,1.0249624690148578,1.0246396962771585,1.0227677181472972,1.0122298603558124,1.0251274261463883,1.0157435082908743,1.0049877550299584,1.0067325458967253,1.0146871527344943,1.0148688294838344,1.0198377664029052,1.0221294580730211,1.025304860431455,1.019506342658693,1.0225133534329216,1.0232418680977533,1.0215156833619852,1.0171497820421052,1.019542041289642,1.013880293144539,1.0165754109959575,1.005362232529558,1.0061893010380873,0.997552395055565,1.001703960145958,1.0027124428313374,0.9982721483152696,1.0063973878099663,1.0140610963624819,1.0220504505871622,1.0250923713599847,1.0171424701485572,1.0230146544910033,1.0240568302292052,1.0209832924155877,1.0251988459399757,1.0277761542939539,1.0273907305422203,1.0240024502501313,1.0242519091525493,1.023335977905538,1.0318146400479213,1.035608516757178,1.0291068647057544,1.0236045999716608,1.0313884827278372,1.0052267593545559,1.0102582043550856,1.0128748391173914,1.015620196327335,1.0136210857993824,1.0122947229771806,1.0048594420984738,1.0002467412628369,1.0085580698659462,1.0015746436263147,1.0096081072505096,1.0149130486604985,1.019486718784175,1.0227269288943819,1.0206167779862216,1.0179604898897654,1.0238400445781517,1.0298676494609895,1.0302115095490028,1.0342407940127765,1.0277053681640078,1.0285981038331715,1.0000641304941809,0.998080152370471,0.9948308170603181,0.9988827212116995,0.9999339241668024,1.0018090558100767,1.006335606718181,1.0075524493024244,1.0037497809177292,1.0082163722202373,1.0081109334891034,1.0147179371426467,1.0157323050176248,1.008246785494094,1.005411000720849,1.0009377224720977,1.0011392646605326,1.0028377906626944,0.9982689719333401,0.9981241018165932,0.9910165134550376,0.9861382334242559,0.9870184633422652,0.9819994289684232,0.9542056371959368,0.9338148610351922,0.9424152913869627,0.9416722597934437,0.9604644005528299,0.9582014191554433,0.9457141464153828,0.9436332300872359,0.9382653901114757,0.932792092270397,0.9087692767131341,0.9207202565211371,0.9067266270619604,0.9063173087195768,0.9247399729664841,0.9305008538694935,0.9967284176335686,1.0033225568595492,1.0107535844156226,1.026931441745048,1.0250118030344841,1.0169015643226291,1.0009170882633842,1.0008859823224419,0.9950233767234633,1.0042101464630782,1.0073705221988785,0.9937114637980354,0.9774001794550805,0.9827781212746501,0.9797289072760359,0.9932200886150467,0.9933714487616395,1.0121572555180869,1.0089809254587472,1.0152251669953587,0.9684545579771351,0.9666307668164001,0.9456133459343661,0.944326021008207,0.942899001195013,0.9480051728004442,0.9437637493235984,0.9301514037002588,0.9101098873675157,0.9094921509767487,0.8960815976891642,0.8818698591497356,0.8659044806166741,0.8425839233894398,0.8803361839106032,0.8880839912060001,0.8866304167820916,0.8939146110876248,0.9805359527811992,1.012364029373076,1.022921485688638,1.033993682069357,1.040821842546517,1.047560214025029,1.0486938194583049,1.0433369594303992,1.051028660477483,1.0534906064842298,1.0629727591937517,1.0787333159229426,1.0646433220758562,1.0643701203688254,1.069274844929925,1.0800560755073052,1.0755746447015122,1.0774224838267594,1.0894808960119537,1.0979848524535427,1.005490754553035,1.009802848124478,1.008676406264135,1.0031977658088427,1.0049082393576603,1.007299180712481,1.0195216489526164,1.02369340634728,1.021714847751723,1.0331732709764265,1.0351194878768726,1.0383573627737697,1.0350632318757518,1.0410257874659494,1.0408409674637602,1.038194448743934,1.0385405933824825,1.0365784367294535,0.9949172301766638,0.9919349102023832,0.9839142874785363,0.9767047005601275,0.9740932334736229,0.9870093800383594,0.9899412238278638,0.9960091283227536,0.9947364059129454,0.9981313155628003,1.0025420293519327,1.00075817209168,0.9946706277455009,1.0078320654240351,0.9881644169620047,0.9885368632548985,0.9965957845511959,0.9933915360451119,0.9986610981709939,1.0047892339980458,0.9992254431460029,1.002043175480279,1.0051632075128105,1.011745061039074,1.0123514051528648,1.004223294978094,1.0096828556857353,1.0111945381341585,1.0183282279129222,1.016181829670475,1.0160152654205072,1.0105033312979317,1.0128077397305515,1.01041920324458,1.0196364744588564,1.019387328608551,1.0141679608455472,1.0206124728814354,1.0205621219347945,1.0239176130020002,1.0009288226057442,1.0100507133090872,1.005562739297292,0.9892728718825693,0.9873430700165535,0.9861253267265054,0.9902737625173351,0.9667010001288397,0.9757483424875001,0.9788683708699001,0.9859275009869344,0.9795266061199586,0.973516320136963,0.9836616305738493,0.979136712561193,0.9675355896248684,0.969533622449441,0.9595214690028673,0.9525849827187761,0.9539236075718169,0.9439826018728816,1.022445933851089,1.0300733488331262,1.034903896881441,1.042475969435519,1.0466959405858256,1.0458708764087792,1.0439830822139842,1.0506857351310248,1.0478006246639817,1.0468793786556694,1.0573844726341715,1.061452807304432,1.0711877401063576,1.068527086451875,1.0642964466370501,1.0568577439727203,1.0545902923974726,1.0613152040488805,1.0708716647873477,1.0003345245617332,1.0097546621849802,1.0082848347493525,1.0029680637769298,1.0027354800061101,1.003942274900218,1.0058021535277433,1.0129806351295008,1.0119363695578212,1.0106102548825893,1.0022532674618498,1.0057876514677113,1.0007267097356203,1.0009514301655522,1.0098213646508911,1.0163594470048496,1.0100734483288885,1.0158709017912912,1.01364241757711,1.0139250553851533,1.004561471406313,0.9921874064660572,0.9639624952893023,0.9749075135793659,0.9764722369298312,0.9944801829257225,0.9864820881032053,0.9741293454877777,0.9864825587801884,0.9565185053954098,0.9572213898189932,0.9722647454596421,0.9840194585751553,0.9758038650309715,0.9839436779387198,0.9844977511690837,0.9585053541940275,0.9670683809238706,0.9622336787813189,0.9697632627417275,0.9827038016048697,0.98445569722937,1.0117049940740253,1.0269843725073429,1.0294725536641327,1.0352298486529066,1.0409338045763539,1.0492299616714351,1.0497304315049272,1.0505249588836414,1.0510332480235607,1.0508133212927258,1.0495910665014077,1.0468939812776192,1.0428931855385253,1.0433763539235044,1.035219681297827,1.0413618611126783,1.0392651792682521,1.0352697624793439,1.0403738863582108,0.9813632472779468,0.9882294122956515,0.9999724803082515,0.9950626289403751,0.9775512483174938,0.9859569050456268,0.9930681776565261,1.0072614342396458,1.0048115396751562,1.013671136834663,1.011769426176844,1.0155683373864848,1.0144137083706728,1.0217818034996835,1.0217471383666217,1.0248759031616976,1.0255014415603714,1.02923818782058,1.031722619869961,1.0343027118921702,1.0345944710508872,1.0291230403176417,1.005214664121771,1.0050388542615354,1.0044159995525872,1.0068692779472304,1.0086968267945726,1.0061556695770233,1.0069545124032395,1.0062131821519336,1.008383381894603,1.0158741226579193,1.0148807148848789,1.0141329564883086,1.0105396443046728,1.0078199549611513,1.0114246904544004,1.019829445396381,1.0217881013586936,1.0261121306493608,1.0211474236244988,0.9920018609315416,0.9994872220221521,1.0013366469310103,1.010263131531115,1.0076825884932004,1.0065140978411837,1.0090956221133904,1.0194964557272634,1.0168004587596566,1.0230477580638964,1.0236393449505838,1.0250680982738785,1.028609112398069,1.0347036745213603,1.0349651567173714,1.0352234279620744,1.0376615055235487,1.0367768952505259,1.0327466368661586],\"type\":\"scatter\"},{\"line\":{\"color\":\"rgba(128, 0, 128, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"S&P 500\",\"text\":\"\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477],\"y\":[1.0063988187678174,1.0104532331222378,1.01756052613646,1.0192520618530718,1.0205800775224427,1.0194449608291194,1.0266153766139654,1.0335446225887093,1.0299019074919185,1.0395984871573627,1.0379180905786511,1.0424696056080711,1.0508789228462483,1.053163917658637,1.0525741713615295,1.0532084745811838,1.0656797230238397,1.0585055944403243,1.0469691373757133,1.0474810899872826,0.9787914523050585,0.9386813371369133,0.9550528040953712,0.9502760228653357,0.9146060632223194,0.9282667019487502,0.9411831475856182,0.943642392884729,0.9562895208774654,0.9678310868101905,0.9681925422447539,0.9625369525123278,0.9572463650149637,0.9581782933130517,0.9735363356475689,0.9849822173437246,0.9724661579633176,0.9616758790755133,1.005071602697713,1.016159579134265,1.0188410806669994,1.0183480893579684,1.02289305656995,1.0406697424149502,1.0393439449479687,1.0327300001691544,1.0268181142903392,1.0260152139842424,1.0277629768289267,1.0131644306530774,1.014665743031788,1.0127947099523045,0.9873098694051805,0.9666090613837801,0.9928595108594567,0.9757065632079799,0.9728607617380555,0.9862567806817226,1.0126148657086849,1.0243272579849914,1.0313570764980473,1.0087494728739093,1.0121152146565606,1.029044819045906,1.0233589712662865,1.031802450431812,1.0288240233366426,1.037166796810276,1.0482245556115208,1.0490960136583551,1.0430887589823636,1.0341843981903012,1.0342425519413678,1.0204038059039324,1.022278348182939,1.0329450097814639,1.0340953231711592,1.0256286771649166,0.9927941364144521,0.990556701620733,1.0032469010248992,1.0067160741565893,1.0064486487434146,1.016193306164882,1.0257156914795584,1.0274671992820958,1.0283749557818398,1.0213386699391316,1.0254858786918764,1.0246081937600573,1.0219112252999667,1.0294598310819911,1.0262316900386654,1.029565311342211,1.0274822810205553,1.0250602786545306,1.0132062894955904,1.0260697452623868,1.0190108370003281,1.0044795984363044,1.0051853388746206,1.013797156235869,1.0130731138039089,1.016239883457275,1.0173259469223745,1.0190995380584336,1.01499651295076,1.0175051272030116,1.0164702200206917,1.0143090745060876,1.0102281010902103,1.0119577672952513,1.005536378857846,1.0074086217219176,0.9935822716687778,0.9957727005926209,0.9872047185704218,0.9933043504338407,0.9940576755436773,0.995052649459258,1.003630802740886,1.0121428782208493,1.0210730007304945,1.0246194600673186,1.01735060188897,1.0262514455236553,1.0273590147346074,1.0263027502102562,1.0303809679741733,1.0326071189351556,1.0285252300803842,1.0275497277211143,1.0294384148472329,1.03436006848548,1.0437744053116034,1.040609372314535,1.0337806764626405,1.0278321266601336,1.032852807699117,1.0049264450595978,1.0095935073980913,1.0131656786160577,1.016027043209936,1.0157604580692234,1.0142960621713257,1.0070804736124737,1.0030461173380103,1.0094548344287018,1.001780792294429,1.0097143035233918,1.013069701211911,1.015529452447731,1.0176301120772238,1.017224940696154,1.0155045466420984,1.021799496569033,1.0296371171228813,1.0299143763326282,1.0357863651188828,1.031197490780373,1.0313361637497624,0.9971968733321512,0.9935548060610239,0.9913557267355201,0.9932371481551123,0.9969516977518016,0.99730728234759,1.0025753131385442,1.0028515041435464,0.9972659000251012,1.0026202353268479,1.0038767917204379,1.0117477800203973,1.0113749176067663,1.0078192390796339,1.0065039383125098,1.003193266899322,1.0059653777973,1.0059584665320758,0.9996033098775927,1.0003145473287949,0.9921424950818614,0.9866579524562761,0.9862681077376338,0.9848696744950467,0.9525026920627381,0.9329068467389267,0.9461599060852729,0.9405728516576987,0.96079102966583,0.9605482739364328,0.9467241376357972,0.9463822093757982,0.9423132131602848,0.9371193427227399,0.908195684892166,0.925110865656466,0.9090812254028265,0.9031180167222123,0.9172669681153622,0.9272205363502554,0.9936833138368367,0.9992482555596338,1.005502845731112,1.026828411076269,1.0242521842534016,1.0148300745026697,0.994836410632192,0.9933621429867606,0.9858449635108176,0.996288761895005,0.9985038163368646,0.981885608556284,0.9640631667273433,0.9669970912180984,0.9606585777113843,0.9755798804019727,0.9787619217422666,1.0012479781394434,0.9990621456627131,1.007225230226082,0.9676350970612119,0.966162135472726,0.9436311197422418,0.9452939432407204,0.9449570911527936,0.950078289560467,0.9498883402068774,0.9317580973076341,0.9124022385020405,0.9124810706966155,0.8984327726729308,0.884262595477043,0.8660571951645509,0.8425764323077432,0.8843629509812443,0.8919354686452154,0.8908280571297416,0.8983934004766292,0.9752432698883858,1.0087289441747151,1.0158005727189647,1.025649048918211,1.029852205405627,1.034505509097238,1.034354163099138,1.028916019793164,1.0399477372149,1.0422584860637139,1.0501706874200907,1.0640151433024947,1.048951554993528,1.0512623038423419,1.052708552276846,1.0616446732558196,1.0533141306892309,1.0517802454545853,1.0681346509898666,1.0773178275788666,1.0067762366585589,1.0115165624123952,1.0092665064607713,0.9998226585351513,1.0004987397093463,1.001208196460029,1.0141139948903926,1.0171806702684842,1.0144834716703601,1.0255197866862462,1.0270567775769541,1.028881971070863,1.025253683967162,1.0318266902923765,1.0330977587686687,1.032281139342201,1.0317195276165916,1.0288043953566641,0.9961194417967204,0.9949922996852526,0.9885008718230445,0.9804685931210823,0.9783785388984994,0.9927274797038621,0.9956593199476047,1.0025787377178452,1.0017084767220341,1.0067018962137082,1.0104326800093903,1.01030075636313,1.0073260736501675,1.0182580610114618,0.9989371221273714,0.9980989930726437,1.0052680646971726,1.0005992731134172,1.0041909056447977,1.0109534084175678,1.0000174557671553,1.0021658701124747,1.004255020508249,1.0089111811654476,1.009967975470098,1.0038400002185275,1.0073312268920238,1.0073696293007466,1.0140276618667168,1.0133894641757184,1.013905642395667,1.0116002115954688,1.0131976216360477,1.0142229956295734,1.023189949870154,1.0209473596922052,1.0205706570592352,1.025352328759443,1.0264510163472285,1.0274275993632191,0.9978760145285372,1.0074938223262329,1.0029893290624603,0.9864283188695834,0.984844681860806,0.9818690476334619,0.9855218921413533,0.9617406998029281,0.9694499599446598,0.9751105541558941,0.9837844423649551,0.9780417646502367,0.9714405911041079,0.979693790669411,0.9769267475240655,0.9652874955299399,0.9665940693333113,0.9584981896994471,0.9518731343309619,0.953870612565939,0.9412839345034183,1.021432370802961,1.029769153185042,1.036087391196153,1.0469639233001995,1.0518428215271907,1.051474802791913,1.0493323396007523,1.0536318550631134,1.0519339144618276,1.052914053304957,1.063145640144341,1.0663193037765843,1.0764196778023158,1.0750642255017029,1.0732023358366578,1.0630107799695856,1.0616990949090916,1.065758157088725,1.0718942092305626,1.0029281260087797,1.010622970172487,1.0087978846193795,1.0039198984911424,1.00516130275557,1.0096952732130933,1.0120026559336488,1.0166782850421827,1.0168570873300702,1.0133959309372158,1.0067771953430888,1.0103834688412185,1.0041425983871153,1.0069830114917453,1.013878310416685,1.0186315219785724,1.0132710740588453,1.0207568075689852,1.0191071478241773,1.016479222190047,1.0054143110172231,0.9927172599946105,0.9631563039768206,0.9756937263621089,0.976441962374194,0.994762262933215,0.9881803124694816,0.9760085772476247,0.9907772347757092,0.9617546422813407,0.9641246634964737,0.9780332460813522,0.9898731847660052,0.982038608343735,0.9901372830014966,0.9896361992346404,0.9639587650585846,0.974545912560365,0.9714242658642347,0.977782704028637,0.9901881186022634,0.9908245989725447,1.0108420789476402,1.0239929461199893,1.0249253993956144,1.0248290459948386,1.0251593528807763,1.0325709281479636,1.0355438576901401,1.0347936951157761,1.0315490096821769,1.0342122137020153,1.0345666298412286,1.0345872951612392,1.0295223937932652,1.0294225961151402,1.0207585935184373,1.027045008364364,1.0245504018928016,1.0191035308549894,1.024247564581078,0.9820967968710144,0.9899259869058753,1.0039996632939374,0.9995034568489072,0.9839503644247936,0.992908732930873,0.9992789330839211,1.010210022957231,1.0088087414335511,1.018852115296318,1.016814876626137,1.0196241649519595,1.0156279061304307,1.0226069113170644,1.0189575682339933,1.0218586922880701,1.0238211169118265,1.0279908337726376,1.0337283979253455,1.0328679170138584,1.0362282186888858,1.033095845251253,1.0037040892383409,1.0025139978744835,1.0032182611433682,1.0059571427020124,1.0085330729466828,1.0065538599361377,1.0081287604511808,1.0088460788801936,1.009690526247189,1.0174605875413794,1.0179725256305474,1.0173692809793886,1.0135478544177075,1.0119436592697673,1.0141445716518327,1.0217580505833912,1.0240013923173887,1.0282760085846303,1.024151367378019,0.9933619048889829,0.999643496048875,1.001143212422562,1.0102893806729702,1.0070940158612913,1.0059893002274503,1.0089148760086188,1.017566548682094,1.0176404056482997,1.024914280649169,1.0252579266458848,1.0248147074530016,1.0293846552881123,1.0344747372133245,1.035370740866389,1.035168379503736,1.0404768953951842,1.040512255893812,1.0344972391152558],\"type\":\"scatter\"}],                        {\"legend\":{\"bgcolor\":\"#F5F6F9\",\"font\":{\"color\":\"#4D5663\"}},\"paper_bgcolor\":\"#F5F6F9\",\"plot_bgcolor\":\"#F5F6F9\",\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"color\":\"#4D5663\"}},\"xaxis\":{\"gridcolor\":\"#E1E5ED\",\"showgrid\":true,\"tickfont\":{\"color\":\"#4D5663\"},\"title\":{\"font\":{\"color\":\"#4D5663\"},\"text\":\"Days\"},\"zerolinecolor\":\"#E1E5ED\"},\"yaxis\":{\"gridcolor\":\"#E1E5ED\",\"showgrid\":true,\"tickfont\":{\"color\":\"#4D5663\"},\"title\":{\"font\":{\"color\":\"#4D5663\"},\"text\":\"Comulative Return\"},\"zerolinecolor\":\"#E1E5ED\"}},                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('1bfb43f9-e0f8-44be-96fc-064bae6eb6dc');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing a module for better and more interactive plot\n",
    "import cufflinks as cf\n",
    "cf.set_config_file(offline = True)\n",
    "\n",
    "'''\n",
    "plotting deep nnf, shallow nnf and, 1/n model performance on the test dataset, compare them with\n",
    "index (s&p) for better understanding\n",
    "'''\n",
    "plot_test.iplot(xTitle='Days', yTitle='Comulative Return')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72a5606bcafec1593511b6d198bb0982fb8ea54acb1913d581966686ae52246b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
