{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta as rd\n",
    "import time\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks data csv read\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df.set_index('Date')\n",
    "\n",
    "# s&p data csv read\n",
    "df_sp = pd.read_csv('sp500.csv')\n",
    "df_sp = df_sp.set_index('Date')\n",
    "\n",
    "# stocks data csv read for partial replication\n",
    "df_reduce = pd.read_csv('data.csv')\n",
    "df_reduce = df_reduce.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_slicer(df, start, duration, rebalancing_period=0):\n",
    "    start = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=rebalancing_period))\n",
    "    end = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=duration) - rd(days=1))\n",
    "    return df.loc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(df):\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    df = df.cumprod()\n",
    "    df = df - 1\n",
    "    df = df.iloc[-1,:]\n",
    "    df = df.to_numpy()\n",
    "    df = torch.from_numpy(df).type(torch.Tensor)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_change(df):\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_return(df):\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_finder(df):\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    df = df.cumprod()\n",
    "    df = df - 1\n",
    "    df = df.iloc[-1,:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_index = index_finder(df).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf biuld\n",
    "class shallow_NNF(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_classes):\n",
    "        super(shallow_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.softmax(self.fc2(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf build\n",
    "class deep_NNF(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size1, hidden_size2, hidden_size3,\n",
    "                 hidden_size4, hidden_size5, num_classes, dropout_p = 0.2):\n",
    "        super(deep_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.fc5 = nn.Linear(hidden_size4, hidden_size5)\n",
    "        self.fc6 = nn.Linear(hidden_size5, num_classes)\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        self.fc3.reset_parameters()\n",
    "        self.fc4.reset_parameters()\n",
    "        self.fc5.reset_parameters()\n",
    "        self.fc6.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc4(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc5(out))\n",
    "        out = self.softmax(self.fc6(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deep_NNF_partial(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size1, hidden_size2, hidden_size3,\n",
    "                 hidden_size4, hidden_size5, num_classes, dropout_p = 0.2):\n",
    "        super(deep_NNF_partial, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.fc5 = nn.Linear(hidden_size4, hidden_size5)\n",
    "        self.fc6 = nn.Linear(hidden_size5, num_classes)\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        self.fc3.reset_parameters()\n",
    "        self.fc4.reset_parameters()\n",
    "        self.fc5.reset_parameters()\n",
    "        self.fc6.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc4(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc5(out))\n",
    "        out = self.softmax(self.fc6(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/N model build\n",
    "class equal_w_model():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.performance()\n",
    "        \n",
    "    def performance(self):\n",
    "        self.df = np.array(self.df)\n",
    "        weights = np.ones((len(self.df), 1)) * (1/len(self.df))\n",
    "        cumulative_change = sum(np.multiply(weights, self.df.reshape(-1,1)))\n",
    "        return cumulative_change, weights.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebalancing period = one or three months\n",
    "rbp = 1\n",
    "\n",
    "# epochs\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size = 471\n",
    "num_classes = 471\n",
    "lr = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf tune\n",
    "shallow_NNF = shallow_NNF(input_dim=input_dim, hidden_size=hidden_size, num_classes=num_classes)\n",
    "shallow_NNF_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "shallow_NNF_optimizer = torch.optim.Adam(shallow_NNF.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size1 = 471\n",
    "hidden_size2 = 471\n",
    "hidden_size3 = 471\n",
    "hidden_size4 = 471\n",
    "hidden_size5 = 471\n",
    "num_classes = 471\n",
    "lr = 1e-3\n",
    "dropout_p = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf tune\n",
    "deep_NNF = deep_NNF(input_dim=input_dim, hidden_size1=hidden_size1, hidden_size2=hidden_size2, \n",
    "                    hidden_size3=hidden_size3, hidden_size4=hidden_size4, hidden_size5=hidden_size5,\n",
    "                    num_classes=num_classes)\n",
    "deep_NNF_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "deep_NNF_optimizer = torch.optim.Adam(deep_NNF.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_NNF_partial = deep_NNF_partial(input_dim=200, hidden_size1=hidden_size1, hidden_size2=hidden_size2, \n",
    "                    hidden_size3=hidden_size3, hidden_size4=hidden_size4, hidden_size5=hidden_size5,\n",
    "                    num_classes=200)\n",
    "deep_NNF_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "deep_NNF_optimizer = torch.optim.Adam(deep_NNF_partial.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "def RMSE(x, y, weights):\n",
    "    temp = 0\n",
    "    for i in range(len(x)):\n",
    "        temp += (sum(x.iloc[i] * weights) - y.iloc[i]) ** 2\n",
    "    return math.sqrt(temp/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEAN\n",
    "def MEAN(x, weights):\n",
    "    temp = []\n",
    "    for i in range(len(x)):\n",
    "        temp.append(sum(x.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility\n",
    "def VOL(x, weights):\n",
    "    temp = []\n",
    "    for i in range(len(x)):\n",
    "        temp.append(sum(x.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fun(x_valid, i, model):\n",
    "    x_change = daily_change(date_slicer(df_reduce, '2017-07-01', 6, i))\n",
    "    y_change = daily_change(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    # x_return = daily_return(date_slicer(df, '2017-07-01', 6, i))\n",
    "    # y_return = daily_return(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_valid).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_valid)[1].detach())\n",
    "    \n",
    "    valid_rmse = RMSE(x_change, y_change, weights)\n",
    "    # valid_mean = MEAN(x_return, weights)\n",
    "    # valid_vol  = VOL(x_return, weights)\n",
    "    \n",
    "    print(f'Validation RMSE: {valid_rmse}')\n",
    "    # print(f'Validation MEAN: {valid_mean}')\n",
    "    # print(f'Validation VOL: {valid_vol}')\n",
    "    \n",
    "    return valid_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fun(x_test, i, model):\n",
    "    x_change = daily_change(date_slicer(df_reduce, '2018-01-01', 6, i))\n",
    "    y_change = daily_change(date_slicer(df_sp, '2018-01-01', 6, i))\n",
    "    x_return = daily_return(date_slicer(df_reduce, '2018-01-01', 6, i))\n",
    "    y_return = daily_return(date_slicer(df_sp, '2018-01-01', 6, i))\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_test).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_test)[1].detach())\n",
    "    \n",
    "    test_rmse = RMSE(x_change, y_change, weights)\n",
    "    test_mean = MEAN(x_return, weights)\n",
    "    test_vol  = VOL(x_return, weights)\n",
    "    test_dic = {'RMSE': test_rmse, 'MEAN': test_mean, 'VOL': test_vol}\n",
    "    \n",
    "    print(f'Test RMSE: {test_rmse}')\n",
    "    print(f'Test MEAN: {test_mean}')\n",
    "    print(f'Test VOL: {test_vol}')\n",
    "    \n",
    "    return test_dic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deep NNF Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf training function\n",
    "def train_deep_nnf(x_train, y_train, i):\n",
    "    start_time_deep_nnf = time.time()\n",
    "    print(f'\\nDeep NNF Training & Results for model {i+1} (Full Reblication) :')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = deep_NNF(x_train)[0]\n",
    "        loss_deep_nnf = deep_NNF_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            weights = np.array(deep_NNF(x_train)[1].detach())\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_deep_nnf.item()}')\n",
    "        deep_NNF_optimizer.zero_grad()\n",
    "        loss_deep_nnf.backward()\n",
    "        deep_NNF_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_deep_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deep_nnf_partial(x_train, y_train, i):    \n",
    "    start_time_deep_nnf = time.time()\n",
    "    print(f'\\nDeep NNF Training & Results for model {i+1} (Partial Reblication):')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = deep_NNF_partial(x_train)[0]\n",
    "        loss_deep_nnf = deep_NNF_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_deep_nnf.item()}')\n",
    "        deep_NNF_optimizer.zero_grad()\n",
    "        loss_deep_nnf.backward()\n",
    "        deep_NNF_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_deep_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial(x_train, x_valid, x_test, weights, stocks_index, num = 200):\n",
    "    df_partial = pd.DataFrame({'x_train': x_train, 'x_valid': x_valid, 'x_test': x_test,\n",
    "                               'weights': weights}, index = stocks_index)\n",
    "    df_partial = df_partial.sort_values(by = ['weights'])\n",
    "    out_index = df_partial.index[num:]\n",
    "    df_partial = df_partial.iloc[:num]\n",
    "    \n",
    "    x_train = df_partial['x_train'].to_numpy()\n",
    "    x_valid = df_partial['x_valid'].to_numpy()\n",
    "    x_test = df_partial['x_test'].to_numpy()\n",
    "    \n",
    "    x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "    x_valid = torch.from_numpy(x_valid).type(torch.Tensor)\n",
    "    x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "    \n",
    "    return x_train, x_valid, x_test, out_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def df_reduce(df, out_index):\n",
    "#     df_reduce = df_reduce.drop(out_index, axis=1)\n",
    "    # for i in out_index():\n",
    "    #     symbol = out_index[i]\n",
    "    #     if not symbol is df_reduce.columns:\n",
    "    #         df_reduce = df_reduce.drop(symbol, axis=1)\n",
    "    #     else:\n",
    "    #         continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deep NNF Training & Results for model 1 (Full Reblication) :\n",
      "Epoch 1 of 100 | MSE: 0.045202791690826416\n",
      "Epoch 100 of 100 | MSE: 0.04521548002958298\n",
      "Training time: 1.27\n",
      "\n",
      "Deep NNF Training & Results for model 2 (Full Reblication) :\n",
      "Epoch 1 of 100 | MSE: 0.05375956371426582\n",
      "Epoch 100 of 100 | MSE: 0.053874026983976364\n",
      "Training time: 1.21\n",
      "\n",
      "Deep NNF Training & Results for model 3 (Full Reblication) :\n",
      "Epoch 1 of 100 | MSE: 0.04506653919816017\n",
      "Epoch 100 of 100 | MSE: 0.04520498588681221\n",
      "Training time: 1.38\n",
      "\n",
      "Deep NNF Training & Results for model 4 (Full Reblication) :\n",
      "Epoch 1 of 100 | MSE: 0.060061004012823105\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bj/_987g_v95g79pn481z7wtctw0000gn/T/ipykernel_85382/1991893142.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_slicer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2018-01-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_slicer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2018-01-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_deep_nnf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m# weights = train_deep_nnf(x_train, y_train, i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdeep_NNF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bj/_987g_v95g79pn481z7wtctw0000gn/T/ipykernel_85382/1933911973.py\u001b[0m in \u001b[0;36mtrain_deep_nnf\u001b[0;34m(x_train, y_train, i)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_NNF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss_deep_nnf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_NNF_loss_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bj/_987g_v95g79pn481z7wtctw0000gn/T/ipykernel_85382/650026538.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mcumulative_change\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcumulative_change\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    924\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             )\n\u001b[0;32m--> 926\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# deep nnf\n",
    "deep_nnf_valid_rmse_list = []\n",
    "deep_nnf_test_results = []\n",
    "\n",
    "for i in range(24):\n",
    "    df_reduce = df.copy()    \n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    x_test = data_process(date_slicer(df, '2018-01-01', 1, i))\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i))\n",
    "    weights = train_deep_nnf(x_train, y_train, i)\n",
    "    deep_NNF.reset_parameters()\n",
    "    x_train, x_valid, x_test, out_index = partial(x_train, x_valid, x_test, weights, stocks_index, num = 200)\n",
    "    df_reduce = df_reduce.drop(out_index, axis=1)\n",
    "    train_deep_nnf_partial(x_train, y_train, i)\n",
    "    deep_nnf_valid_rmse_list.append(valid_fun(x_valid, i, deep_NNF_partial))\n",
    "    deep_nnf_test_results.append(test_fun(x_test, i, deep_NNF_partial))\n",
    "    deep_NNF_partial.reset_parameters()\n",
    "\n",
    "print(f'\\nMin Valid RMSE is: {min(deep_nnf_valid_rmse_list)} for model i = {deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))+1}')\n",
    "print('Selected Model Test Results are:')\n",
    "print('RMSE =', deep_nnf_test_results[deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))]['RMSE'])\n",
    "print('MEAN =', deep_nnf_test_results[deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))]['MEAN'])\n",
    "print('VOL =', deep_nnf_test_results[deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))]['VOL'])\n",
    "\n",
    "deep_best_result_index = deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Shallow NNF Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf training function\n",
    "def train_shallow_nnf(x_train, y_train, i):\n",
    "    start_time_shallow_nnf = time.time()\n",
    "    print(f'\\nShallow NNF Training & Results for model {i+1}:')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = shallow_NNF(x_train)[0]\n",
    "        loss_shallow_nnf = shallow_NNF_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_shallow_nnf.item()}')\n",
    "        shallow_NNF_optimizer.zero_grad()\n",
    "        loss_shallow_nnf.backward()\n",
    "        shallow_NNF_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_shallow_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shallow NNF Training & Results for model 1:\n",
      "Epoch 1 of 10 | MSE: 0.04371798411011696\n",
      "Epoch 10 of 10 | MSE: 0.00019278429681435227\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0014546284129028247\n",
      "Test RMSE: 0.0017157801201284888\n",
      "Test MEAN: 1.0002111756807943\n",
      "Test VOL: 0.009403857108581328\n",
      "\n",
      "Shallow NNF Training & Results for model 2:\n",
      "Epoch 1 of 10 | MSE: 0.05330565199255943\n",
      "Epoch 10 of 10 | MSE: 0.005897405091673136\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.001546255871007465\n",
      "Test RMSE: 0.0019272445788737465\n",
      "Test MEAN: 1.0001865551532412\n",
      "Test VOL: 0.009366691806952\n",
      "\n",
      "Shallow NNF Training & Results for model 3:\n",
      "Epoch 1 of 10 | MSE: 0.04605824500322342\n",
      "Epoch 10 of 10 | MSE: 0.005997266620397568\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0016998343571342897\n",
      "Test RMSE: 0.0018099436629064407\n",
      "Test MEAN: 1.0007226767502353\n",
      "Test VOL: 0.00734694977893762\n",
      "\n",
      "Shallow NNF Training & Results for model 4:\n",
      "Epoch 1 of 10 | MSE: 0.05928375571966171\n",
      "Epoch 10 of 10 | MSE: 0.007325995713472366\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0018807021221453842\n",
      "Test RMSE: 0.0017806228883694233\n",
      "Test MEAN: 1.0008779011704163\n",
      "Test VOL: 0.005763190823782135\n",
      "\n",
      "Shallow NNF Training & Results for model 5:\n",
      "Epoch 1 of 10 | MSE: 0.043423548340797424\n",
      "Epoch 10 of 10 | MSE: 0.004553280770778656\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.00182051633104939\n",
      "Test RMSE: 0.002119084538264717\n",
      "Test MEAN: 1.0001110876398047\n",
      "Test VOL: 0.0070765232732229585\n",
      "\n",
      "Shallow NNF Training & Results for model 6:\n",
      "Epoch 1 of 10 | MSE: 0.05461662635207176\n",
      "Epoch 10 of 10 | MSE: 0.00526947807520628\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0017630638434245442\n",
      "Test RMSE: 0.0023037885899637525\n",
      "Test MEAN: 1.000166849572258\n",
      "Test VOL: 0.00777199933418758\n",
      "\n",
      "Shallow NNF Training & Results for model 7:\n",
      "Epoch 1 of 10 | MSE: 0.036403633654117584\n",
      "Epoch 10 of 10 | MSE: 0.004341721534729004\n",
      "Training time: 0.08\n",
      "Validation RMSE: 0.0017531521878558075\n",
      "Test RMSE: 0.0024511881232108105\n",
      "Test MEAN: 0.999364462020903\n",
      "Test VOL: 0.010226413644050563\n",
      "\n",
      "Shallow NNF Training & Results for model 8:\n",
      "Epoch 1 of 10 | MSE: 0.0348234623670578\n",
      "Epoch 10 of 10 | MSE: 0.0004433800932019949\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.0019593746322649637\n",
      "Test RMSE: 0.002394722708417811\n",
      "Test MEAN: 0.9999094316750323\n",
      "Test VOL: 0.011023496446586026\n",
      "\n",
      "Shallow NNF Training & Results for model 9:\n",
      "Epoch 1 of 10 | MSE: 0.025107188150286674\n",
      "Epoch 10 of 10 | MSE: 0.0037648521829396486\n",
      "Training time: 0.09\n",
      "Validation RMSE: 0.0018831148143435708\n",
      "Test RMSE: 0.0024100217323497447\n",
      "Test MEAN: 1.0000070788432587\n",
      "Test VOL: 0.011217445095596596\n",
      "\n",
      "Shallow NNF Training & Results for model 10:\n",
      "Epoch 1 of 10 | MSE: 0.032166142016649246\n",
      "Epoch 10 of 10 | MSE: 0.004802691750228405\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.001868067971361234\n",
      "Test RMSE: 0.002316982128876275\n",
      "Test MEAN: 1.0000727399987783\n",
      "Test VOL: 0.011497036923447952\n",
      "\n",
      "Shallow NNF Training & Results for model 11:\n",
      "Epoch 1 of 10 | MSE: 0.03505079448223114\n",
      "Epoch 10 of 10 | MSE: 0.004681856371462345\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.002114469668406336\n",
      "Test RMSE: 0.0020610229374398636\n",
      "Test MEAN: 1.000828091831266\n",
      "Test VOL: 0.010259822923303701\n",
      "\n",
      "Shallow NNF Training & Results for model 12:\n",
      "Epoch 1 of 10 | MSE: 0.03382795676589012\n",
      "Epoch 10 of 10 | MSE: 0.002984583145007491\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.0023310435429574976\n",
      "Test RMSE: 0.0018912458501232298\n",
      "Test MEAN: 1.0000360451735584\n",
      "Test VOL: 0.01018181393483742\n",
      "\n",
      "Shallow NNF Training & Results for model 13:\n",
      "Epoch 1 of 10 | MSE: 0.031876444816589355\n",
      "Epoch 10 of 10 | MSE: 0.0036393748596310616\n",
      "Training time: 0.08\n",
      "Validation RMSE: 0.0024104472747239684\n",
      "Test RMSE: 0.002016754593443032\n",
      "Test MEAN: 1.0015303342963318\n",
      "Test VOL: 0.007804881213869393\n",
      "\n",
      "Shallow NNF Training & Results for model 14:\n",
      "Epoch 1 of 10 | MSE: 0.03688463568687439\n",
      "Epoch 10 of 10 | MSE: 0.0028191658202558756\n",
      "Training time: 0.13\n",
      "Validation RMSE: 0.0023682517869172363\n",
      "Test RMSE: 0.0018427328489414795\n",
      "Test MEAN: 1.0008330676640758\n",
      "Test VOL: 0.006790070696051205\n",
      "\n",
      "Shallow NNF Training & Results for model 15:\n",
      "Epoch 1 of 10 | MSE: 0.04469841718673706\n",
      "Epoch 10 of 10 | MSE: 0.0008138759876601398\n",
      "Training time: 0.10\n",
      "Validation RMSE: 0.0024197150064060877\n",
      "Test RMSE: 0.001841401490318184\n",
      "Test MEAN: 1.000271130453005\n",
      "Test VOL: 0.00875885939529901\n",
      "\n",
      "Shallow NNF Training & Results for model 16:\n",
      "Epoch 1 of 10 | MSE: 0.04290163144469261\n",
      "Epoch 10 of 10 | MSE: 0.0012475349940359592\n",
      "Training time: 0.10\n",
      "Validation RMSE: 0.002339724933374005\n",
      "Test RMSE: 0.001946305447237787\n",
      "Test MEAN: 1.0003985848475048\n",
      "Test VOL: 0.008494673131875926\n",
      "\n",
      "Shallow NNF Training & Results for model 17:\n",
      "Epoch 1 of 10 | MSE: 0.024610424414277077\n",
      "Epoch 10 of 10 | MSE: 0.004409154877066612\n",
      "Training time: 0.13\n",
      "Validation RMSE: 0.002130149439508771\n",
      "Test RMSE: 0.001964044046635904\n",
      "Test MEAN: 1.0003902682446792\n",
      "Test VOL: 0.008954139752328531\n",
      "\n",
      "Shallow NNF Training & Results for model 18:\n",
      "Epoch 1 of 10 | MSE: 0.02337954379618168\n",
      "Epoch 10 of 10 | MSE: 0.004759816452860832\n",
      "Training time: 0.09\n",
      "Validation RMSE: 0.0018962557708110785\n",
      "Test RMSE: 0.0018057687547935635\n",
      "Test MEAN: 1.001078380321489\n",
      "Test VOL: 0.008333475487454077\n",
      "\n",
      "Shallow NNF Training & Results for model 19:\n",
      "Epoch 1 of 10 | MSE: 0.019609622657299042\n",
      "Epoch 10 of 10 | MSE: 0.00427213916555047\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.0020680912507909316\n",
      "Test RMSE: 0.0017188433521676562\n",
      "Test MEAN: 1.0006693875569954\n",
      "Test VOL: 0.00808222072152141\n",
      "\n",
      "Shallow NNF Training & Results for model 20:\n",
      "Epoch 1 of 10 | MSE: 0.03669436648488045\n",
      "Epoch 10 of 10 | MSE: 0.00026665927725844085\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.001872458031352192\n",
      "Test RMSE: 0.0016402239356901277\n",
      "Test MEAN: 1.0008715524597025\n",
      "Test VOL: 0.008458144322112993\n",
      "\n",
      "Shallow NNF Training & Results for model 21:\n",
      "Epoch 1 of 10 | MSE: 0.03957456722855568\n",
      "Epoch 10 of 10 | MSE: 0.00047946113045327365\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.0018615462615915342\n",
      "Test RMSE: 0.001731655519416515\n",
      "Test MEAN: 1.0013654032778692\n",
      "Test VOL: 0.006085718164748324\n",
      "\n",
      "Shallow NNF Training & Results for model 22:\n",
      "Epoch 1 of 10 | MSE: 0.03449966758489609\n",
      "Epoch 10 of 10 | MSE: 0.0017150274943560362\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.0019785500986557103\n",
      "Test RMSE: 0.0015256033729124446\n",
      "Test MEAN: 1.001396442993068\n",
      "Test VOL: 0.005960073058966203\n",
      "\n",
      "Shallow NNF Training & Results for model 23:\n",
      "Epoch 1 of 10 | MSE: 0.025430763140320778\n",
      "Epoch 10 of 10 | MSE: 0.00029223290039226413\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.001991756775363548\n",
      "Test RMSE: 0.0011353670952137106\n",
      "Test MEAN: 1.0011636617808117\n",
      "Test VOL: 0.0042604952272880334\n",
      "\n",
      "Shallow NNF Training & Results for model 24:\n",
      "Epoch 1 of 10 | MSE: 0.017317797988653183\n",
      "Epoch 10 of 10 | MSE: 0.0030417758971452713\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.0018746520014661777\n",
      "Test RMSE: 0.0013439625254853497\n",
      "Test MEAN: 1.0017045820300876\n",
      "Test VOL: 0.004521346369800098\n",
      "Selected Model Test Results for model i = 1 are: \n",
      "RMSE = 0.0017157801201284888\n",
      "MEAN = 1.0002111756807943\n",
      "VOL = 0.009403857108581328\n"
     ]
    }
   ],
   "source": [
    "#shallow nnf\n",
    "shallow_nnf_valid_rmse_list = []\n",
    "shallow_nnf_test_results = []\n",
    "\n",
    "for i in range(24):\n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    x_test = data_process(date_slicer(df, '2018-01-01', 1, i))\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i))\n",
    "    \n",
    "    train_shallow_nnf(x_train, y_train, i)\n",
    "    shallow_nnf_valid_rmse_list.append(valid_fun(x_valid, i, shallow_NNF))\n",
    "    shallow_nnf_test_results.append(test_fun(x_test, i, shallow_NNF))\n",
    "    shallow_NNF.reset_parameters()\n",
    "\n",
    "# print(f'\\nMin Valid RMSE is: {min(valid_rmse_list)} for model i = {(deep_best_result_index)+1}')\n",
    "print('Selected Model Test Results for model i =', (deep_best_result_index)+1, 'are: ')\n",
    "print('RMSE =', shallow_nnf_test_results[(deep_best_result_index)]['RMSE'])\n",
    "print('MEAN =', shallow_nnf_test_results[(deep_best_result_index)]['MEAN'])\n",
    "print('VOL =', shallow_nnf_test_results[(deep_best_result_index)]['VOL'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1/N Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Equal Weights Model Results for model 1:\n",
      "Validation RMSE: 0.0013752466607634818\n",
      "Test RMSE: 0.0016838896697022906\n",
      "Test MEAN: 1.000223979363228\n",
      "Test VOL: 0.009419904643453112\n",
      "\n",
      "Equal Weights Model Results for model 2:\n",
      "Validation RMSE: 0.0014103582761839522\n",
      "Test RMSE: 0.0019078407523448037\n",
      "Test MEAN: 1.0001866853162422\n",
      "Test VOL: 0.009375762658917808\n",
      "\n",
      "Equal Weights Model Results for model 3:\n",
      "Validation RMSE: 0.00161101492926301\n",
      "Test RMSE: 0.0017918743187162148\n",
      "Test MEAN: 1.0007247171178195\n",
      "Test VOL: 0.0073472545924650355\n",
      "\n",
      "Equal Weights Model Results for model 4:\n",
      "Validation RMSE: 0.00178815568268382\n",
      "Test RMSE: 0.0017472761704575702\n",
      "Test MEAN: 1.0008824136684178\n",
      "Test VOL: 0.005771463367467524\n",
      "\n",
      "Equal Weights Model Results for model 5:\n",
      "Validation RMSE: 0.0017533218637125797\n",
      "Test RMSE: 0.002080505442953261\n",
      "Test MEAN: 1.0001083627465603\n",
      "Test VOL: 0.0071012566865318\n",
      "\n",
      "Equal Weights Model Results for model 6:\n",
      "Validation RMSE: 0.0017002638599400465\n",
      "Test RMSE: 0.00228250529001297\n",
      "Test MEAN: 1.0001620095538837\n",
      "Test VOL: 0.007788089429743422\n",
      "\n",
      "Equal Weights Model Results for model 7:\n",
      "Validation RMSE: 0.0016838896697022906\n",
      "Test RMSE: 0.002378854806423318\n",
      "Test MEAN: 0.9993495431539628\n",
      "Test VOL: 0.01030115605112\n",
      "\n",
      "Equal Weights Model Results for model 8:\n",
      "Validation RMSE: 0.0019078407523448037\n",
      "Test RMSE: 0.0023376364047417086\n",
      "Test MEAN: 0.9999067253622472\n",
      "Test VOL: 0.011090800105457103\n",
      "\n",
      "Equal Weights Model Results for model 9:\n",
      "Validation RMSE: 0.0017918743187162148\n",
      "Test RMSE: 0.002388129123328023\n",
      "Test MEAN: 1.0000040026106212\n",
      "Test VOL: 0.01124682440183062\n",
      "\n",
      "Equal Weights Model Results for model 10:\n",
      "Validation RMSE: 0.0017472761704575702\n",
      "Test RMSE: 0.0023085543362458107\n",
      "Test MEAN: 1.0000718893313152\n",
      "Test VOL: 0.011509377237775696\n",
      "\n",
      "Equal Weights Model Results for model 11:\n",
      "Validation RMSE: 0.002080505442953261\n",
      "Test RMSE: 0.002032437718144319\n",
      "Test MEAN: 1.000830591240973\n",
      "Test VOL: 0.010286093526332842\n",
      "\n",
      "Equal Weights Model Results for model 12:\n",
      "Validation RMSE: 0.00228250529001297\n",
      "Test RMSE: 0.0018717109499381298\n",
      "Test MEAN: 1.0000411226733432\n",
      "Test VOL: 0.010199217186937788\n",
      "\n",
      "Equal Weights Model Results for model 13:\n",
      "Validation RMSE: 0.002378854806423318\n",
      "Test RMSE: 0.0019686564797122682\n",
      "Test MEAN: 1.001545688626488\n",
      "Test VOL: 0.00785354280865888\n",
      "\n",
      "Equal Weights Model Results for model 14:\n",
      "Validation RMSE: 0.0023376364047417086\n",
      "Test RMSE: 0.0018238046048378409\n",
      "Test MEAN: 1.0008391489528465\n",
      "Test VOL: 0.006810393203633415\n",
      "\n",
      "Equal Weights Model Results for model 15:\n",
      "Validation RMSE: 0.002388129123328023\n",
      "Test RMSE: 0.0018329033576296974\n",
      "Test MEAN: 1.0002709492409667\n",
      "Test VOL: 0.008782697951417989\n",
      "\n",
      "Equal Weights Model Results for model 16:\n",
      "Validation RMSE: 0.0023085543362458107\n",
      "Test RMSE: 0.0019462210070632896\n",
      "Test MEAN: 1.0003969000958595\n",
      "Test VOL: 0.00852099192750391\n",
      "\n",
      "Equal Weights Model Results for model 17:\n",
      "Validation RMSE: 0.002032437718144319\n",
      "Test RMSE: 0.0019529162145969603\n",
      "Test MEAN: 1.000392883753487\n",
      "Test VOL: 0.008965706249123151\n",
      "\n",
      "Equal Weights Model Results for model 18:\n",
      "Validation RMSE: 0.0018717109499381298\n",
      "Test RMSE: 0.0017551968016899662\n",
      "Test MEAN: 1.0010811798288035\n",
      "Test VOL: 0.008335453377224893\n",
      "\n",
      "Equal Weights Model Results for model 19:\n",
      "Validation RMSE: 0.0019686564797122682\n",
      "Test RMSE: 0.0016997279716028772\n",
      "Test MEAN: 1.0006691408676718\n",
      "Test VOL: 0.008074250561516116\n",
      "\n",
      "Equal Weights Model Results for model 20:\n",
      "Validation RMSE: 0.0018238046048378409\n",
      "Test RMSE: 0.0016412298848949248\n",
      "Test MEAN: 1.0008752824992275\n",
      "Test VOL: 0.008477442042150077\n",
      "\n",
      "Equal Weights Model Results for model 21:\n",
      "Validation RMSE: 0.0018329033576296974\n",
      "Test RMSE: 0.0017154290837354325\n",
      "Test MEAN: 1.0013691612601823\n",
      "Test VOL: 0.0060952621747070645\n",
      "\n",
      "Equal Weights Model Results for model 22:\n",
      "Validation RMSE: 0.0019462210070632896\n",
      "Test RMSE: 0.0015070538899133762\n",
      "Test MEAN: 1.001407483656043\n",
      "Test VOL: 0.005970004052186092\n",
      "\n",
      "Equal Weights Model Results for model 23:\n",
      "Validation RMSE: 0.0019529162145969603\n",
      "Test RMSE: 0.0011258740977238898\n",
      "Test MEAN: 1.0011664333407222\n",
      "Test VOL: 0.004264614317583064\n",
      "\n",
      "Equal Weights Model Results for model 24:\n",
      "Validation RMSE: 0.0017551968016899662\n",
      "Test RMSE: 0.0013201770489190275\n",
      "Test MEAN: 1.0017054738565843\n",
      "Test VOL: 0.004493494843845112\n",
      "Selected Model Test Results for model i = 1 are: \n",
      "RMSE = 0.0016838896697022906\n",
      "MEAN = 1.000223979363228\n",
      "VOL = 0.009419904643453112\n"
     ]
    }
   ],
   "source": [
    "equal_w_model_valid_rmse_list = []\n",
    "equal_w_model_test_results = []\n",
    "\n",
    "for i in range(24):\n",
    "    print(f'\\nEqual Weights Model Results for model {i+1}:')\n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    x_test = data_process(date_slicer(df, '2018-01-01', 1, i))\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i))\n",
    "    \n",
    "    equal_w_model_valid_rmse_list.append(valid_fun(x_valid, i, equal_w_model))\n",
    "    equal_w_model_test_results.append(test_fun(x_test, i, equal_w_model))\n",
    "    \n",
    "print('Selected Model Test Results for model i =', (deep_best_result_index)+1, 'are: ')\n",
    "print('RMSE =', equal_w_model_test_results[(deep_best_result_index)]['RMSE'])\n",
    "print('MEAN =', equal_w_model_test_results[(deep_best_result_index)]['MEAN'])\n",
    "print('VOL =', equal_w_model_test_results[(deep_best_result_index)]['VOL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models test results with rebalancing period of 1 month(s) are: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep NNF</th>\n",
       "      <th>Shallow NNF</th>\n",
       "      <th>1/N Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.001684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN</th>\n",
       "      <td>1.000198</td>\n",
       "      <td>1.000211</td>\n",
       "      <td>1.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOL</th>\n",
       "      <td>0.009396</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>0.009420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Deep NNF  Shallow NNF  1/N Model\n",
       "RMSE  0.001745     0.001716   0.001684\n",
       "MEAN  1.000198     1.000211   1.000224\n",
       "VOL   0.009396     0.009404   0.009420"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print test results\n",
    "print(f'Models test results with rebalancing period of {rbp} month(s) are: ')\n",
    "deep_temp = pd.DataFrame(deep_nnf_test_results)\n",
    "deep_temp = deep_temp.iloc[deep_best_result_index]\n",
    "shallow_temp = pd.DataFrame(shallow_nnf_test_results)\n",
    "shallow_temp = shallow_temp.iloc[deep_best_result_index]\n",
    "equal_w_temp = pd.DataFrame(equal_w_model_test_results)\n",
    "equal_w_temp = equal_w_temp.iloc[deep_best_result_index]\n",
    "\n",
    "final_result = pd.concat([deep_temp, shallow_temp, equal_w_temp], axis=1, join='inner')\n",
    "final_result.columns = ['Deep NNF', 'Shallow NNF', '1/N Model']\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72a5606bcafec1593511b6d198bb0982fb8ea54acb1913d581966686ae52246b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
