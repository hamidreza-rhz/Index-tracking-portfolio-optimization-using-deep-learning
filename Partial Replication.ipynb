{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta as rd\n",
    "import time\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks data csv read\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df.set_index('Date')\n",
    "\n",
    "# s&p data csv read\n",
    "df_sp = pd.read_csv('sp500.csv')\n",
    "df_sp = df_sp.set_index('Date')\n",
    "\n",
    "# stocks data csv read for partial replication\n",
    "df_reduce = pd.read_csv('data.csv')\n",
    "df_reduce = df_reduce.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_slicer(df, start, duration, rebalancing_period=0):\n",
    "    '''\n",
    "    this function is used to slice out specific section of the data\n",
    "    '''\n",
    "    start = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=rebalancing_period))\n",
    "    end = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=duration) - rd(days=1))\n",
    "    return df.loc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(df):\n",
    "    '''\n",
    "    this function gets the dataframe as input, processes it, and ouputs the cumulative change of the stocks\n",
    "    that is used as input for training the model.\n",
    "    '''\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    df = df.cumprod()\n",
    "    df = df - 1\n",
    "    df = df.iloc[-1,:]\n",
    "    df = df.to_numpy()\n",
    "    df = torch.from_numpy(df).type(torch.Tensor)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_change(df):\n",
    "    '''\n",
    "    this function calculate the daily change of stocks included in the dataframe.\n",
    "    '''\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_return(df):\n",
    "    '''\n",
    "    this function calculate the daily return of stocks included in the dataframe, note that \n",
    "    daily return is equal to daily change + 1\n",
    "    '''\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_finder(df):\n",
    "    '''\n",
    "    this function is just being used for extracting the stocks symbols\n",
    "    '''\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    df = df.cumprod()\n",
    "    df = df - 1\n",
    "    df = df.iloc[-1,:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing stocks symbols\n",
    "stocks_index = index_finder(df).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf biuld\n",
    "class shallow_NNF(nn.Module):\n",
    "    '''\n",
    "    this class is used to train the data with Shallow NNF model, consisted of 2 fully connected layers, \n",
    "    a relU activation function in between and a softmax layer output that is translated into stock weights in portfolio.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_size, num_classes):\n",
    "        super(shallow_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size) # fully connected layer\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # fully connected layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.softmax(self.fc2(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "shallow nnf partial biuld which is the same as original shallow nnf\n",
    "this class helps us to use the full replication training to find the best companies to invest\n",
    "and then find the optimal wieghts with the partial model\n",
    "'''\n",
    "class shallow_NNF_partial(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_classes):\n",
    "        super(shallow_NNF_partial, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.softmax(self.fc2(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf build\n",
    "class deep_NNF(nn.Module):\n",
    "    '''\n",
    "    this class is used to train the data with Deep NNF model, consisted of 6 fully connected layers, \n",
    "    relU activation functions in between and a softmax layer output that is translated into stock weights in portfolio.\n",
    "    dropout is also included in deep NNF model.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_size1, hidden_size2, hidden_size3,\n",
    "                 hidden_size4, hidden_size5, num_classes, dropout_p = 0.2):\n",
    "        super(deep_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size1) # fully connected layer\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2) # fully connected layer\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3) # fully connected layer\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4) # fully connected layer\n",
    "        self.fc5 = nn.Linear(hidden_size4, hidden_size5) # fully connected layer\n",
    "        self.fc6 = nn.Linear(hidden_size5, num_classes) # fully connected layer\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        self.fc3.reset_parameters()\n",
    "        self.fc4.reset_parameters()\n",
    "        self.fc5.reset_parameters()\n",
    "        self.fc6.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc4(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc5(out))\n",
    "        out = self.softmax(self.fc6(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "deep nnf partial biuld which is the same as original deep nnf\n",
    "this class helps us to use the full replication training to find the best companies to invest\n",
    "and then find the optimal wieghts with the partial model\n",
    "'''\n",
    "class deep_NNF_partial(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size1, hidden_size2, hidden_size3,\n",
    "                 hidden_size4, hidden_size5, num_classes, dropout_p = 0.2):\n",
    "        super(deep_NNF_partial, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.fc5 = nn.Linear(hidden_size4, hidden_size5)\n",
    "        self.fc6 = nn.Linear(hidden_size5, num_classes)\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        self.fc3.reset_parameters()\n",
    "        self.fc4.reset_parameters()\n",
    "        self.fc5.reset_parameters()\n",
    "        self.fc6.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc4(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc5(out))\n",
    "        out = self.softmax(self.fc6(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/N model build\n",
    "class equal_w_model():\n",
    "    '''\n",
    "    this class is used to construct a portfolio with equal weights.\n",
    "    '''\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.performance()\n",
    "        \n",
    "    def performance(self):\n",
    "        self.df = np.array(self.df)\n",
    "        weights = np.ones((len(self.df), 1)) * (1/len(self.df))\n",
    "        cumulative_change = sum(np.multiply(weights, self.df.reshape(-1,1)))\n",
    "        return cumulative_change, weights.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebalancing period = one or three months\n",
    "rbp = 3\n",
    "\n",
    "# number of companies in the partial portfolio\n",
    "partial_num = 50\n",
    "\n",
    "# epochs\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size = 471\n",
    "num_classes = 471\n",
    "lr = 1e-3 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf tune\n",
    "'''\n",
    "loss function is set to MSE and Adam optimizer is used in this model.\n",
    "'''\n",
    "shallow_NNF = shallow_NNF(input_dim=input_dim, hidden_size=hidden_size, num_classes=num_classes)\n",
    "shallow_NNF_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "shallow_NNF_optimizer = torch.optim.Adam(shallow_NNF.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf partial tune\n",
    "'''\n",
    "loss function is set to MSE and Adam optimizer is used in this model.\n",
    "'''\n",
    "shallow_NNF_partial = shallow_NNF_partial(input_dim=partial_num, hidden_size=hidden_size, num_classes=partial_num)\n",
    "shallow_NNF_partial_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "shallow_NNF_partial_optimizer = torch.optim.Adam(shallow_NNF_partial.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size1 = 471\n",
    "hidden_size2 = 471\n",
    "hidden_size3 = 471\n",
    "hidden_size4 = 471\n",
    "hidden_size5 = 471\n",
    "num_classes = 471\n",
    "lr = 1e-3 # learning rate\n",
    "# probability of a neuron being shutdown that shuffles every epoch minimizing the overfit phenomenon\n",
    "dropout_p = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf tune\n",
    "'''\n",
    "like in shallow NNF, loss function is set to MSE and Adam optimizer is used.\n",
    "'''\n",
    "deep_NNF = deep_NNF(input_dim=input_dim, hidden_size1=hidden_size1, hidden_size2=hidden_size2, \n",
    "                    hidden_size3=hidden_size3, hidden_size4=hidden_size4, hidden_size5=hidden_size5,\n",
    "                    num_classes=num_classes)\n",
    "deep_NNF_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "deep_NNF_optimizer = torch.optim.Adam(deep_NNF.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf partial tune\n",
    "'''\n",
    "like in shallow NNF, loss function is set to MSE and Adam optimizer is used.\n",
    "'''\n",
    "deep_NNF_partial = deep_NNF_partial(input_dim=partial_num, hidden_size1=hidden_size1, hidden_size2=hidden_size2, \n",
    "                    hidden_size3=hidden_size3, hidden_size4=hidden_size4, hidden_size5=hidden_size5,\n",
    "                    num_classes=partial_num)\n",
    "deep_NNF_partial_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "deep_NNF_partial_optimizer = torch.optim.Adam(deep_NNF_partial.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "def RMSE(x, y, weights):\n",
    "    '''\n",
    "    this function calculates the root mean squere error of constructed portfollio and benchmark index \n",
    "    that is used for evaluating trained models.\n",
    "    '''\n",
    "    temp = 0\n",
    "    for i in range(len(x)):\n",
    "        temp += (sum(x.iloc[i] * weights) - y.iloc[i]) ** 2\n",
    "    return math.sqrt(temp/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEAN\n",
    "def MEAN(x, weights):\n",
    "    '''\n",
    "    this function calculates the mean return of the constructed portfolio during the given period.\n",
    "    '''\n",
    "    temp = []\n",
    "    for i in range(len(x)):\n",
    "        temp.append(sum(x.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility\n",
    "def VOL(x, weights):\n",
    "    '''\n",
    "    this function calculates the volatility of the constructed portfolio during the given period.\n",
    "    '''\n",
    "    temp = []\n",
    "    for i in range(len(x)):\n",
    "        temp.append(sum(x.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_return(df, x_test, model, i, temp):   \n",
    "    '''\n",
    "    this function outputs the cumulative return of the portfolio test dataset of the given dataframe\n",
    "    ''' \n",
    "    x_return = date_slicer(df, '2018-01-01', 1, i)\n",
    "    x_return =  x_return.pct_change()\n",
    "    x_return =  x_return.tail(-1)\n",
    "    x_return =  x_return + 1\n",
    "    x_return =  x_return.cumprod()\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_test).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_test)[1].detach())\n",
    "    \n",
    "    for i in range(len(x_return)):\n",
    "        temp.append(sum(x_return.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_return(df_sp, i, temp):\n",
    "    '''\n",
    "    this function outputs the cumulative return of the benchmark index test dataset of the given dataframe\n",
    "    '''\n",
    "    y_return = date_slicer(df_sp, '2018-01-01', 1, i)\n",
    "    y_return = y_return.pct_change()\n",
    "    y_return = y_return.tail(-1)\n",
    "    y_return = y_return + 1\n",
    "    y_return = y_return.cumprod()\n",
    "    \n",
    "    for i in range(len(y_return)):\n",
    "        temp.append(sum(y_return.iloc[i]))\n",
    "    temp = np.array(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fun(x_valid, i, model):\n",
    "    '''\n",
    "    this function gets validation dataset, model and rebalaning period as input, then outputs the RMSE of given dataset.\n",
    "    '''\n",
    "    x_change = daily_change(date_slicer(df_reduce, '2017-07-01', 6, i))\n",
    "    y_change = daily_change(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    # x_return = daily_return(date_slicer(df, '2017-07-01', 6, i))\n",
    "    # y_return = daily_return(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_valid).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_valid)[1].detach())\n",
    "    \n",
    "    valid_rmse = RMSE(x_change, y_change, weights)\n",
    "    # valid_mean = MEAN(x_return, weights)\n",
    "    # valid_vol  = VOL(x_return, weights)\n",
    "    \n",
    "    print(f'Validation RMSE: {valid_rmse}')\n",
    "    # print(f'Validation MEAN: {valid_mean}')\n",
    "    # print(f'Validation VOL: {valid_vol}')\n",
    "    \n",
    "    return valid_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fun(x_test, i, model):\n",
    "    '''\n",
    "    this function gets test dataset, model and rebalaning period as input, then outputs the RMSE, Mean and volatility \n",
    "    of the given dataset.\n",
    "    '''\n",
    "    x_change = daily_change(date_slicer(df_reduce, '2018-01-01', 6, i))\n",
    "    y_change = daily_change(date_slicer(df_sp, '2018-01-01', 6, i))\n",
    "    x_return = daily_return(date_slicer(df_reduce, '2018-01-01', 6, i))\n",
    "    y_return = daily_return(date_slicer(df_sp, '2018-01-01', 6, i))\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_test).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_test)[1].detach())\n",
    "    \n",
    "    test_rmse = RMSE(x_change, y_change, weights)\n",
    "    test_mean = MEAN(x_return, weights)\n",
    "    test_vol  = VOL(x_return, weights)\n",
    "    test_dic = {'RMSE': test_rmse, 'MEAN': test_mean, 'VOL': test_vol}\n",
    "    \n",
    "    print(f'Test RMSE: {test_rmse}')\n",
    "    print(f'Test MEAN: {test_mean}')\n",
    "    print(f'Test VOL: {test_vol}')\n",
    "    \n",
    "    return test_dic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deep NNF Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf training function\n",
    "'''\n",
    "this function is used to train the model using x_train & y_train given to it, printing MSE of trained model in first and last\n",
    " epich and also printing train time of the model\n",
    "'''\n",
    "def train_deep_nnf(x_train, y_train, i):\n",
    "    start_time_deep_nnf = time.time()\n",
    "    print(f'\\nDeep NNF Training & Results for model {(i/rbp)+1} (Full replication) :')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = deep_NNF(x_train)[0]\n",
    "        loss_deep_nnf = deep_NNF_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            weights = np.array(deep_NNF(x_train)[1].detach())\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_deep_nnf.item()}')\n",
    "        deep_NNF_optimizer.zero_grad()\n",
    "        loss_deep_nnf.backward()\n",
    "        deep_NNF_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_deep_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf partial training function\n",
    "def train_deep_nnf_partial(x_train, y_train, i):    \n",
    "    start_time_deep_nnf = time.time()\n",
    "    print(f'\\nDeep NNF Training & Results for model {(i/rbp)+1} (Partial replication):')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = deep_NNF_partial(x_train)[0]\n",
    "        loss_deep_nnf = deep_NNF_partial_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_deep_nnf.item()}')\n",
    "        deep_NNF_partial_optimizer.zero_grad()\n",
    "        loss_deep_nnf.backward()\n",
    "        deep_NNF_partial_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_deep_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial(x_train, x_valid, x_test, weights, stocks_index, num = partial_num):\n",
    "    df_partial = pd.DataFrame({'x_train': x_train, 'x_valid': x_valid, 'x_test': x_test,\n",
    "                               'weights': weights}, index = stocks_index)\n",
    "    df_partial = df_partial.sort_values(by = ['weights'])\n",
    "    out_index = df_partial.index[num:]\n",
    "    df_partial = df_partial.iloc[:num]\n",
    "    \n",
    "    x_train = df_partial['x_train'].to_numpy()\n",
    "    x_valid = df_partial['x_valid'].to_numpy()\n",
    "    x_test = df_partial['x_test'].to_numpy()\n",
    "    \n",
    "    x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "    x_valid = torch.from_numpy(x_valid).type(torch.Tensor)\n",
    "    x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "    \n",
    "    return x_train, x_valid, x_test, out_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deep NNF Training & Results for model 1.0 (Full replication) :\n",
      "Epoch 1 of 10 | MSE: 0.04576672986149788\n",
      "Epoch 10 of 10 | MSE: 2.7898104235646315e-05\n",
      "Training time: 0.11\n",
      "\n",
      "Deep NNF Training & Results for model 1.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 1.1630672216415405\n",
      "Epoch 10 of 10 | MSE: 0.11094827950000763\n",
      "Training time: 0.05\n",
      "Validation RMSE: 0.002603573623611535\n",
      "Test RMSE: 0.002783187123030721\n",
      "Test MEAN: 1.0007080186151753\n",
      "Test VOL: 0.009928726956642712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamidrezarahimzadeh/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning:\n",
      "\n",
      "Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deep NNF Training & Results for model 2.0 (Full replication) :\n",
      "Epoch 1 of 10 | MSE: 0.060359105467796326\n",
      "Epoch 10 of 10 | MSE: 0.00017864475375972688\n",
      "Training time: 0.10\n",
      "\n",
      "Deep NNF Training & Results for model 2.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 1.5597609281539917\n",
      "Epoch 10 of 10 | MSE: 0.24643553793430328\n",
      "Training time: 0.04\n",
      "Validation RMSE: 0.00406127756807631\n",
      "Test RMSE: 0.003562123989246157\n",
      "Test MEAN: 1.0012533749186343\n",
      "Test VOL: 0.007433502033991717\n",
      "\n",
      "Deep NNF Training & Results for model 3.0 (Full replication) :\n",
      "Epoch 1 of 10 | MSE: 0.039711933583021164\n",
      "Epoch 10 of 10 | MSE: 0.00988954771310091\n",
      "Training time: 0.10\n",
      "\n",
      "Deep NNF Training & Results for model 3.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 1.6051511764526367\n",
      "Epoch 10 of 10 | MSE: 0.18667708337306976\n",
      "Training time: 0.05\n",
      "Validation RMSE: 0.0036003180298986677\n",
      "Test RMSE: 0.005051869300410573\n",
      "Test MEAN: 0.9989478605606705\n",
      "Test VOL: 0.013719933597843207\n",
      "\n",
      "Deep NNF Training & Results for model 4.0 (Full replication) :\n",
      "Epoch 1 of 10 | MSE: 0.030727500095963478\n",
      "Epoch 10 of 10 | MSE: 0.006350250449031591\n",
      "Training time: 0.11\n",
      "\n",
      "Deep NNF Training & Results for model 4.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 1.8711416721343994\n",
      "Epoch 10 of 10 | MSE: 0.10663554817438126\n",
      "Training time: 0.05\n",
      "Validation RMSE: 0.0058672508435265594\n",
      "Test RMSE: 0.006217000230810333\n",
      "Test MEAN: 1.0001146994854286\n",
      "Test VOL: 0.016496475794264474\n",
      "\n",
      "Deep NNF Training & Results for model 5.0 (Full replication) :\n",
      "Epoch 1 of 10 | MSE: 0.03507731482386589\n",
      "Epoch 10 of 10 | MSE: 0.006476775277405977\n",
      "Training time: 0.10\n",
      "\n",
      "Deep NNF Training & Results for model 5.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 2.048994541168213\n",
      "Epoch 10 of 10 | MSE: 0.0644543245434761\n",
      "Training time: 0.05\n",
      "Validation RMSE: 0.005100078898333103\n",
      "Test RMSE: 0.0034711006056418084\n",
      "Test MEAN: 1.0022790699658013\n",
      "Test VOL: 0.009753216320859792\n",
      "\n",
      "Deep NNF Training & Results for model 6.0 (Full replication) :\n",
      "Epoch 1 of 10 | MSE: 0.03967913240194321\n",
      "Epoch 10 of 10 | MSE: 0.0047518708743155\n",
      "Training time: 0.10\n",
      "\n",
      "Deep NNF Training & Results for model 6.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 3.2371268272399902\n",
      "Epoch 10 of 10 | MSE: 0.5570375919342041\n",
      "Training time: 0.04\n",
      "Validation RMSE: 0.005803568095702459\n",
      "Test RMSE: 0.0047607949666176735\n",
      "Test MEAN: 0.9999209547001239\n",
      "Test VOL: 0.011600810174773048\n",
      "\n",
      "Deep NNF Training & Results for model 7.0 (Full replication) :\n",
      "Epoch 1 of 10 | MSE: 0.020332086831331253\n",
      "Epoch 10 of 10 | MSE: 0.015630003064870834\n",
      "Training time: 0.09\n",
      "\n",
      "Deep NNF Training & Results for model 7.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 0.8606882095336914\n",
      "Epoch 10 of 10 | MSE: 0.25779497623443604\n",
      "Training time: 0.05\n",
      "Validation RMSE: 0.003089886400413772\n",
      "Test RMSE: 0.0025888910124267192\n",
      "Test MEAN: 1.0008439212249878\n",
      "Test VOL: 0.008837174159125437\n",
      "\n",
      "Deep NNF Training & Results for model 8.0 (Full replication) :\n",
      "Epoch 1 of 10 | MSE: 0.028519373387098312\n",
      "Epoch 10 of 10 | MSE: 0.005818419624119997\n",
      "Training time: 0.09\n",
      "\n",
      "Deep NNF Training & Results for model 8.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 1.7042640447616577\n",
      "Epoch 10 of 10 | MSE: 0.1808413863182068\n",
      "Training time: 0.05\n",
      "Validation RMSE: 0.003960383845371803\n",
      "Test RMSE: 0.0038973973870345996\n",
      "Test MEAN: 1.0018158157596462\n",
      "Test VOL: 0.007820339850489019\n",
      "\n",
      "Min Valid RMSE is: 0.002603573623611535 for model i = 1\n",
      "Selected Model Test Results are:\n",
      "RMSE = 0.002783187123030721\n",
      "MEAN = 1.0007080186151753\n",
      "VOL = 0.009928726956642712\n"
     ]
    }
   ],
   "source": [
    "# deep nnf\n",
    "'''\n",
    "in this cell,firstly, train, validation and test datasets are sliced in each loop. then deep NNf outputs the best stocks with \n",
    "full replication and then we use the specific stocks to train the model again and get the optimal weights (each loop)\n",
    "then best model will be chosen. Also RMSE, Mean and volatility of all models and then the best model is printed.\n",
    "'''\n",
    "deep_nnf_valid_rmse_list = []\n",
    "deep_nnf_test_results = []\n",
    "out_index_history = []\n",
    "deep_nnf_test_plot = [] # storing the deep model test data return for plotting later on\n",
    "index_test_plot = [] # storing the index test data return for plotting later on\n",
    "\n",
    "for i in range(int(24/rbp)):\n",
    "    df_reduce = df.copy()    \n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i*rbp))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i*rbp))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i*rbp))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i*rbp))\n",
    "    x_test = data_process(date_slicer(df, '2018-01-01', 1, i*rbp))\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i*rbp))\n",
    "    weights = train_deep_nnf(x_train, y_train, i*rbp)\n",
    "    x_train, x_valid, x_test, out_index = partial(x_train, x_valid, x_test, weights, stocks_index, num = partial_num)\n",
    "    out_index_history.append(out_index)\n",
    "    df_reduce = df_reduce.drop(out_index, axis=1)\n",
    "    train_deep_nnf_partial(x_train, y_train, i*rbp)\n",
    "    deep_nnf_valid_rmse_list.append(valid_fun(x_valid, i*rbp, deep_NNF_partial))\n",
    "    deep_nnf_test_results.append(test_fun(x_test, i*rbp, deep_NNF_partial))\n",
    "    portfolio_return(df_reduce, x_test, deep_NNF_partial, i, deep_nnf_test_plot)\n",
    "    index_return(df_sp, i, index_test_plot)\n",
    "    deep_NNF.reset_parameters()\n",
    "    deep_NNF_partial.reset_parameters()\n",
    "\n",
    "print(f'\\nMin Valid RMSE is: {min(deep_nnf_valid_rmse_list)} for model i = {deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))+1}')\n",
    "print('Selected Model Test Results are:')\n",
    "print('RMSE =', deep_nnf_test_results[deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))]['RMSE'])\n",
    "print('MEAN =', deep_nnf_test_results[deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))]['MEAN'])\n",
    "print('VOL =', deep_nnf_test_results[deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))]['VOL'])\n",
    "\n",
    "deep_best_result_index = deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))\n",
    "deep_nnf_test_plot = np.array(deep_nnf_test_plot).reshape(-1,1)\n",
    "index_test_plot = np.array(index_test_plot).reshape(-1,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Shallow NNF Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf training function\n",
    "def train_shallow_nnf(x_train, y_train, i):\n",
    "    '''\n",
    "    this function is used to train the model using x_train & y_train given to it, printing MSE of trained model in first and last\n",
    "    epoch and also printing train time of the model\n",
    "    '''\n",
    "    start_time_shallow_nnf = time.time()\n",
    "    print(f'\\nShallow NNF Training & Results for model {(i/rbp)+1}:')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = shallow_NNF(x_train)[0]\n",
    "        loss_shallow_nnf = shallow_NNF_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            weights = np.array(deep_NNF(x_train)[1].detach())\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_shallow_nnf.item()}')\n",
    "        shallow_NNF_optimizer.zero_grad()\n",
    "        loss_shallow_nnf.backward()\n",
    "        shallow_NNF_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_shallow_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf partial training function\n",
    "def train_shallow_nnf_partial(x_train, y_train, i):    \n",
    "    start_time_shallow_nnf = time.time()\n",
    "    print(f'\\nDeep NNF Training & Results for model {(i/rbp)+1} (Partial replication):')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = shallow_NNF_partial(x_train)[0]\n",
    "        loss_shallow_nnf = shallow_NNF_partial_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_shallow_nnf.item()}')\n",
    "        shallow_NNF_partial_optimizer.zero_grad()\n",
    "        loss_shallow_nnf.backward()\n",
    "        shallow_NNF_partial_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_shallow_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shallow NNF Training & Results for model 1.0:\n",
      "Epoch 1 of 10 | MSE: 0.047189950942993164\n",
      "Epoch 10 of 10 | MSE: 0.0008117908728308976\n",
      "Training time: 0.07\n",
      "\n",
      "Deep NNF Training & Results for model 1.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 0.10243089497089386\n",
      "Epoch 10 of 10 | MSE: 0.0011636066483333707\n",
      "Training time: 0.01\n",
      "Validation RMSE: 0.001856581934988317\n",
      "Test RMSE: 0.002208954769116824\n",
      "Test MEAN: 1.000093617340787\n",
      "Test VOL: 0.009614344629706147\n",
      "\n",
      "Shallow NNF Training & Results for model 2.0:\n",
      "Epoch 1 of 10 | MSE: 0.05882757529616356\n",
      "Epoch 10 of 10 | MSE: 0.007734063547104597\n",
      "Training time: 0.06\n",
      "\n",
      "Deep NNF Training & Results for model 2.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 0.16543707251548767\n",
      "Epoch 10 of 10 | MSE: 0.00021248288976494223\n",
      "Training time: 0.01\n",
      "Validation RMSE: 0.0022024651628990556\n",
      "Test RMSE: 0.002047568063379345\n",
      "Test MEAN: 1.000875751731011\n",
      "Test VOL: 0.005789363090760106\n",
      "\n",
      "Shallow NNF Training & Results for model 3.0:\n",
      "Epoch 1 of 10 | MSE: 0.04022863134741783\n",
      "Epoch 10 of 10 | MSE: 0.005090109072625637\n",
      "Training time: 0.08\n",
      "\n",
      "Deep NNF Training & Results for model 3.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 0.10346242040395737\n",
      "Epoch 10 of 10 | MSE: 0.0018463032320141792\n",
      "Training time: 0.02\n",
      "Validation RMSE: 0.0024669320475992616\n",
      "Test RMSE: 0.0031151785945720918\n",
      "Test MEAN: 0.9995658221176201\n",
      "Test VOL: 0.010409457343086712\n",
      "\n",
      "Shallow NNF Training & Results for model 4.0:\n",
      "Epoch 1 of 10 | MSE: 0.0291241817176342\n",
      "Epoch 10 of 10 | MSE: 0.0030952489469200373\n",
      "Training time: 0.07\n",
      "\n",
      "Deep NNF Training & Results for model 4.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 0.12089767307043076\n",
      "Epoch 10 of 10 | MSE: 0.008176322095096111\n",
      "Training time: 0.01\n",
      "Validation RMSE: 0.0024565278277400376\n",
      "Test RMSE: 0.0029689943213857227\n",
      "Test MEAN: 0.9999830344997355\n",
      "Test VOL: 0.01170874923269747\n",
      "\n",
      "Shallow NNF Training & Results for model 5.0:\n",
      "Epoch 1 of 10 | MSE: 0.03409900143742561\n",
      "Epoch 10 of 10 | MSE: 0.004319716710597277\n",
      "Training time: 0.09\n",
      "\n",
      "Deep NNF Training & Results for model 5.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 0.09443025290966034\n",
      "Epoch 10 of 10 | MSE: 0.004936709068715572\n",
      "Training time: 0.02\n",
      "Validation RMSE: 0.0027698525643167584\n",
      "Test RMSE: 0.0020188994918058515\n",
      "Test MEAN: 1.001563854594027\n",
      "Test VOL: 0.008167165947939134\n",
      "\n",
      "Shallow NNF Training & Results for model 6.0:\n",
      "Epoch 1 of 10 | MSE: 0.043517112731933594\n",
      "Epoch 10 of 10 | MSE: 5.8764690038515255e-05\n",
      "Training time: 0.14\n",
      "\n",
      "Deep NNF Training & Results for model 6.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 0.05032550171017647\n",
      "Epoch 10 of 10 | MSE: 0.008981547318398952\n",
      "Training time: 0.02\n",
      "Validation RMSE: 0.002952576330067275\n",
      "Test RMSE: 0.002348489102353736\n",
      "Test MEAN: 1.0003995979962708\n",
      "Test VOL: 0.009106680430842633\n",
      "\n",
      "Shallow NNF Training & Results for model 7.0:\n",
      "Epoch 1 of 10 | MSE: 0.019779551774263382\n",
      "Epoch 10 of 10 | MSE: 0.004094227682799101\n",
      "Training time: 0.18\n",
      "\n",
      "Deep NNF Training & Results for model 7.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 0.043545983731746674\n",
      "Epoch 10 of 10 | MSE: 0.0014531174674630165\n",
      "Training time: 0.04\n",
      "Validation RMSE: 0.0021113621066493255\n",
      "Test RMSE: 0.002036199566916084\n",
      "Test MEAN: 1.0006357732732793\n",
      "Test VOL: 0.008091080127137001\n",
      "\n",
      "Shallow NNF Training & Results for model 8.0:\n",
      "Epoch 1 of 10 | MSE: 0.0294477716088295\n",
      "Epoch 10 of 10 | MSE: 0.0013635758077725768\n",
      "Training time: 0.20\n",
      "\n",
      "Deep NNF Training & Results for model 8.0 (Partial replication):\n",
      "Epoch 1 of 10 | MSE: 0.02781776338815689\n",
      "Epoch 10 of 10 | MSE: 0.006926948204636574\n",
      "Training time: 0.03\n",
      "Validation RMSE: 0.0022118212071419916\n",
      "Test RMSE: 0.00206440391069782\n",
      "Test MEAN: 1.0013058672238302\n",
      "Test VOL: 0.00614795816376175\n",
      "Selected Model Test Results for model i = 1 are: \n",
      "RMSE = 0.002208954769116824\n",
      "MEAN = 1.000093617340787\n",
      "VOL = 0.009614344629706147\n"
     ]
    }
   ],
   "source": [
    "#shallow nnf\n",
    "'''\n",
    "in this cell,firstly, train, validation and test datasets are sliced in each loop. then shallow NNf outputs the best stocks with \n",
    "full replication and then we use the specific stocks to train the model again and get the optimal weights (each loop)\n",
    "then best model will be chosen. Also RMSE, Mean and volatility of all models and then the best model is printed.\n",
    "'''\n",
    "shallow_nnf_valid_rmse_list = []\n",
    "shallow_nnf_test_results = []\n",
    "shallow_nnf_test_plot = [] # storing the shallow model test data return for plotting later on\n",
    "\n",
    "for i in range(int(24/rbp)):\n",
    "    df_reduce = df.copy()\n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i*rbp))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i*rbp))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i*rbp))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i*rbp))\n",
    "    x_test = data_process(date_slicer(df, '2018-01-01', 1, i*rbp))\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i*rbp))\n",
    "    weights = train_shallow_nnf(x_train, y_train, i*rbp)\n",
    "    x_train, x_valid, x_test, out_index = partial(x_train, x_valid, x_test, weights, stocks_index, num = partial_num)\n",
    "    df_reduce = df_reduce.drop(out_index, axis=1)\n",
    "    train_shallow_nnf_partial(x_train, y_train, i*rbp)\n",
    "    shallow_nnf_valid_rmse_list.append(valid_fun(x_valid, i*rbp, shallow_NNF_partial))\n",
    "    shallow_nnf_test_results.append(test_fun(x_test, i*rbp, shallow_NNF_partial))\n",
    "    portfolio_return(df_reduce, x_test, shallow_NNF_partial, i, shallow_nnf_test_plot)\n",
    "    shallow_NNF.reset_parameters()\n",
    "    shallow_NNF_partial.reset_parameters()\n",
    "\n",
    "# print(f'\\nMin Valid RMSE is: {min(valid_rmse_list)} for model i = {(deep_best_result_index)+1}')\n",
    "print('Selected Model Test Results for model i =', (deep_best_result_index)+1, 'are: ')\n",
    "print('RMSE =', shallow_nnf_test_results[(deep_best_result_index)]['RMSE'])\n",
    "print('MEAN =', shallow_nnf_test_results[(deep_best_result_index)]['MEAN'])\n",
    "print('VOL =', shallow_nnf_test_results[(deep_best_result_index)]['VOL'])\n",
    "\n",
    "shallow_nnf_test_plot = np.array(shallow_nnf_test_plot).reshape(-1,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1/N Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Equal Weights Model Results for model 1:\n",
      "Validation RMSE: 0.0028697472289477464\n",
      "Test RMSE: 0.002612447787867624\n",
      "Test MEAN: 1.0007578565699635\n",
      "Test VOL: 0.010065460979996322\n",
      "\n",
      "Equal Weights Model Results for model 2:\n",
      "Validation RMSE: 0.004159345733954496\n",
      "Test RMSE: 0.0035677375056315363\n",
      "Test MEAN: 1.0013003988873346\n",
      "Test VOL: 0.0076340066343048435\n",
      "\n",
      "Equal Weights Model Results for model 3:\n",
      "Validation RMSE: 0.0038568232465743904\n",
      "Test RMSE: 0.005513872288860587\n",
      "Test MEAN: 0.9988827842977956\n",
      "Test VOL: 0.014238280000508004\n",
      "\n",
      "Equal Weights Model Results for model 4:\n",
      "Validation RMSE: 0.004396383724639134\n",
      "Test RMSE: 0.006285642911346925\n",
      "Test MEAN: 1.0000178515818765\n",
      "Test VOL: 0.01657948131764014\n",
      "\n",
      "Equal Weights Model Results for model 5:\n",
      "Validation RMSE: 0.005414594792879423\n",
      "Test RMSE: 0.0035676176794984314\n",
      "Test MEAN: 1.0021253586882646\n",
      "Test VOL: 0.01006587638929778\n",
      "\n",
      "Equal Weights Model Results for model 6:\n",
      "Validation RMSE: 0.006119391602061266\n",
      "Test RMSE: 0.003870030332358839\n",
      "Test MEAN: 1.0003216826437862\n",
      "Test VOL: 0.010938856391634038\n",
      "\n",
      "Equal Weights Model Results for model 7:\n",
      "Validation RMSE: 0.003388425650226273\n",
      "Test RMSE: 0.0026933027957938014\n",
      "Test MEAN: 1.0008061762785965\n",
      "Test VOL: 0.00889323429471708\n",
      "\n",
      "Equal Weights Model Results for model 8:\n",
      "Validation RMSE: 0.0037579378905624712\n",
      "Test RMSE: 0.0033624604337649964\n",
      "Test MEAN: 1.0019798978273609\n",
      "Test VOL: 0.007392156306918086\n",
      "Selected Model Test Results for model i = 1 are: \n",
      "RMSE = 0.002612447787867624\n",
      "MEAN = 1.0007578565699635\n",
      "VOL = 0.010065460979996322\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "here we run the 1/N model, for the number of stocks, each stock gets the weight of 1/N meaning that\n",
    "every stock is equally important, this model play the role of a benchmark to see how effective our model are\n",
    "'''\n",
    "equal_w_model_valid_rmse_list = []\n",
    "equal_w_model_test_results = []\n",
    "equal_w_model_test_plot = [] # storing the 1/n model test data return for plotting later on\n",
    "\n",
    "for i in range(int(24/rbp)):\n",
    "    df_reduce = df.copy()\n",
    "    df_reduce = df_reduce.drop(out_index_history[i], axis=1)\n",
    "    print(f'\\nEqual Weights Model Results for model {i+1}:')\n",
    "    x_train = data_process(date_slicer(df_reduce, '2014-07-01', 36, i*rbp))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i*rbp))\n",
    "    x_valid = data_process(date_slicer(df_reduce, '2017-07-01', 6, i*rbp))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i*rbp))\n",
    "    x_test = data_process(date_slicer(df_reduce, '2018-01-01', 1, i*rbp))\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i*rbp))\n",
    "    \n",
    "    equal_w_model_valid_rmse_list.append(valid_fun(x_valid, i*rbp, equal_w_model))\n",
    "    equal_w_model_test_results.append(test_fun(x_test, i*rbp, equal_w_model))\n",
    "    portfolio_return(df_reduce, x_test, equal_w_model, i, equal_w_model_test_plot)\n",
    "    \n",
    "print('Selected Model Test Results for model i =', (deep_best_result_index)+1, 'are: ')\n",
    "print('RMSE =', equal_w_model_test_results[(deep_best_result_index)]['RMSE'])\n",
    "print('MEAN =', equal_w_model_test_results[(deep_best_result_index)]['MEAN'])\n",
    "print('VOL =', equal_w_model_test_results[(deep_best_result_index)]['VOL'])\n",
    "\n",
    "equal_w_model_test_plot = np.array(equal_w_model_test_plot).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models test results with rebalancing period of 3 month(s) are: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep NNF</th>\n",
       "      <th>Shallow NNF</th>\n",
       "      <th>1/N Model</th>\n",
       "      <th>S&amp;P 500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN</th>\n",
       "      <td>1.000708</td>\n",
       "      <td>1.000094</td>\n",
       "      <td>1.000758</td>\n",
       "      <td>1.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOL</th>\n",
       "      <td>0.009929</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>0.010367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Deep NNF  Shallow NNF  1/N Model   S&P 500\n",
       "RMSE  0.002783     0.002209   0.002612         -\n",
       "MEAN  1.000708     1.000094   1.000758  1.000121\n",
       "VOL   0.009929     0.009614   0.010065  0.010367"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print test results\n",
    "'''\n",
    "here we compare the results in a dataframe featuring RMSE, MEAN and, volatility of each model in the test dataset\n",
    "that has the best results for deep nnf model. this dataframe can cope with the understanding of why we bother \n",
    "implementing a complex neural network\n",
    "'''\n",
    "print(f'Models test results with rebalancing period of {rbp} month(s) are: ')\n",
    "deep_temp = pd.DataFrame(deep_nnf_test_results)\n",
    "deep_temp = deep_temp.iloc[deep_best_result_index]\n",
    "shallow_temp = pd.DataFrame(shallow_nnf_test_results)\n",
    "shallow_temp = shallow_temp.iloc[deep_best_result_index]\n",
    "equal_w_temp = pd.DataFrame(equal_w_model_test_results)\n",
    "equal_w_temp = equal_w_temp.iloc[deep_best_result_index]\n",
    "\n",
    "# extract the mean and volatility of the s&p index on the test dataset\n",
    "sp_temp_rmse = '-'\n",
    "sp_temp_mean = daily_return(date_slicer(df_sp, '2018-01-01', 6, deep_best_result_index)).mean()[0]\n",
    "sp_temp_std = daily_return(date_slicer(df_sp, '2018-01-01', 6, deep_best_result_index)).std()[0]\n",
    "sp_temp = pd.DataFrame([sp_temp_rmse, sp_temp_mean, sp_temp_std], index=deep_temp.index)\n",
    "\n",
    "# concatinating the result in a unified dataframe\n",
    "final_result = pd.concat([deep_temp, shallow_temp, equal_w_temp, sp_temp], axis=1, join='inner')\n",
    "final_result.columns = ['Deep NNF', 'Shallow NNF', '1/N Model', 'S&P 500']\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of test RMSE for each model: \n",
      "Deep NNF: 0.004041545576902323\n",
      "Shallow NNF: 0.002351085977528434\n",
      "Equal weight model: 0.003934138966890342\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "to further showcase the results, here we compute the average RMSE of each model in test dataset\n",
    "'''\n",
    "print(f'Average of test RMSE for each model: ')\n",
    "\n",
    "deep_nnf_test_rmse_mean = 0 # temp variable for storing each tmse for deep nnf model\n",
    "for i in range(int(24/rbp)):\n",
    "    deep_nnf_test_rmse_mean += deep_nnf_test_results[i]['RMSE']\n",
    "print(f'Deep NNF: {deep_nnf_test_rmse_mean/int(24/rbp)}')\n",
    "\n",
    "shallow_nnf_test_rmse_mean = 0 # temp variable for storing each tmse for shallow nnf model\n",
    "for i in range(int(24/rbp)):\n",
    "    shallow_nnf_test_rmse_mean += shallow_nnf_test_results[i]['RMSE']\n",
    "print(f'Shallow NNF: {shallow_nnf_test_rmse_mean/int(24/rbp)}')\n",
    "\n",
    "equal_w_model_test_rmse_mean = 0 # temp variable for storing each tmse for 1/n model model\n",
    "for i in range(int(24/rbp)):\n",
    "    equal_w_model_test_rmse_mean += equal_w_model_test_results[i]['RMSE']\n",
    "print(f'Equal weight model: {equal_w_model_test_rmse_mean/int(24/rbp)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinating the test dataset return results of each model + index return for plot\n",
    "plot_test = pd.concat([pd.DataFrame(deep_nnf_test_plot), pd.DataFrame(shallow_nnf_test_plot),\n",
    "                       pd.DataFrame(equal_w_model_test_plot), pd.DataFrame(index_test_plot)], axis=1, join='inner')\n",
    "plot_test.columns = ['Deep NNF', 'Shallow NNF', '1/N Model', 'S&P 500']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "Deep NNF",
         "text": "",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160
         ],
         "y": [
          1.011009111787536,
          1.0117975177059817,
          1.0204999104529544,
          1.0239420081962505,
          1.0226683417954827,
          1.0229777505302502,
          1.0303192739728093,
          1.037121726930793,
          1.03464391230641,
          1.0460124107876918,
          1.0463182703721758,
          1.053646739117018,
          1.0582063247157567,
          1.0655360027543632,
          1.0612191551150683,
          1.0656957751945089,
          1.0717485952607486,
          1.0676499489452425,
          1.0575473973867988,
          1.061343397846923,
          0.9842313164709952,
          0.9492115830445602,
          0.9580189556537592,
          0.9545587117650977,
          0.9144603809291517,
          0.9319739516963249,
          0.94598713241831,
          0.951235469377766,
          0.9696743970184407,
          0.9879431730175509,
          0.9839143900318603,
          0.9838849781352604,
          0.9782121835826731,
          0.9745845143678845,
          0.9908827380910625,
          1.0021121271725046,
          0.9936036395560361,
          0.9873564037474277,
          1.007866995492888,
          1.017400038598482,
          1.029623742093652,
          1.0336083420210915,
          1.038421995522781,
          1.0589613270723903,
          1.0576416263718769,
          1.0530033042555067,
          1.0472524950096256,
          1.0436853423694294,
          1.0459519254296057,
          1.0354179327507593,
          1.0423186487138685,
          1.0433440159560716,
          1.0133876774034443,
          0.9910576564946825,
          1.0215481047814425,
          0.9949804165730337,
          0.9853525904273364,
          1.0004181223090112,
          1.011260629866224,
          1.0231017960416986,
          1.0279221136407173,
          1.002472845029727,
          1.008381241347656,
          1.0323256921622763,
          1.0262832248240423,
          1.0379798273961756,
          1.0302018949825347,
          1.0389876278747678,
          1.0629722327241062,
          1.0651342528103993,
          1.053682520970854,
          1.0471173064021086,
          1.0422381276978288,
          1.0218862671094546,
          1.0201136350736724,
          1.0382823926270128,
          1.0360952772283119,
          1.028152610513318,
          0.9935681811125499,
          0.9945186850910855,
          1.007363767240268,
          1.0144759113615929,
          1.01685854233114,
          1.0276050298902826,
          1.0374544525824376,
          1.0370810382408204,
          1.0347687961836998,
          1.024916906719804,
          1.028719028271806,
          1.0291428402148362,
          1.0323072306232564,
          1.0400258913421758,
          1.0320341046261936,
          1.040196251529021,
          1.0422166271858924,
          1.040351990522989,
          1.0315303549092105,
          1.046067622687,
          1.040026535433377,
          1.0083112426236023,
          1.0143316068663353,
          1.0229851639740926,
          1.0130643850211505,
          1.0187762104867162,
          1.0211436277132637,
          1.0248681938072328,
          1.023617720325921,
          1.026636873815249,
          1.0251409575893398,
          1.0247955558823354,
          1.0168026736811797,
          1.0197105930479664,
          1.01655271413586,
          1.0123216529697254,
          0.9917983564250792,
          0.9962609343678782,
          0.9804220460714286,
          0.9902362641978645,
          0.991629676360221,
          0.9952373365543628,
          1.0026774917189953,
          1.0128538432057295,
          1.0222824395136414,
          1.0250228487691364,
          1.017792356909297,
          1.0308226990978178,
          1.030065323533702,
          1.0263728840890274,
          1.0342414474646784,
          1.039291767284511,
          1.0365578599134067,
          1.0341786053935074,
          1.0353206132552342,
          1.030595227421108,
          1.0449439968683631,
          1.0465269753203563,
          1.0325742195761414,
          1.0168588643641525,
          1.0254448091588857,
          1.0181345214745758,
          1.0185472098825286,
          1.0244172881797569,
          1.0317747180439516,
          1.0303842651979573,
          1.0304606585490323,
          1.0242303525367247,
          1.0195761736848106,
          1.0262878037163483,
          1.014195395395829,
          1.020076630431818,
          1.0203356781176796,
          1.0242381010359087,
          1.0305670044109982,
          1.0356796412639295,
          1.0354553672035502,
          1.0498840694171905,
          1.0586784212791511,
          1.0600441731106816,
          1.06684409232439,
          1.0639285536192564,
          1.0667512452880914
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "Shallow NNF",
         "text": "",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160
         ],
         "y": [
          1.0070266793333584,
          1.011915513671015,
          1.017912470880568,
          1.0220530698945245,
          1.0243095459773912,
          1.0226115627945707,
          1.0284364124737955,
          1.0350770050156786,
          1.0308050762277148,
          1.0402560706305553,
          1.0384438556307622,
          1.04819888078864,
          1.0552474980713353,
          1.0609938032289015,
          1.0637209821706473,
          1.0676253772435949,
          1.076794902537133,
          1.0695939043418188,
          1.0573192793323374,
          1.0565565119691458,
          0.9804845589073148,
          0.9430884154386462,
          0.9507488746746994,
          0.9473729341775821,
          0.9137203548732383,
          0.9270902664718318,
          0.9381986019865136,
          0.9417676213993296,
          0.9540519094728538,
          0.967230898119529,
          0.9672340518397887,
          0.9603925816042528,
          0.9554015749787799,
          0.9575132382911229,
          0.9716349114594773,
          0.9767099168148733,
          0.9642640623311832,
          0.9557046375685946,
          1.0055309779730395,
          1.0154594084825495,
          1.0203591640675265,
          1.0213279878643484,
          1.0256540835697034,
          1.0415705837004563,
          1.0386052623170303,
          1.034678105894377,
          1.0296849593482005,
          1.0277207078994444,
          1.0306882850943262,
          1.0206869669717449,
          1.0229631325999762,
          1.020555437328153,
          0.9994073721072101,
          0.9791238029590492,
          1.0003634439426956,
          0.988119712269447,
          0.9889164057784906,
          1.0009724471903927,
          1.0112283261560697,
          1.0210900785498298,
          1.0249012531386028,
          1.003745297744197,
          1.0038089081376833,
          1.0171040722698952,
          1.0130328372674766,
          1.0176448013825752,
          1.0145477293407676,
          1.0218530282577727,
          1.029968575885891,
          1.033408184471489,
          1.0252065385555609,
          1.0173333791362054,
          1.0178220190175835,
          1.0040606205971305,
          1.006090630955755,
          1.0121592796847128,
          1.0147404732342407,
          1.0089073041326664,
          0.9888682058214897,
          0.9901241114160821,
          1.0020067718684482,
          1.0069720524180463,
          1.0083789581691316,
          1.0171177222836278,
          1.0264709963948624,
          1.0285772725015168,
          1.028047564217167,
          1.0209906135654374,
          1.0255036852292554,
          1.0261047595783017,
          1.0238336684588907,
          1.0313532567817425,
          1.0268999043644038,
          1.0295740444995642,
          1.0296367213648296,
          1.0278912846309811,
          1.0172962942806276,
          1.028992529562065,
          1.0199052508737796,
          1.006359868104996,
          1.0075325981989425,
          1.0162222053446832,
          1.0169229443679106,
          1.0205481125954348,
          1.0212375935563753,
          1.0243063614582257,
          1.0197204953621097,
          1.0215884268706,
          1.0202622190379809,
          1.0160633081548311,
          1.0105645571468083,
          1.0128806853409704,
          1.0065451077659848,
          1.0079675075598142,
          0.99489700712981,
          0.9952605062252695,
          0.986548512938963,
          0.9912421050813496,
          0.9928946812387538,
          0.9978346220362766,
          1.0087237628080628,
          1.014894355523599,
          1.0216366011715803,
          1.0222042585009778,
          1.0160778703226696,
          1.0212150439040955,
          1.0193826947624505,
          1.0147510309523005,
          1.0187597831018333,
          1.0194955668123518,
          1.0191607512139023,
          1.0175186118626147,
          1.0159180221752264,
          1.0146573735401836,
          1.0240132839121985,
          1.0235536661639915,
          1.0124565666405951,
          1.0027714937638985,
          1.0130650439329465,
          1.005998488676664,
          1.0107521765197982,
          1.0123477335022324,
          1.0171656653301224,
          1.0139174349403972,
          1.0126565383204034,
          1.004999600770802,
          1.0014115424792103,
          1.0090110385509248,
          1.0069922497542638,
          1.0133038748169465,
          1.0209005819843726,
          1.0278361318662594,
          1.0313731552548173,
          1.0292608676169053,
          1.026208233598114,
          1.033036281203028,
          1.0382521680392358,
          1.0387618052198793,
          1.0421129313946225,
          1.0371897064430347,
          1.0384670139503438
         ]
        },
        {
         "line": {
          "color": "rgba(50, 171, 96, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "1/N Model",
         "text": "",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160
         ],
         "y": [
          1.0111392067124567,
          1.0145288411128348,
          1.0241033926089795,
          1.0282978308223618,
          1.0277751715221262,
          1.0254493486162533,
          1.032612802065572,
          1.0394492698932205,
          1.0360655025317647,
          1.0478535822089492,
          1.048518107937274,
          1.0559607219604836,
          1.0590213016798753,
          1.0643563873294364,
          1.0590413918236703,
          1.0625567447981665,
          1.071776052756524,
          1.0653992858516756,
          1.0553195865217564,
          1.0618519691091146,
          0.9831982533943552,
          0.9479481657670803,
          0.956409006021188,
          0.9529452882746814,
          0.9122797252391689,
          0.9301682494869108,
          0.9443645917599108,
          0.9494087663242581,
          0.9684096141093367,
          0.9858963449036495,
          0.9834925452279816,
          0.9837062062447094,
          0.9785245266931994,
          0.9745760135063747,
          0.9910763616258395,
          1.0014160027683194,
          0.9927642614442648,
          0.9853281275951894,
          1.0092364570341945,
          1.0202300063944019,
          1.0326894279201604,
          1.0364207251085282,
          1.0411138083458367,
          1.06165467344359,
          1.0602591216567059,
          1.0550699730794149,
          1.0499519154614865,
          1.046273653170608,
          1.0484909017562183,
          1.0370809828104364,
          1.0446889724569015,
          1.0455489892640921,
          1.0156791531392044,
          0.9937073908042114,
          1.024429315435834,
          0.996530986297887,
          0.9860468568128701,
          1.00250528035522,
          1.0110028234052684,
          1.0233366098855259,
          1.0298214632862757,
          1.0040413838305602,
          1.0096605414941886,
          1.03304771685293,
          1.0270940568667606,
          1.0383676428144502,
          1.0301084653443466,
          1.0387304566717819,
          1.0621604206527058,
          1.0641619960200985,
          1.0542323193120096,
          1.0472128033086463,
          1.0425576255574585,
          1.0227388735318046,
          1.020008142674861,
          1.0398894124292108,
          1.0380356319691493,
          1.0308689717628319,
          0.9944359556710949,
          0.9984384119265892,
          1.0112314352620317,
          1.0192252140341769,
          1.0231960505576776,
          1.0376820734954386,
          1.048185479326575,
          1.0488838297111454,
          1.0458327875981652,
          1.0365055978628348,
          1.0396266470889033,
          1.0407347737378594,
          1.0429483769974346,
          1.0512551608786043,
          1.0443007930921864,
          1.0526613274217027,
          1.0537178108117662,
          1.0517774309329364,
          1.0431428866061063,
          1.0563565477031778,
          1.0495231158853213,
          1.0079637738737242,
          1.014218887382775,
          1.0227176242145368,
          1.0118571812843453,
          1.0180472224995607,
          1.0214180739286012,
          1.0260068977622918,
          1.0249534816949593,
          1.0283206274857015,
          1.0271249586367235,
          1.0277798943968466,
          1.019913514053102,
          1.0231576549151709,
          1.0176449839344512,
          1.0139545302427755,
          0.9928152977997321,
          0.9976006904238996,
          0.9805891987443436,
          0.9909412371869871,
          0.9919247777481102,
          0.9951661505527053,
          1.0023504503006309,
          1.012876459404166,
          1.0222630848963001,
          1.0249121618151582,
          1.017669133972759,
          1.031065332151058,
          1.0302929999219663,
          1.0267343911954985,
          1.0347464484045585,
          1.0400157373492036,
          1.0370520343234848,
          1.034727023753983,
          1.036209310099204,
          1.0312316868190188,
          1.0456454339203372,
          1.0463914133513668,
          1.032290513223092,
          1.0166276678000519,
          1.024941143000564,
          1.0159341978307084,
          1.0168790181428131,
          1.0231643175737652,
          1.0313891706455882,
          1.02920049791813,
          1.0293232738459839,
          1.023307766692803,
          1.0195418948675041,
          1.026026544674622,
          1.0139074757934334,
          1.0195687660583193,
          1.0204929718626674,
          1.0237869106099087,
          1.031180134231188,
          1.0356213539207377,
          1.0366412316599498,
          1.0548434664320852,
          1.0634589968647625,
          1.0654913917806794,
          1.072290075424782,
          1.069246704158892,
          1.0719929653087537
         ]
        },
        {
         "line": {
          "color": "rgba(128, 0, 128, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "S&P 500",
         "text": "",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160
         ],
         "y": [
          1.0063988187678174,
          1.0104532331222378,
          1.01756052613646,
          1.0192520618530718,
          1.0205800775224427,
          1.0194449608291194,
          1.0266153766139654,
          1.0335446225887093,
          1.0299019074919185,
          1.0395984871573627,
          1.0379180905786511,
          1.0424696056080711,
          1.0508789228462483,
          1.053163917658637,
          1.0525741713615295,
          1.0532084745811838,
          1.0656797230238397,
          1.0585055944403243,
          1.0469691373757133,
          1.0474810899872826,
          0.9787914523050585,
          0.9386813371369133,
          0.9550528040953712,
          0.9502760228653357,
          0.9146060632223194,
          0.9282667019487502,
          0.9411831475856182,
          0.943642392884729,
          0.9562895208774654,
          0.9678310868101905,
          0.9681925422447539,
          0.9625369525123278,
          0.9572463650149637,
          0.9581782933130517,
          0.9735363356475689,
          0.9849822173437246,
          0.9724661579633176,
          0.9616758790755133,
          1.005071602697713,
          1.016159579134265,
          1.0188410806669994,
          1.0183480893579684,
          1.02289305656995,
          1.0406697424149502,
          1.0393439449479687,
          1.0327300001691544,
          1.0268181142903392,
          1.0260152139842424,
          1.0277629768289267,
          1.0131644306530774,
          1.014665743031788,
          1.0127947099523045,
          0.9873098694051805,
          0.9666090613837801,
          0.9928595108594567,
          0.9757065632079799,
          0.9728607617380555,
          0.9862567806817226,
          1.0126148657086849,
          1.0243272579849914,
          1.0313570764980473,
          1.0087494728739093,
          1.0121152146565606,
          1.029044819045906,
          1.0233589712662865,
          1.031802450431812,
          1.0288240233366426,
          1.037166796810276,
          1.0482245556115208,
          1.0490960136583551,
          1.0430887589823636,
          1.0341843981903012,
          1.0342425519413678,
          1.0204038059039324,
          1.022278348182939,
          1.0329450097814639,
          1.0340953231711592,
          1.0256286771649166,
          0.9927941364144521,
          0.990556701620733,
          1.0032469010248992,
          1.0067160741565893,
          1.0064486487434146,
          1.016193306164882,
          1.0257156914795584,
          1.0274671992820958,
          1.0283749557818398,
          1.0213386699391316,
          1.0254858786918764,
          1.0246081937600573,
          1.0219112252999667,
          1.0294598310819911,
          1.0262316900386654,
          1.029565311342211,
          1.0274822810205553,
          1.0250602786545306,
          1.0132062894955904,
          1.0260697452623868,
          1.0190108370003281,
          1.0044795984363044,
          1.0051853388746206,
          1.013797156235869,
          1.0130731138039089,
          1.016239883457275,
          1.0173259469223745,
          1.0190995380584336,
          1.01499651295076,
          1.0175051272030116,
          1.0164702200206917,
          1.0143090745060876,
          1.0102281010902103,
          1.0119577672952513,
          1.005536378857846,
          1.0074086217219176,
          0.9935822716687778,
          0.9957727005926209,
          0.9872047185704218,
          0.9933043504338407,
          0.9940576755436773,
          0.995052649459258,
          1.003630802740886,
          1.0121428782208493,
          1.0210730007304945,
          1.0246194600673186,
          1.01735060188897,
          1.0262514455236553,
          1.0273590147346074,
          1.0263027502102562,
          1.0303809679741733,
          1.0326071189351556,
          1.0285252300803842,
          1.0275497277211143,
          1.0294384148472329,
          1.03436006848548,
          1.0437744053116034,
          1.040609372314535,
          1.0337806764626405,
          1.0278321266601336,
          1.032852807699117,
          1.0049264450595978,
          1.0095935073980913,
          1.0131656786160577,
          1.016027043209936,
          1.0157604580692234,
          1.0142960621713257,
          1.0070804736124737,
          1.0030461173380103,
          1.0094548344287018,
          1.001780792294429,
          1.0097143035233918,
          1.013069701211911,
          1.015529452447731,
          1.0176301120772238,
          1.017224940696154,
          1.0155045466420984,
          1.021799496569033,
          1.0296371171228813,
          1.0299143763326282,
          1.0357863651188828,
          1.031197490780373,
          1.0313361637497624
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"55e3b1be-24bb-4672-a80a-2d932ba773bf\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';                                    if (document.getElementById(\"55e3b1be-24bb-4672-a80a-2d932ba773bf\")) {                    Plotly.newPlot(                        \"55e3b1be-24bb-4672-a80a-2d932ba773bf\",                        [{\"line\":{\"color\":\"rgba(255, 153, 51, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"Deep NNF\",\"text\":\"\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160],\"y\":[1.011009111787536,1.0117975177059817,1.0204999104529544,1.0239420081962505,1.0226683417954827,1.0229777505302502,1.0303192739728093,1.037121726930793,1.03464391230641,1.0460124107876918,1.0463182703721758,1.053646739117018,1.0582063247157567,1.0655360027543632,1.0612191551150683,1.0656957751945089,1.0717485952607486,1.0676499489452425,1.0575473973867988,1.061343397846923,0.9842313164709952,0.9492115830445602,0.9580189556537592,0.9545587117650977,0.9144603809291517,0.9319739516963249,0.94598713241831,0.951235469377766,0.9696743970184407,0.9879431730175509,0.9839143900318603,0.9838849781352604,0.9782121835826731,0.9745845143678845,0.9908827380910625,1.0021121271725046,0.9936036395560361,0.9873564037474277,1.007866995492888,1.017400038598482,1.029623742093652,1.0336083420210915,1.038421995522781,1.0589613270723903,1.0576416263718769,1.0530033042555067,1.0472524950096256,1.0436853423694294,1.0459519254296057,1.0354179327507593,1.0423186487138685,1.0433440159560716,1.0133876774034443,0.9910576564946825,1.0215481047814425,0.9949804165730337,0.9853525904273364,1.0004181223090112,1.011260629866224,1.0231017960416986,1.0279221136407173,1.002472845029727,1.008381241347656,1.0323256921622763,1.0262832248240423,1.0379798273961756,1.0302018949825347,1.0389876278747678,1.0629722327241062,1.0651342528103993,1.053682520970854,1.0471173064021086,1.0422381276978288,1.0218862671094546,1.0201136350736724,1.0382823926270128,1.0360952772283119,1.028152610513318,0.9935681811125499,0.9945186850910855,1.007363767240268,1.0144759113615929,1.01685854233114,1.0276050298902826,1.0374544525824376,1.0370810382408204,1.0347687961836998,1.024916906719804,1.028719028271806,1.0291428402148362,1.0323072306232564,1.0400258913421758,1.0320341046261936,1.040196251529021,1.0422166271858924,1.040351990522989,1.0315303549092105,1.046067622687,1.040026535433377,1.0083112426236023,1.0143316068663353,1.0229851639740926,1.0130643850211505,1.0187762104867162,1.0211436277132637,1.0248681938072328,1.023617720325921,1.026636873815249,1.0251409575893398,1.0247955558823354,1.0168026736811797,1.0197105930479664,1.01655271413586,1.0123216529697254,0.9917983564250792,0.9962609343678782,0.9804220460714286,0.9902362641978645,0.991629676360221,0.9952373365543628,1.0026774917189953,1.0128538432057295,1.0222824395136414,1.0250228487691364,1.017792356909297,1.0308226990978178,1.030065323533702,1.0263728840890274,1.0342414474646784,1.039291767284511,1.0365578599134067,1.0341786053935074,1.0353206132552342,1.030595227421108,1.0449439968683631,1.0465269753203563,1.0325742195761414,1.0168588643641525,1.0254448091588857,1.0181345214745758,1.0185472098825286,1.0244172881797569,1.0317747180439516,1.0303842651979573,1.0304606585490323,1.0242303525367247,1.0195761736848106,1.0262878037163483,1.014195395395829,1.020076630431818,1.0203356781176796,1.0242381010359087,1.0305670044109982,1.0356796412639295,1.0354553672035502,1.0498840694171905,1.0586784212791511,1.0600441731106816,1.06684409232439,1.0639285536192564,1.0667512452880914],\"type\":\"scatter\"},{\"line\":{\"color\":\"rgba(55, 128, 191, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"Shallow NNF\",\"text\":\"\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160],\"y\":[1.0070266793333584,1.011915513671015,1.017912470880568,1.0220530698945245,1.0243095459773912,1.0226115627945707,1.0284364124737955,1.0350770050156786,1.0308050762277148,1.0402560706305553,1.0384438556307622,1.04819888078864,1.0552474980713353,1.0609938032289015,1.0637209821706473,1.0676253772435949,1.076794902537133,1.0695939043418188,1.0573192793323374,1.0565565119691458,0.9804845589073148,0.9430884154386462,0.9507488746746994,0.9473729341775821,0.9137203548732383,0.9270902664718318,0.9381986019865136,0.9417676213993296,0.9540519094728538,0.967230898119529,0.9672340518397887,0.9603925816042528,0.9554015749787799,0.9575132382911229,0.9716349114594773,0.9767099168148733,0.9642640623311832,0.9557046375685946,1.0055309779730395,1.0154594084825495,1.0203591640675265,1.0213279878643484,1.0256540835697034,1.0415705837004563,1.0386052623170303,1.034678105894377,1.0296849593482005,1.0277207078994444,1.0306882850943262,1.0206869669717449,1.0229631325999762,1.020555437328153,0.9994073721072101,0.9791238029590492,1.0003634439426956,0.988119712269447,0.9889164057784906,1.0009724471903927,1.0112283261560697,1.0210900785498298,1.0249012531386028,1.003745297744197,1.0038089081376833,1.0171040722698952,1.0130328372674766,1.0176448013825752,1.0145477293407676,1.0218530282577727,1.029968575885891,1.033408184471489,1.0252065385555609,1.0173333791362054,1.0178220190175835,1.0040606205971305,1.006090630955755,1.0121592796847128,1.0147404732342407,1.0089073041326664,0.9888682058214897,0.9901241114160821,1.0020067718684482,1.0069720524180463,1.0083789581691316,1.0171177222836278,1.0264709963948624,1.0285772725015168,1.028047564217167,1.0209906135654374,1.0255036852292554,1.0261047595783017,1.0238336684588907,1.0313532567817425,1.0268999043644038,1.0295740444995642,1.0296367213648296,1.0278912846309811,1.0172962942806276,1.028992529562065,1.0199052508737796,1.006359868104996,1.0075325981989425,1.0162222053446832,1.0169229443679106,1.0205481125954348,1.0212375935563753,1.0243063614582257,1.0197204953621097,1.0215884268706,1.0202622190379809,1.0160633081548311,1.0105645571468083,1.0128806853409704,1.0065451077659848,1.0079675075598142,0.99489700712981,0.9952605062252695,0.986548512938963,0.9912421050813496,0.9928946812387538,0.9978346220362766,1.0087237628080628,1.014894355523599,1.0216366011715803,1.0222042585009778,1.0160778703226696,1.0212150439040955,1.0193826947624505,1.0147510309523005,1.0187597831018333,1.0194955668123518,1.0191607512139023,1.0175186118626147,1.0159180221752264,1.0146573735401836,1.0240132839121985,1.0235536661639915,1.0124565666405951,1.0027714937638985,1.0130650439329465,1.005998488676664,1.0107521765197982,1.0123477335022324,1.0171656653301224,1.0139174349403972,1.0126565383204034,1.004999600770802,1.0014115424792103,1.0090110385509248,1.0069922497542638,1.0133038748169465,1.0209005819843726,1.0278361318662594,1.0313731552548173,1.0292608676169053,1.026208233598114,1.033036281203028,1.0382521680392358,1.0387618052198793,1.0421129313946225,1.0371897064430347,1.0384670139503438],\"type\":\"scatter\"},{\"line\":{\"color\":\"rgba(50, 171, 96, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"1/N Model\",\"text\":\"\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160],\"y\":[1.0111392067124567,1.0145288411128348,1.0241033926089795,1.0282978308223618,1.0277751715221262,1.0254493486162533,1.032612802065572,1.0394492698932205,1.0360655025317647,1.0478535822089492,1.048518107937274,1.0559607219604836,1.0590213016798753,1.0643563873294364,1.0590413918236703,1.0625567447981665,1.071776052756524,1.0653992858516756,1.0553195865217564,1.0618519691091146,0.9831982533943552,0.9479481657670803,0.956409006021188,0.9529452882746814,0.9122797252391689,0.9301682494869108,0.9443645917599108,0.9494087663242581,0.9684096141093367,0.9858963449036495,0.9834925452279816,0.9837062062447094,0.9785245266931994,0.9745760135063747,0.9910763616258395,1.0014160027683194,0.9927642614442648,0.9853281275951894,1.0092364570341945,1.0202300063944019,1.0326894279201604,1.0364207251085282,1.0411138083458367,1.06165467344359,1.0602591216567059,1.0550699730794149,1.0499519154614865,1.046273653170608,1.0484909017562183,1.0370809828104364,1.0446889724569015,1.0455489892640921,1.0156791531392044,0.9937073908042114,1.024429315435834,0.996530986297887,0.9860468568128701,1.00250528035522,1.0110028234052684,1.0233366098855259,1.0298214632862757,1.0040413838305602,1.0096605414941886,1.03304771685293,1.0270940568667606,1.0383676428144502,1.0301084653443466,1.0387304566717819,1.0621604206527058,1.0641619960200985,1.0542323193120096,1.0472128033086463,1.0425576255574585,1.0227388735318046,1.020008142674861,1.0398894124292108,1.0380356319691493,1.0308689717628319,0.9944359556710949,0.9984384119265892,1.0112314352620317,1.0192252140341769,1.0231960505576776,1.0376820734954386,1.048185479326575,1.0488838297111454,1.0458327875981652,1.0365055978628348,1.0396266470889033,1.0407347737378594,1.0429483769974346,1.0512551608786043,1.0443007930921864,1.0526613274217027,1.0537178108117662,1.0517774309329364,1.0431428866061063,1.0563565477031778,1.0495231158853213,1.0079637738737242,1.014218887382775,1.0227176242145368,1.0118571812843453,1.0180472224995607,1.0214180739286012,1.0260068977622918,1.0249534816949593,1.0283206274857015,1.0271249586367235,1.0277798943968466,1.019913514053102,1.0231576549151709,1.0176449839344512,1.0139545302427755,0.9928152977997321,0.9976006904238996,0.9805891987443436,0.9909412371869871,0.9919247777481102,0.9951661505527053,1.0023504503006309,1.012876459404166,1.0222630848963001,1.0249121618151582,1.017669133972759,1.031065332151058,1.0302929999219663,1.0267343911954985,1.0347464484045585,1.0400157373492036,1.0370520343234848,1.034727023753983,1.036209310099204,1.0312316868190188,1.0456454339203372,1.0463914133513668,1.032290513223092,1.0166276678000519,1.024941143000564,1.0159341978307084,1.0168790181428131,1.0231643175737652,1.0313891706455882,1.02920049791813,1.0293232738459839,1.023307766692803,1.0195418948675041,1.026026544674622,1.0139074757934334,1.0195687660583193,1.0204929718626674,1.0237869106099087,1.031180134231188,1.0356213539207377,1.0366412316599498,1.0548434664320852,1.0634589968647625,1.0654913917806794,1.072290075424782,1.069246704158892,1.0719929653087537],\"type\":\"scatter\"},{\"line\":{\"color\":\"rgba(128, 0, 128, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"S&P 500\",\"text\":\"\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160],\"y\":[1.0063988187678174,1.0104532331222378,1.01756052613646,1.0192520618530718,1.0205800775224427,1.0194449608291194,1.0266153766139654,1.0335446225887093,1.0299019074919185,1.0395984871573627,1.0379180905786511,1.0424696056080711,1.0508789228462483,1.053163917658637,1.0525741713615295,1.0532084745811838,1.0656797230238397,1.0585055944403243,1.0469691373757133,1.0474810899872826,0.9787914523050585,0.9386813371369133,0.9550528040953712,0.9502760228653357,0.9146060632223194,0.9282667019487502,0.9411831475856182,0.943642392884729,0.9562895208774654,0.9678310868101905,0.9681925422447539,0.9625369525123278,0.9572463650149637,0.9581782933130517,0.9735363356475689,0.9849822173437246,0.9724661579633176,0.9616758790755133,1.005071602697713,1.016159579134265,1.0188410806669994,1.0183480893579684,1.02289305656995,1.0406697424149502,1.0393439449479687,1.0327300001691544,1.0268181142903392,1.0260152139842424,1.0277629768289267,1.0131644306530774,1.014665743031788,1.0127947099523045,0.9873098694051805,0.9666090613837801,0.9928595108594567,0.9757065632079799,0.9728607617380555,0.9862567806817226,1.0126148657086849,1.0243272579849914,1.0313570764980473,1.0087494728739093,1.0121152146565606,1.029044819045906,1.0233589712662865,1.031802450431812,1.0288240233366426,1.037166796810276,1.0482245556115208,1.0490960136583551,1.0430887589823636,1.0341843981903012,1.0342425519413678,1.0204038059039324,1.022278348182939,1.0329450097814639,1.0340953231711592,1.0256286771649166,0.9927941364144521,0.990556701620733,1.0032469010248992,1.0067160741565893,1.0064486487434146,1.016193306164882,1.0257156914795584,1.0274671992820958,1.0283749557818398,1.0213386699391316,1.0254858786918764,1.0246081937600573,1.0219112252999667,1.0294598310819911,1.0262316900386654,1.029565311342211,1.0274822810205553,1.0250602786545306,1.0132062894955904,1.0260697452623868,1.0190108370003281,1.0044795984363044,1.0051853388746206,1.013797156235869,1.0130731138039089,1.016239883457275,1.0173259469223745,1.0190995380584336,1.01499651295076,1.0175051272030116,1.0164702200206917,1.0143090745060876,1.0102281010902103,1.0119577672952513,1.005536378857846,1.0074086217219176,0.9935822716687778,0.9957727005926209,0.9872047185704218,0.9933043504338407,0.9940576755436773,0.995052649459258,1.003630802740886,1.0121428782208493,1.0210730007304945,1.0246194600673186,1.01735060188897,1.0262514455236553,1.0273590147346074,1.0263027502102562,1.0303809679741733,1.0326071189351556,1.0285252300803842,1.0275497277211143,1.0294384148472329,1.03436006848548,1.0437744053116034,1.040609372314535,1.0337806764626405,1.0278321266601336,1.032852807699117,1.0049264450595978,1.0095935073980913,1.0131656786160577,1.016027043209936,1.0157604580692234,1.0142960621713257,1.0070804736124737,1.0030461173380103,1.0094548344287018,1.001780792294429,1.0097143035233918,1.013069701211911,1.015529452447731,1.0176301120772238,1.017224940696154,1.0155045466420984,1.021799496569033,1.0296371171228813,1.0299143763326282,1.0357863651188828,1.031197490780373,1.0313361637497624],\"type\":\"scatter\"}],                        {\"legend\":{\"bgcolor\":\"#F5F6F9\",\"font\":{\"color\":\"#4D5663\"}},\"paper_bgcolor\":\"#F5F6F9\",\"plot_bgcolor\":\"#F5F6F9\",\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"color\":\"#4D5663\"}},\"xaxis\":{\"gridcolor\":\"#E1E5ED\",\"showgrid\":true,\"tickfont\":{\"color\":\"#4D5663\"},\"title\":{\"font\":{\"color\":\"#4D5663\"},\"text\":\"\"},\"zerolinecolor\":\"#E1E5ED\"},\"yaxis\":{\"gridcolor\":\"#E1E5ED\",\"showgrid\":true,\"tickfont\":{\"color\":\"#4D5663\"},\"title\":{\"font\":{\"color\":\"#4D5663\"},\"text\":\"\"},\"zerolinecolor\":\"#E1E5ED\"}},                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('55e3b1be-24bb-4672-a80a-2d932ba773bf');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing a module for better and more interactive plot\n",
    "import cufflinks as cf\n",
    "cf.set_config_file(offline = True)\n",
    "\n",
    "'''\n",
    "plotting deep nnf, shallow nnf and, 1/n model performance on the test dataset, compare them with\n",
    "index (s&p) for better understanding\n",
    "'''\n",
    "plot_test.iplot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72a5606bcafec1593511b6d198bb0982fb8ea54acb1913d581966686ae52246b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
