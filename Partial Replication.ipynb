{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta as rd\n",
    "import time\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks data csv read\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df.set_index('Date')\n",
    "\n",
    "# s&p data csv read\n",
    "df_sp = pd.read_csv('sp500.csv')\n",
    "df_sp = df_sp.set_index('Date')\n",
    "\n",
    "# stocks data csv read for partial replication\n",
    "df_reduce = pd.read_csv('data.csv')\n",
    "df_reduce = df_reduce.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_slicer(df, start, duration, rebalancing_period=0):\n",
    "    start = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=rebalancing_period))\n",
    "    end = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=duration) - rd(days=1))\n",
    "    return df.loc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(df):\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    df = df.cumprod()\n",
    "    df = df - 1\n",
    "    df = df.iloc[-1,:]\n",
    "    df = df.to_numpy()\n",
    "    df = torch.from_numpy(df).type(torch.Tensor)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_change(df):\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_return(df):\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_finder(df):\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    df = df.cumprod()\n",
    "    df = df - 1\n",
    "    df = df.iloc[-1,:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_index = index_finder(df).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf biuld\n",
    "class shallow_NNF(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_classes):\n",
    "        super(shallow_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.softmax(self.fc2(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf biuld\n",
    "class shallow_NNF_partial(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_classes):\n",
    "        super(shallow_NNF_partial, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.softmax(self.fc2(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf build\n",
    "class deep_NNF(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size1, hidden_size2, hidden_size3,\n",
    "                 hidden_size4, hidden_size5, num_classes, dropout_p = 0.2):\n",
    "        super(deep_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.fc5 = nn.Linear(hidden_size4, hidden_size5)\n",
    "        self.fc6 = nn.Linear(hidden_size5, num_classes)\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        self.fc3.reset_parameters()\n",
    "        self.fc4.reset_parameters()\n",
    "        self.fc5.reset_parameters()\n",
    "        self.fc6.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc4(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc5(out))\n",
    "        out = self.softmax(self.fc6(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deep_NNF_partial(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size1, hidden_size2, hidden_size3,\n",
    "                 hidden_size4, hidden_size5, num_classes, dropout_p = 0.2):\n",
    "        super(deep_NNF_partial, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.fc5 = nn.Linear(hidden_size4, hidden_size5)\n",
    "        self.fc6 = nn.Linear(hidden_size5, num_classes)\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        self.fc3.reset_parameters()\n",
    "        self.fc4.reset_parameters()\n",
    "        self.fc5.reset_parameters()\n",
    "        self.fc6.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc4(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc5(out))\n",
    "        out = self.softmax(self.fc6(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/N model build\n",
    "class equal_w_model():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.performance()\n",
    "        \n",
    "    def performance(self):\n",
    "        self.df = np.array(self.df)\n",
    "        weights = np.ones((len(self.df), 1)) * (1/len(self.df))\n",
    "        cumulative_change = sum(np.multiply(weights, self.df.reshape(-1,1)))\n",
    "        return cumulative_change, weights.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebalancing period = one or three months\n",
    "rbp = 3\n",
    "\n",
    "# number of companies in the partial portfolio\n",
    "partial_num = 200\n",
    "\n",
    "# epochs\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size = 471\n",
    "num_classes = 471\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf tune\n",
    "shallow_NNF = shallow_NNF(input_dim=input_dim, hidden_size=hidden_size, num_classes=num_classes)\n",
    "shallow_NNF_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "shallow_NNF_optimizer = torch.optim.Adam(shallow_NNF.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf partial tune\n",
    "shallow_NNF_partial = shallow_NNF_partial(input_dim=partial_num, hidden_size=hidden_size, num_classes=partial_num)\n",
    "shallow_NNF_partial_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "shallow_NNF_partial_optimizer = torch.optim.Adam(shallow_NNF_partial.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size1 = 471\n",
    "hidden_size2 = 471\n",
    "hidden_size3 = 471\n",
    "hidden_size4 = 471\n",
    "hidden_size5 = 471\n",
    "num_classes = 471\n",
    "lr = 1e-10\n",
    "dropout_p = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf tune\n",
    "deep_NNF = deep_NNF(input_dim=input_dim, hidden_size1=hidden_size1, hidden_size2=hidden_size2, \n",
    "                    hidden_size3=hidden_size3, hidden_size4=hidden_size4, hidden_size5=hidden_size5,\n",
    "                    num_classes=num_classes)\n",
    "deep_NNF_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "deep_NNF_optimizer = torch.optim.Adam(deep_NNF.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf partial tune\n",
    "deep_NNF_partial = deep_NNF_partial(input_dim=partial_num, hidden_size1=hidden_size1, hidden_size2=hidden_size2, \n",
    "                    hidden_size3=hidden_size3, hidden_size4=hidden_size4, hidden_size5=hidden_size5,\n",
    "                    num_classes=partial_num)\n",
    "deep_NNF_partial_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "deep_NNF_partial_optimizer = torch.optim.Adam(deep_NNF_partial.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "def RMSE(x, y, weights):\n",
    "    temp = 0\n",
    "    for i in range(len(x)):\n",
    "        temp += (sum(x.iloc[i] * weights) - y.iloc[i]) ** 2\n",
    "    return math.sqrt(temp/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEAN\n",
    "def MEAN(x, weights):\n",
    "    temp = []\n",
    "    for i in range(len(x)):\n",
    "        temp.append(sum(x.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility\n",
    "def VOL(x, weights):\n",
    "    temp = []\n",
    "    for i in range(len(x)):\n",
    "        temp.append(sum(x.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fun(x_valid, i, model):\n",
    "    x_change = daily_change(date_slicer(df_reduce, '2017-07-01', 6, i))\n",
    "    y_change = daily_change(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    # x_return = daily_return(date_slicer(df, '2017-07-01', 6, i))\n",
    "    # y_return = daily_return(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_valid).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_valid)[1].detach())\n",
    "    \n",
    "    valid_rmse = RMSE(x_change, y_change, weights)\n",
    "    # valid_mean = MEAN(x_return, weights)\n",
    "    # valid_vol  = VOL(x_return, weights)\n",
    "    \n",
    "    print(f'Validation RMSE: {valid_rmse}')\n",
    "    # print(f'Validation MEAN: {valid_mean}')\n",
    "    # print(f'Validation VOL: {valid_vol}')\n",
    "    \n",
    "    return valid_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fun(x_test, i, model):\n",
    "    x_change = daily_change(date_slicer(df_reduce, '2018-01-01', 6, i))\n",
    "    y_change = daily_change(date_slicer(df_sp, '2018-01-01', 6, i))\n",
    "    x_return = daily_return(date_slicer(df_reduce, '2018-01-01', 6, i))\n",
    "    y_return = daily_return(date_slicer(df_sp, '2018-01-01', 6, i))\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_test).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_test)[1].detach())\n",
    "    \n",
    "    test_rmse = RMSE(x_change, y_change, weights)\n",
    "    test_mean = MEAN(x_return, weights)\n",
    "    test_vol  = VOL(x_return, weights)\n",
    "    test_dic = {'RMSE': test_rmse, 'MEAN': test_mean, 'VOL': test_vol}\n",
    "    \n",
    "    print(f'Test RMSE: {test_rmse}')\n",
    "    print(f'Test MEAN: {test_mean}')\n",
    "    print(f'Test VOL: {test_vol}')\n",
    "    \n",
    "    return test_dic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deep NNF Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf training function\n",
    "def train_deep_nnf(x_train, y_train, i):\n",
    "    start_time_deep_nnf = time.time()\n",
    "    print(f'\\nDeep NNF Training & Results for model {(i/rbp)+1} (Full Reblication) :')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = deep_NNF(x_train)[0]\n",
    "        loss_deep_nnf = deep_NNF_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            weights = np.array(deep_NNF(x_train)[1].detach())\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_deep_nnf.item()}')\n",
    "        deep_NNF_optimizer.zero_grad()\n",
    "        loss_deep_nnf.backward()\n",
    "        deep_NNF_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_deep_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deep_nnf_partial(x_train, y_train, i):    \n",
    "    start_time_deep_nnf = time.time()\n",
    "    print(f'\\nDeep NNF Training & Results for model {(i/rbp)+1} (Partial Reblication):')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = deep_NNF_partial(x_train)[0]\n",
    "        loss_deep_nnf = deep_NNF_partial_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_deep_nnf.item()}')\n",
    "        deep_NNF_partial_optimizer.zero_grad()\n",
    "        loss_deep_nnf.backward()\n",
    "        deep_NNF_partial_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_deep_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial(x_train, x_valid, x_test, weights, stocks_index, num = partial_num):\n",
    "    df_partial = pd.DataFrame({'x_train': x_train, 'x_valid': x_valid, 'x_test': x_test,\n",
    "                               'weights': weights}, index = stocks_index)\n",
    "    df_partial = df_partial.sort_values(by = ['weights'])\n",
    "    out_index = df_partial.index[num:]\n",
    "    df_partial = df_partial.iloc[:num]\n",
    "    \n",
    "    x_train = df_partial['x_train'].to_numpy()\n",
    "    x_valid = df_partial['x_valid'].to_numpy()\n",
    "    x_test = df_partial['x_test'].to_numpy()\n",
    "    \n",
    "    x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "    x_valid = torch.from_numpy(x_valid).type(torch.Tensor)\n",
    "    x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "    \n",
    "    return x_train, x_valid, x_test, out_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deep NNF Training & Results for model 1.0 (Full Reblication) :\n",
      "Epoch 1 of 100 | MSE: 0.04566861316561699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamidrezarahimzadeh/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 of 100 | MSE: 0.04566877707839012\n",
      "Training time: 0.75\n",
      "\n",
      "Deep NNF Training & Results for model 1.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.061448998749256134\n",
      "Epoch 100 of 100 | MSE: 0.06159500777721405\n",
      "Training time: 0.53\n",
      "Validation RMSE: 0.0014898983392043015\n",
      "Test RMSE: 0.0017775458220514588\n",
      "Test MEAN: 1.0002287540988233\n",
      "Test VOL: 0.009420203726963554\n",
      "\n",
      "Deep NNF Training & Results for model 2.0 (Full Reblication) :\n",
      "Epoch 1 of 100 | MSE: 0.06037161126732826\n",
      "Epoch 100 of 100 | MSE: 0.060311052948236465\n",
      "Training time: 0.69\n",
      "\n",
      "Deep NNF Training & Results for model 2.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.04497447609901428\n",
      "Epoch 100 of 100 | MSE: 0.04492756724357605\n",
      "Training time: 0.61\n",
      "Validation RMSE: 0.0019115778314505768\n",
      "Test RMSE: 0.0018719206917839648\n",
      "Test MEAN: 1.000870741370569\n",
      "Test VOL: 0.0058813721982710655\n",
      "\n",
      "Deep NNF Training & Results for model 3.0 (Full Reblication) :\n",
      "Epoch 1 of 100 | MSE: 0.03899169713258743\n",
      "Epoch 100 of 100 | MSE: 0.03891553729772568\n",
      "Training time: 0.72\n",
      "\n",
      "Deep NNF Training & Results for model 3.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.034610565751791\n",
      "Epoch 100 of 100 | MSE: 0.03477107360959053\n",
      "Training time: 0.53\n",
      "Validation RMSE: 0.0018943170609860929\n",
      "Test RMSE: 0.0025169084782044214\n",
      "Test MEAN: 0.9993690094664073\n",
      "Test VOL: 0.010127251361621901\n",
      "\n",
      "Deep NNF Training & Results for model 4.0 (Full Reblication) :\n",
      "Epoch 1 of 100 | MSE: 0.031661078333854675\n",
      "Epoch 100 of 100 | MSE: 0.031564753502607346\n",
      "Training time: 0.77\n",
      "\n",
      "Deep NNF Training & Results for model 4.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.024533435702323914\n",
      "Epoch 100 of 100 | MSE: 0.024486806243658066\n",
      "Training time: 0.75\n",
      "Validation RMSE: 0.0017940823538474438\n",
      "Test RMSE: 0.0022520876272737194\n",
      "Test MEAN: 1.000087588363713\n",
      "Test VOL: 0.011601582370288613\n",
      "\n",
      "Deep NNF Training & Results for model 5.0 (Full Reblication) :\n",
      "Epoch 1 of 100 | MSE: 0.03539671748876572\n",
      "Epoch 100 of 100 | MSE: 0.03534636273980141\n",
      "Training time: 1.01\n",
      "\n",
      "Deep NNF Training & Results for model 5.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.027999786660075188\n",
      "Epoch 100 of 100 | MSE: 0.028003856539726257\n",
      "Training time: 0.75\n",
      "Validation RMSE: 0.002550090424827704\n",
      "Test RMSE: 0.002168801776026706\n",
      "Test MEAN: 1.001448107358775\n",
      "Test VOL: 0.00799625817415073\n",
      "\n",
      "Deep NNF Training & Results for model 6.0 (Full Reblication) :\n",
      "Epoch 1 of 100 | MSE: 0.03885176405310631\n",
      "Epoch 100 of 100 | MSE: 0.03846951574087143\n",
      "Training time: 0.89\n",
      "\n",
      "Deep NNF Training & Results for model 6.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.03539736941456795\n",
      "Epoch 100 of 100 | MSE: 0.03528766706585884\n",
      "Training time: 0.53\n",
      "Validation RMSE: 0.0022831719474359653\n",
      "Test RMSE: 0.0019451262104233549\n",
      "Test MEAN: 1.0003330545836762\n",
      "Test VOL: 0.008682266607396518\n",
      "\n",
      "Deep NNF Training & Results for model 7.0 (Full Reblication) :\n",
      "Epoch 1 of 100 | MSE: 0.020407330244779587\n",
      "Epoch 100 of 100 | MSE: 0.020429501309990883\n",
      "Training time: 0.73\n",
      "\n",
      "Deep NNF Training & Results for model 7.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.0283463466912508\n",
      "Epoch 100 of 100 | MSE: 0.02822600118815899\n",
      "Training time: 0.56\n",
      "Validation RMSE: 0.001921143582354424\n",
      "Test RMSE: 0.00164355482996931\n",
      "Test MEAN: 1.0006730434775213\n",
      "Test VOL: 0.008012789636790326\n",
      "\n",
      "Deep NNF Training & Results for model 8.0 (Full Reblication) :\n",
      "Epoch 1 of 100 | MSE: 0.02805345132946968\n",
      "Epoch 100 of 100 | MSE: 0.02800782583653927\n",
      "Training time: 0.77\n",
      "\n",
      "Deep NNF Training & Results for model 8.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.02697453461587429\n",
      "Epoch 100 of 100 | MSE: 0.026804311200976372\n",
      "Training time: 0.54\n",
      "Validation RMSE: 0.002036109453031499\n",
      "Test RMSE: 0.0016123022532283577\n",
      "Test MEAN: 1.0014300742223818\n",
      "Test VOL: 0.005904155235127073\n",
      "\n",
      "Min Valid RMSE is: 0.0014898983392043015 for model i = 1\n",
      "Selected Model Test Results are:\n",
      "RMSE = 0.0017775458220514588\n",
      "MEAN = 1.0002287540988233\n",
      "VOL = 0.009420203726963554\n"
     ]
    }
   ],
   "source": [
    "# deep nnf\n",
    "deep_nnf_valid_rmse_list = []\n",
    "deep_nnf_test_results = []\n",
    "out_index_history = []\n",
    "\n",
    "for i in range(int(24/rbp)):\n",
    "    df_reduce = df.copy()    \n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i*rbp))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i*rbp))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i*rbp))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i*rbp))\n",
    "    x_test = data_process(date_slicer(df, '2018-01-01', 1, i*rbp))\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i*rbp))\n",
    "    weights = train_deep_nnf(x_train, y_train, i*rbp)\n",
    "    deep_NNF.reset_parameters()\n",
    "    x_train, x_valid, x_test, out_index = partial(x_train, x_valid, x_test, weights, stocks_index, num = partial_num)\n",
    "    out_index_history.append(out_index)\n",
    "    df_reduce = df_reduce.drop(out_index, axis=1)\n",
    "    train_deep_nnf_partial(x_train, y_train, i*rbp)\n",
    "    deep_nnf_valid_rmse_list.append(valid_fun(x_valid, i*rbp, deep_NNF_partial))\n",
    "    deep_nnf_test_results.append(test_fun(x_test, i*rbp, deep_NNF_partial))\n",
    "    deep_NNF_partial.reset_parameters()\n",
    "\n",
    "print(f'\\nMin Valid RMSE is: {min(deep_nnf_valid_rmse_list)} for model i = {deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))+1}')\n",
    "print('Selected Model Test Results are:')\n",
    "print('RMSE =', deep_nnf_test_results[deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))]['RMSE'])\n",
    "print('MEAN =', deep_nnf_test_results[deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))]['MEAN'])\n",
    "print('VOL =', deep_nnf_test_results[deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))]['VOL'])\n",
    "\n",
    "deep_best_result_index = deep_nnf_valid_rmse_list.index(min(deep_nnf_valid_rmse_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Shallow NNF Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf training function\n",
    "def train_shallow_nnf(x_train, y_train, i):\n",
    "    start_time_shallow_nnf = time.time()\n",
    "    print(f'\\nShallow NNF Training & Results for model {(i/rbp)+1}:')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = shallow_NNF(x_train)[0]\n",
    "        loss_shallow_nnf = shallow_NNF_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            weights = np.array(deep_NNF(x_train)[1].detach())\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_shallow_nnf.item()}')\n",
    "        shallow_NNF_optimizer.zero_grad()\n",
    "        loss_shallow_nnf.backward()\n",
    "        shallow_NNF_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_shallow_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_shallow_nnf_partial(x_train, y_train, i):    \n",
    "    start_time_shallow_nnf = time.time()\n",
    "    print(f'\\nDeep NNF Training & Results for model {(i/rbp)+1} (Partial Reblication):')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = shallow_NNF_partial(x_train)[0]\n",
    "        loss_shallow_nnf = shallow_NNF_partial_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_shallow_nnf.item()}')\n",
    "        shallow_NNF_partial_optimizer.zero_grad()\n",
    "        loss_shallow_nnf.backward()\n",
    "        shallow_NNF_partial_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_shallow_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shallow NNF Training & Results for model 1.0:\n",
      "Epoch 1 of 100 | MSE: 0.04449588060379028\n",
      "Epoch 100 of 100 | MSE: 2.3366943935343443e-09\n",
      "Training time: 0.45\n",
      "\n",
      "Deep NNF Training & Results for model 1.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.01692584715783596\n",
      "Epoch 100 of 100 | MSE: 1.9652335314646052e-09\n",
      "Training time: 0.21\n",
      "Validation RMSE: 0.0016118840395405163\n",
      "Test RMSE: 0.0018110241699876273\n",
      "Test MEAN: 1.000191222045947\n",
      "Test VOL: 0.0096294161103305\n",
      "\n",
      "Shallow NNF Training & Results for model 2.0:\n",
      "Epoch 1 of 100 | MSE: 0.05458909273147583\n",
      "Epoch 100 of 100 | MSE: 6.044797942195146e-07\n",
      "Training time: 0.46\n",
      "\n",
      "Deep NNF Training & Results for model 2.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.021377578377723694\n",
      "Epoch 100 of 100 | MSE: 8.185452315956354e-12\n",
      "Training time: 0.25\n",
      "Validation RMSE: 0.002076585704884206\n",
      "Test RMSE: 0.0020191054348520604\n",
      "Test MEAN: 1.0008324714714139\n",
      "Test VOL: 0.00587828662367308\n",
      "\n",
      "Shallow NNF Training & Results for model 3.0:\n",
      "Epoch 1 of 100 | MSE: 0.04281168058514595\n",
      "Epoch 100 of 100 | MSE: 9.404491407849491e-09\n",
      "Training time: 0.45\n",
      "\n",
      "Deep NNF Training & Results for model 3.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.019874228164553642\n",
      "Epoch 100 of 100 | MSE: 5.2087191448890735e-08\n",
      "Training time: 0.21\n",
      "Validation RMSE: 0.001962447411467281\n",
      "Test RMSE: 0.0027270100847899834\n",
      "Test MEAN: 0.9992672132584329\n",
      "Test VOL: 0.01042176379768659\n",
      "\n",
      "Shallow NNF Training & Results for model 4.0:\n",
      "Epoch 1 of 100 | MSE: 0.02943129651248455\n",
      "Epoch 100 of 100 | MSE: 2.5547706172801554e-09\n",
      "Training time: 0.41\n",
      "\n",
      "Deep NNF Training & Results for model 4.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.011446721851825714\n",
      "Epoch 100 of 100 | MSE: 1.3495341733005262e-08\n",
      "Training time: 0.21\n",
      "Validation RMSE: 0.0020099351092589353\n",
      "Test RMSE: 0.0026383333617127414\n",
      "Test MEAN: 0.9999678060370923\n",
      "Test VOL: 0.011874254978642763\n",
      "\n",
      "Shallow NNF Training & Results for model 5.0:\n",
      "Epoch 1 of 100 | MSE: 0.03488670289516449\n",
      "Epoch 100 of 100 | MSE: 1.034820513723389e-07\n",
      "Training time: 0.41\n",
      "\n",
      "Deep NNF Training & Results for model 5.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.017127694562077522\n",
      "Epoch 100 of 100 | MSE: 7.29048821312972e-10\n",
      "Training time: 0.20\n",
      "Validation RMSE: 0.002553006473172472\n",
      "Test RMSE: 0.0022314726520347937\n",
      "Test MEAN: 1.0015106220700747\n",
      "Test VOL: 0.008119432078720255\n",
      "\n",
      "Shallow NNF Training & Results for model 6.0:\n",
      "Epoch 1 of 100 | MSE: 0.037166777998209\n",
      "Epoch 100 of 100 | MSE: 1.7668874079390662e-06\n",
      "Training time: 0.43\n",
      "\n",
      "Deep NNF Training & Results for model 6.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.022302640601992607\n",
      "Epoch 100 of 100 | MSE: 1.073148325758666e-08\n",
      "Training time: 0.22\n",
      "Validation RMSE: 0.0026696940425929697\n",
      "Test RMSE: 0.002463617601899431\n",
      "Test MEAN: 1.00032509054691\n",
      "Test VOL: 0.008843428449527992\n",
      "\n",
      "Shallow NNF Training & Results for model 7.0:\n",
      "Epoch 1 of 100 | MSE: 0.020519599318504333\n",
      "Epoch 100 of 100 | MSE: 7.1788344158107975e-09\n",
      "Training time: 0.40\n",
      "\n",
      "Deep NNF Training & Results for model 7.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.010988050140440464\n",
      "Epoch 100 of 100 | MSE: 7.193445838993284e-08\n",
      "Training time: 0.21\n",
      "Validation RMSE: 0.002268758854773335\n",
      "Test RMSE: 0.00217807136394298\n",
      "Test MEAN: 1.000698875504137\n",
      "Test VOL: 0.008444465644500373\n",
      "\n",
      "Shallow NNF Training & Results for model 8.0:\n",
      "Epoch 1 of 100 | MSE: 0.023042699322104454\n",
      "Epoch 100 of 100 | MSE: 1.3775131719739875e-06\n",
      "Training time: 0.40\n",
      "\n",
      "Deep NNF Training & Results for model 8.0 (Partial Reblication):\n",
      "Epoch 1 of 100 | MSE: 0.015201997011899948\n",
      "Epoch 100 of 100 | MSE: 5.099114730455767e-08\n",
      "Training time: 0.21\n",
      "Validation RMSE: 0.002528796614070873\n",
      "Test RMSE: 0.001837292208078357\n",
      "Test MEAN: 1.0015747849822652\n",
      "Test VOL: 0.006258489404319588\n",
      "Selected Model Test Results for model i = 1 are: \n",
      "RMSE = 0.0018110241699876273\n",
      "MEAN = 1.000191222045947\n",
      "VOL = 0.0096294161103305\n"
     ]
    }
   ],
   "source": [
    "#shallow nnf\n",
    "shallow_nnf_valid_rmse_list = []\n",
    "shallow_nnf_test_results = []\n",
    "\n",
    "for i in range(int(24/rbp)):\n",
    "    df_reduce = df.copy()\n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i*rbp))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i*rbp))\n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i*rbp))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i*rbp))\n",
    "    x_test = data_process(date_slicer(df, '2018-01-01', 1, i*rbp))\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i*rbp))\n",
    "    weights = train_shallow_nnf(x_train, y_train, i*rbp)\n",
    "    shallow_NNF.reset_parameters()\n",
    "    x_train, x_valid, x_test, out_index = partial(x_train, x_valid, x_test, weights, stocks_index, num = partial_num)\n",
    "    df_reduce = df_reduce.drop(out_index, axis=1)\n",
    "    train_shallow_nnf_partial(x_train, y_train, i*rbp)\n",
    "    shallow_nnf_valid_rmse_list.append(valid_fun(x_valid, i*rbp, shallow_NNF_partial))\n",
    "    shallow_nnf_test_results.append(test_fun(x_test, i*rbp, shallow_NNF_partial))\n",
    "    shallow_NNF_partial.reset_parameters()\n",
    "\n",
    "# print(f'\\nMin Valid RMSE is: {min(valid_rmse_list)} for model i = {(deep_best_result_index)+1}')\n",
    "print('Selected Model Test Results for model i =', (deep_best_result_index)+1, 'are: ')\n",
    "print('RMSE =', shallow_nnf_test_results[(deep_best_result_index)]['RMSE'])\n",
    "print('MEAN =', shallow_nnf_test_results[(deep_best_result_index)]['MEAN'])\n",
    "print('VOL =', shallow_nnf_test_results[(deep_best_result_index)]['VOL'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1/N Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Equal Weights Model Results for model 1:\n",
      "Validation RMSE: 0.0014874330344783573\n",
      "Test RMSE: 0.0017766416223550592\n",
      "Test MEAN: 1.0002319159808057\n",
      "Test VOL: 0.009416261209756437\n",
      "\n",
      "Equal Weights Model Results for model 2:\n",
      "Validation RMSE: 0.0019177376619139571\n",
      "Test RMSE: 0.0018753307150838493\n",
      "Test MEAN: 1.0008701243543865\n",
      "Test VOL: 0.005877820495139852\n",
      "\n",
      "Equal Weights Model Results for model 3:\n",
      "Validation RMSE: 0.0018932314944657652\n",
      "Test RMSE: 0.0025307492255576456\n",
      "Test MEAN: 0.9993704437732619\n",
      "Test VOL: 0.010116797937027888\n",
      "\n",
      "Equal Weights Model Results for model 4:\n",
      "Validation RMSE: 0.0017921202435552826\n",
      "Test RMSE: 0.0022485529358493754\n",
      "Test MEAN: 1.0000869426141366\n",
      "Test VOL: 0.011604357605707811\n",
      "\n",
      "Equal Weights Model Results for model 5:\n",
      "Validation RMSE: 0.0025498210860338375\n",
      "Test RMSE: 0.0021710284234400926\n",
      "Test MEAN: 1.0014519301808213\n",
      "Test VOL: 0.00799512112064046\n",
      "\n",
      "Equal Weights Model Results for model 6:\n",
      "Validation RMSE: 0.0022760332430162705\n",
      "Test RMSE: 0.0019409453322065074\n",
      "Test MEAN: 1.0003318868223576\n",
      "Test VOL: 0.00867567633811305\n",
      "\n",
      "Equal Weights Model Results for model 7:\n",
      "Validation RMSE: 0.001917819840258663\n",
      "Test RMSE: 0.001644687296720344\n",
      "Test MEAN: 1.0006738457720108\n",
      "Test VOL: 0.008025886108996296\n",
      "\n",
      "Equal Weights Model Results for model 8:\n",
      "Validation RMSE: 0.0020229882418951466\n",
      "Test RMSE: 0.0016049456324488222\n",
      "Test MEAN: 1.0014357254535418\n",
      "Test VOL: 0.005903554435783857\n",
      "Selected Model Test Results for model i = 1 are: \n",
      "RMSE = 0.0017766416223550592\n",
      "MEAN = 1.0002319159808057\n",
      "VOL = 0.009416261209756437\n"
     ]
    }
   ],
   "source": [
    "equal_w_model_valid_rmse_list = []\n",
    "equal_w_model_test_results = []\n",
    "\n",
    "for i in range(int(24/rbp)):\n",
    "    df_reduce = df.copy()\n",
    "    df_reduce = df_reduce.drop(out_index_history[i], axis=1)\n",
    "    print(f'\\nEqual Weights Model Results for model {i+1}:')\n",
    "    x_train = data_process(date_slicer(df_reduce, '2014-07-01', 36, i*rbp))\n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i*rbp))\n",
    "    x_valid = data_process(date_slicer(df_reduce, '2017-07-01', 6, i*rbp))\n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i*rbp))\n",
    "    x_test = data_process(date_slicer(df_reduce, '2018-01-01', 1, i*rbp))\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i*rbp))\n",
    "    \n",
    "    equal_w_model_valid_rmse_list.append(valid_fun(x_valid, i*rbp, equal_w_model))\n",
    "    equal_w_model_test_results.append(test_fun(x_test, i*rbp, equal_w_model))\n",
    "    \n",
    "print('Selected Model Test Results for model i =', (deep_best_result_index)+1, 'are: ')\n",
    "print('RMSE =', equal_w_model_test_results[(deep_best_result_index)]['RMSE'])\n",
    "print('MEAN =', equal_w_model_test_results[(deep_best_result_index)]['MEAN'])\n",
    "print('VOL =', equal_w_model_test_results[(deep_best_result_index)]['VOL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models test results with rebalancing period of 3 month(s) are: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep NNF</th>\n",
       "      <th>Shallow NNF</th>\n",
       "      <th>1/N Model</th>\n",
       "      <th>S&amp;P 500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN</th>\n",
       "      <td>1.000229</td>\n",
       "      <td>1.000191</td>\n",
       "      <td>1.000232</td>\n",
       "      <td>1.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOL</th>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.009629</td>\n",
       "      <td>0.009416</td>\n",
       "      <td>0.010367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Deep NNF  Shallow NNF  1/N Model   S&P 500\n",
       "RMSE  0.001778     0.001811   0.001777         -\n",
       "MEAN  1.000229     1.000191   1.000232  1.000121\n",
       "VOL   0.009420     0.009629   0.009416  0.010367"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print test results\n",
    "print(f'Models test results with rebalancing period of {rbp} month(s) are: ')\n",
    "deep_temp = pd.DataFrame(deep_nnf_test_results)\n",
    "deep_temp = deep_temp.iloc[deep_best_result_index]\n",
    "shallow_temp = pd.DataFrame(shallow_nnf_test_results)\n",
    "shallow_temp = shallow_temp.iloc[deep_best_result_index]\n",
    "equal_w_temp = pd.DataFrame(equal_w_model_test_results)\n",
    "equal_w_temp = equal_w_temp.iloc[deep_best_result_index]\n",
    "\n",
    "sp_temp_rmse = '-'\n",
    "sp_temp_mean = daily_return(date_slicer(df_sp, '2018-01-01', 6, deep_best_result_index)).mean()[0]\n",
    "sp_temp_std = daily_return(date_slicer(df_sp, '2018-01-01', 6, deep_best_result_index)).std()[0]\n",
    "sp_temp = pd.DataFrame([sp_temp_rmse, sp_temp_mean, sp_temp_std], index=deep_temp.index)\n",
    "\n",
    "final_result = pd.concat([deep_temp, shallow_temp, equal_w_temp, sp_temp], axis=1, join='inner')\n",
    "final_result.columns = ['Deep NNF', 'Shallow NNF', '1/N Model', 'S&P 500']\n",
    "final_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72a5606bcafec1593511b6d198bb0982fb8ea54acb1913d581966686ae52246b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
